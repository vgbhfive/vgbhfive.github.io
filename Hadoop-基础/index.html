<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="https://i.loli.net/2019/12/10/JF3dKDSkZoPz7h6.jpg">
  <link rel="icon" type="image/png" sizes="16x16" href="https://i.loli.net/2019/12/10/JF3dKDSkZoPz7h6.jpg">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="G-QBK8PCQC9B">
  <meta name="baidu-site-verification" content="codeva-K7aZhBcBPm">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blog.vgbhfive.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":null,"activeClass":"gitalk"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="简介Hadoop 是一个分布式计算开源框架，其提供一个分布式文件系统子项目（HDFS）和支持 MapReduce 分布式计算的软件架构。 在有了大量数据之后，那么该如何进行存储和分析这些数据呢？Hadoop 需要解决的问题如下：  硬件故障问题。一旦使用磁盘存储数据，就会遇到磁盘故障；但是为了避免数据丢失，最常见的做法就是复制（replication）；系统保存数据的副本（replica），一旦硬">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop-基础">
<meta property="og:url" content="https://blog.vgbhfive.com/Hadoop-%E5%9F%BA%E7%A1%80/index.html">
<meta property="og:site_name" content="Vgbhfive&#39;s Blog">
<meta property="og:description" content="简介Hadoop 是一个分布式计算开源框架，其提供一个分布式文件系统子项目（HDFS）和支持 MapReduce 分布式计算的软件架构。 在有了大量数据之后，那么该如何进行存储和分析这些数据呢？Hadoop 需要解决的问题如下：  硬件故障问题。一旦使用磁盘存储数据，就会遇到磁盘故障；但是为了避免数据丢失，最常见的做法就是复制（replication）；系统保存数据的副本（replica），一旦硬">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://s2.loli.net/2023/02/01/agxbF1OwT7yG9Ps.png">
<meta property="og:image" content="https://s2.loli.net/2023/02/01/O4qDK9esm2n6wfT.png">
<meta property="article:published_time" content="2023-01-15T05:42:34.000Z">
<meta property="article:modified_time" content="2023-02-04T07:42:34.000Z">
<meta property="article:author" content="vgbhfive">
<meta property="article:tag" content="Hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2023/02/01/agxbF1OwT7yG9Ps.png">

<link rel="canonical" href="https://blog.vgbhfive.com/Hadoop-%E5%9F%BA%E7%A1%80/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Hadoop-基础 | Vgbhfive's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Vgbhfive's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Vgbhfive's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-pictures">

    <a href="/pictures/" rel="section"><i class="fa fa-th fa-fw"></i>Pictures</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/vgbhfive" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blog.vgbhfive.com/Hadoop-%E5%9F%BA%E7%A1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.loli.net/2019/12/10/JF3dKDSkZoPz7h6.jpg">
      <meta itemprop="name" content="vgbhfive">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Vgbhfive's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Hadoop-基础
        </h1>

        <div class="post-meta">
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-01-15 13:42:34" itemprop="dateCreated datePublished" datetime="2023-01-15T13:42:34+08:00">2023-01-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-02-04 15:42:34" itemprop="dateModified" datetime="2023-02-04T15:42:34+08:00">2023-02-04</time>
              </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p><code>Hadoop</code> 是一个分布式计算开源框架，其提供一个分布式文件系统子项目（<code>HDFS</code>）和支持 <code>MapReduce</code> 分布式计算的软件架构。</p>
<p>在有了大量数据之后，那么该如何进行存储和分析这些数据呢？<code>Hadoop</code> 需要解决的问题如下：</p>
<ul>
<li>硬件故障问题。一旦使用磁盘存储数据，就会遇到磁盘故障；但是为了避免数据丢失，最常见的做法就是复制（<code>replication</code>）；系统保存数据的副本（<code>replica</code>），一旦硬件系统出现故障，就立即使用另外保存的<strong>副本</strong>。</li>
<li>以某种方式结合大部分数据来共同完成分析。各种分布式系统允许不同来源的数据进行分析，但其数据的正确性是无法保证的。因此 <code>MapReduce</code> 提出了一个编程模型，该模型抽象出这些硬盘读&#x2F;写问题并将其作为对一个数据集（由<strong>键值对</strong>组成）的计算。</li>
</ul>
<span id="more"></span>

<hr>

<h3 id="架构设计及用途"><a href="#架构设计及用途" class="headerlink" title="架构设计及用途"></a>架构设计及用途</h3><p><code>HDFS</code> 采用<strong>主从架构</strong>。<br><code>HDFS</code> 集群是由 <strong>一个 <code>Namenode</code></strong> 和 <strong>一定数量的 <code>Datanodes</code></strong> 组成。<code>Namenode</code> 是一个中心服务器，负责管理文件系统的名字空间（<code>namespace</code>）即元数据以及客户端对文件的访问；而 <code>Datanode</code> 一般是一个节点部署一个，负责管理所在节点上数据的存储。</p>
<p><img src="https://s2.loli.net/2023/02/01/agxbF1OwT7yG9Ps.png" alt="hadoop_1_1.jpg"></p>
<p>集群中单一 <code>Namenode</code> 的结构大大简化了系统的架构，<code>Namenode</code> 是所有 <code>HDFS</code> 元数据的<strong>仲裁者</strong>和<strong>管理者</strong>，因此用户数据永远都不会流过 <code>Namenode</code>。</p>
<p><code>HDFS</code> 使用 <code>Java</code> 语言开发，因此任何支持 <code>Java</code> 的机器都可以部署 <code>Namenode</code> 或者 <code>Datanode</code>。一个典型的场景就是一台机器上运行一个 <code>Namenode</code>，而集群的其他机器运行 <code>Datanode</code> 实例，另外这种架构并不排斥一台机器上部署多个 <code>Datanode</code>，只不过这种情况比较少见而已。</p>
<h4 id="文件系统"><a href="#文件系统" class="headerlink" title="文件系统"></a>文件系统</h4><p><code>HDFS</code> 被设计成能够在一个<strong>大集群中跨机器可靠地存储超大文件</strong>。<code>HDFS</code> 将每个文件存储成一系列的数据块，所有的数据块都是相同的大小（默认为 <code>128M</code>，不包含最后一个数据块）。避免数据丢失文件的所有数据块都会有副本，每个文件的数据块大小和副本系数都可配置；应用程序可以指定某个文件的副本数目，其中副本系数可以在文件创建的时候指定，也可以在之后改变。<br><small><code>HDFS</code> 中的文件都是一次性写入，并严格要求在任何时候只能有一个写入者。</small></p>
<p><img src="https://s2.loli.net/2023/02/01/O4qDK9esm2n6wfT.png" alt="hadoop_1_2.jpg"></p>
<p><code>HDFS</code> 暴露了文件系统的名字空间，用户能够以<strong>文件的形式在上面存储数据</strong>。从内部看，一个文件其实被分成一个或多个数据块，这些块存储在一组 <code>Datanode</code> 上。<code>Namenode</code> 执行文件系统的名字空间操作，比如 <em>打开</em>、<em>关闭</em>、<em>重命名文件</em> 或 <em>目录</em>；同时也负责确定数据块到具体 <code>Datanode</code> 节点的映射。<code>Datanode</code> 负责处理文件系统客户端的读写请求；其在 <code>Namenode</code> 的统一调度下进行数据块的<em>创建</em>、<em>删除</em> 和 <em>复制</em>。</p>
<p><code>Namenode</code> 负责维护文件系统的名字空间，任何对文件系统名字空间或属性的修改都将被 <code>Namenode</code> 记录下来，另外还可以设置 <code>HDFS</code> 保存的文件的副本数目。文件副本的数目称为文件的副本系数，该信息也是由 <code>Namenode</code> 保存的。</p>
<h4 id="数据副本复制"><a href="#数据副本复制" class="headerlink" title="数据副本复制"></a>数据副本复制</h4><p>如何<strong>存放数据块副本</strong>是 <code>HDFS</code> 可靠性和性能的关键，优化的副本存放策略是 <code>HDFS</code> 区分于其他大部分分布式文件系统的重要特性（该特性需要做大量的调优，并需要经验的积累）。<br><code>HDFS</code> 目前采用一种被称为<strong>机架感知（<code>rack-aware</code>）</strong>的策略来改进数据的 <em>可靠性</em>、<em>可用性</em> 和 <em>网络带宽的利用率</em>。目前实现的副本存放策略只是在这个方向上的第一步，实现这个策略的短期目标是验证它在生产环境下的有效性，观察它的行为，为实现更先进的策略打下测试和研究的基础。<br><small>而大型 <code>HDFS</code> 实例一般运行在跨越多个机架的计算机组成的集群上，不同机架上的两台机器之间的通讯需要经过交换机。在大多数情况下，同一个机架内的两台机器间的带宽会比不同机架的两台机器间的带宽大。</small></p>
<p>由于 <strong><code>Namenode</code> 全权管理数据块的复制</strong>，因此会<strong>周期性</strong>地从集群中的每个 <code>Datanode</code> 接收<strong>心跳信号</strong>和<strong>块状态报告（<code>Blockreport</code>）</strong>；接收到心跳信号意味着该 <code>Datanode</code> 节点工作正常，而块状态报告包含该 <code>Datanode</code> 上所有数据块的列表。<br>另外为了降低整体的带宽消耗和读取延时，<code>HDFS</code> 会尽量让读取程序读取离它最近的数据副本。如果在读取程序的同一个机架上有一个副本，那么就读取该副本；但是若一个集群跨越多个数据中心，那么客户端也将首先读本地数据中心的副本。</p>
<p>当一个<strong>文件的副本系数被减小</strong>后，<code>Namenode</code> 会选择过剩的副本删除，在下次心跳检测时会将该信息传递给 <code>Datanode</code>，收到消息后随即移除相应的数据块，集群中的空闲空间增大。</p>
<p>所有的 <code>HDFS</code> 通讯协议都是建立在 <strong><code>TCP/IP</code></strong> 协议之上。客户端通过一个可配置的 <code>TCP</code> 端口连接到 <code>Namenode</code>，通过 <strong><code>ClientProtocol</code></strong> 协议与 Namenode 交互，而 <code>Datanode</code> 则是使用 <strong><code>DatanodeProtocol</code></strong> 协议与 <code>Namenode</code> 交互。一个远程过程调用（<code>RPC</code>）模型被抽象出来封装 <code>ClientProtocol</code> 和 <code>Datanodeprotocol</code> 协议，在该设计上，<code>Namenode</code> 不会主动发起 <code>RPC</code>，而是响应来自客户端或 <code>Datanode</code> 的 <code>RPC</code> 请求。</p>
<h4 id="健壮性"><a href="#健壮性" class="headerlink" title="健壮性"></a>健壮性</h4><p><code>HDFS</code> 的主要目标是即使在出错的情况下也要保证数据存储的可靠性。常见的三种出错情况是：</p>
<ul>
<li><code>Namenode</code> 出错。</li>
<li><code>Datanode</code> 出错。</li>
<li>网络割裂（<code>network partitions</code>）。</li>
</ul>
<p>每个 <code>Datanode</code> 节点周期性地向 <code>Namenode</code> 发送心跳信号，因此一旦出现网络割裂就会导致一部分 <code>Datanode</code> 跟 <code>Namenode</code> 失去联系，<code>Namenode</code> 若是定期没有收到心跳信号，就会<strong>将这些近期不再发送心跳信号的 <code>Datanode</code> 标记为宕机</strong>，不会再将新的读写请求发给它们。<code>Datanode</code> 宕机会导致任何存储在上的数据将不再有效，会引起一些数据块的副本系数低于指定值，然而 <code>Namenode</code> 会不断地检测这些需要复制的数据块，一旦发现副本系数不匹配就会启动复制操作。在下列情况下会启动复制操作：</p>
<ul>
<li>某个 <code>Datanode</code> 节点失效。</li>
<li>某个副本遭到损坏。</li>
<li><code>Datanode</code> 上的硬盘错误。</li>
<li>文件的副本系数增大。</li>
</ul>
<p>现实中从某个 <code>Datanode</code> 获取的数据块有可能是损坏的，损坏可能是由 <code>Datanode</code> 的存储设备错误、网络错误或者软件 <code>bug</code> 造成的。为此 <code>HDFS</code> 客户端软件实现了对 <code>HDFS</code> <strong>文件内容的校验</strong>和 <strong><code>checksum</code> 检查</strong>。当客户端创建一个新的 <code>HDFS</code> 文件时会计算这个文件每个数据块的校验和，并将校验和作为一个单独的隐藏文件保存在同一个 <code>HDFS</code> 名字空间下，当客户端获取文件内容后，它会检验从 <code>Datanode</code> 获取的数据跟相应的校验和文件中的校验和是否匹配；如果不匹配，客户端可以选择从其他 <code>Datanode</code> 获取该数据块的副本。</p>
<p><strong><code>FsImage</code></strong> 和 <strong><code>Editlog</code></strong> 是 <code>HDFS</code> 的核心数据结构，如果这些文件损坏那么整个 <code>HDFS</code> 实例都将失效。因此 <code>Namenode</code> 可以配置成支持<strong>多个 <code>FsImage</code> 和 <code>Editlog</code> 的副本</strong>，任何对核心数据结构的修改都将同步到它们的所有副本上。尽管这种多副本的同步操作可能会降低 <code>Namenode</code> 每秒处理的名字空间事务数量，但是代价依旧是可以接受的，因为即使 <code>HDFS</code> 的应用是数据密集的，但是并非元数据密集的，因此当 <code>Namenode</code> 重启的时候会选取最近的完整的 <code>FsImage</code> 和 <code>Editlog</code> 来使用。</p>
<p><code>Namenode</code> 是 <code>HDFS</code> 集群中的<strong>单点故障（<code>single point of failure</code>）</strong>所在，因此如果 <code>Namenode</code> 机器故障，是需要手工干预的。</p>
<hr>

<h3 id="搭建集群"><a href="#搭建集群" class="headerlink" title="搭建集群"></a>搭建集群</h3><p>在大多数情况下，副本系数是 <code>3</code>，<code>HDFS</code> 的存放策略是将一个副本存放在本地机架的节点上，一个副本放在同一机架的另一个节点上，最后一个副本放在不同机架的节点上。<br>这种策略减少了机架间的数据传输，提高了写操作的效率，同时由于机架的错误远远比节点的错误少，所以这个策略不会影响到数据的可靠性和可用性。与此同时数据块因为放在两个（不是三个）不同的机架上，所以此策略可以减少读取数据时需要的网络传输总带宽。在这种策略下，副本并不是均匀分布在不同的机架上，三分之一的副本在一个节点上，三分之二的副本在一个机架上，其他副本均匀分布在剩下的机架中，这一策略在不损害数据可靠性和读取性能的情况下改进了写数据的性能。</p>
<h4 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h4><ol>
<li><p>三台机器<br>三台机器包含一台 <code>Namenode</code> 机器和两台 <code>Datanode</code> 机器，机器都拥有自己的内网 <code>IP</code>。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">namenode    10.250.0.1</span><br><span class="line">datanode1   10.250.0.2</span><br><span class="line">datanode2   10.250.0.3</span><br></pre></td></tr></table></figure>
</li>
<li><p>全部机器创建相同的用户名和组</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">groupadd hadoop</span><br><span class="line">useradd hadoop -g hadoop</span><br><span class="line">passwd hadoop</span><br><span class="line"><span class="built_in">mkdir</span> /home/hadoop</span><br><span class="line"><span class="built_in">chown</span> -R hadoop:hadoop /home/hadoop</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>Java</code> 环境</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">~ java -version</span><br><span class="line">java version <span class="string">&quot;1.8.0_192&quot;</span></span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_192-b12)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.192-b12, mixed mode)</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="下载及配置"><a href="#下载及配置" class="headerlink" title="下载及配置"></a>下载及配置</h4><ol>
<li><p>下载 <code>jar</code> 包<br>下载这部分就靠自己去网上寻找了，这里就不进行说明。</p>
</li>
<li><p>修改默认配置<br>进入到 <code>conf</code> 文件下。</p>
</li>
<li><p><code>hadoop.sh</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/etc/java-config-2/current-system-vm</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>hdfs-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/hadoop/conan/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>core-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.default.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://10.250.0.1:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>mapred-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapred.job.tracker<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>10.250.0.1:9001<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>masters</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">10.250.0.1</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>slaves</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">10.250.0.2</span><br><span class="line">10.250.0.3</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="同步配置"><a href="#同步配置" class="headerlink" title="同步配置"></a>同步配置</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入到 hadoop 解压的目录下</span></span><br><span class="line">scp -r ./hadoop hadoop@10.250.0.2:/hadoop/conan</span><br><span class="line">scp -r ./hadoop hadoop@10.250.0.3:/hadoop/conan</span><br></pre></td></tr></table></figure>

<h4 id="启动-Namenode-节点"><a href="#启动-Namenode-节点" class="headerlink" title="启动 Namenode 节点"></a>启动 <code>Namenode</code> 节点</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入到 bin 目录下</span></span><br><span class="line">bin/hadoop namenode -format</span><br><span class="line">bin/start-all.sh</span><br></pre></td></tr></table></figure>
<h4 id="检查是否成功"><a href="#检查是否成功" class="headerlink" title="检查是否成功"></a>检查是否成功</h4><ol>
<li><p><code>jps</code></p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">9362 Jps</span><br><span class="line">7756 SecondaryNameNode</span><br><span class="line">7531 JobTracker</span><br><span class="line">7357 NameNode</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>netstat -nl</code></p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Proto Recv-Q Send-Q Local Address           Foreign Address         State      </span><br><span class="line">tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN     </span><br><span class="line">tcp        0      0 0.0.0.0:5666            0.0.0.0:*               LISTEN     </span><br><span class="line">tcp        0      0 0.0.0.0:8649            0.0.0.0:*               LISTEN     </span><br><span class="line">tcp6       0      0 :::50070                :::*                    LISTEN     </span><br><span class="line">tcp6       0      0 :::22                   :::*                    LISTEN     </span><br><span class="line">tcp6       0      0 :::39418                :::*                    LISTEN     </span><br><span class="line">tcp6       0      0 :::32895                :::*                    LISTEN     </span><br><span class="line">tcp6       0      0 10.250.0.1:9000         :::*                    LISTEN     </span><br><span class="line">tcp6       0      0 10.250.0.1:9001         :::*                    LISTEN     </span><br><span class="line">tcp6       0      0 :::50090                :::*                    LISTEN     </span><br><span class="line">tcp6       0      0 :::51595                :::*                    LISTEN     </span><br><span class="line">tcp6       0      0 :::50030                :::*                    LISTEN     </span><br><span class="line">udp        0      0 127.0.0.1:8649          0.0.0.0:*  </span><br></pre></td></tr></table></figure>
</li>
<li><p><code>hadoop</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入到 bin 目录下</span></span><br><span class="line">bin/hadoop fs -<span class="built_in">mkdir</span> /test</span><br><span class="line">bin/hadoop fs -copyFormLocal README.txt /test</span><br><span class="line">bin/hadoop fs -<span class="built_in">ls</span> /test</span><br><span class="line"><span class="comment"># Found 1 items</span></span><br><span class="line"><span class="comment"># -rw-r--r--   2 hadoop supergroup       1006 2022-02-01 12:05 /test/README.txt</span></span><br></pre></td></tr></table></figure></li>
</ol>
<hr>

<h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><h4 id="Web-接口"><a href="#Web-接口" class="headerlink" title="Web 接口"></a><code>Web</code> 接口</h4><p><code>NameNode</code> 和 <code>DataNode</code> 各自启动了一个<strong>内置的 <code>Web</code> 服务器</strong>，显示了集群当前的<strong>基本状态</strong>和<strong>信息</strong>。<br>在默认配置下 <code>NameNode</code> 的首页地址是 <code>http://namenode-name:50070/</code>，这个页面列出了集群里的所有 <code>DataNode</code> 和集群的基本状态，同时该 <code>Web</code> 接口也可以用来浏览整个文件系统（使用 <code>Namenode</code> 首页的 <code>Browse the file system</code> 链接）。</p>
<h4 id="Shell-命令"><a href="#Shell-命令" class="headerlink" title="Shell 命令"></a><code>Shell</code> 命令</h4><p><code>Hadoop</code> 包括一系列的类 <code>sh</code> 的命令，这些命令可直接和 <code>HDFS</code> 以及其他 <code>Hadoop</code> 支持的文件系统进行交互，支持大多数普通文件系统的操作，比如复制文件、改变文件权限等。另外还支持一些 <code>HDFS</code> 特有的操作，比如改变文件副本数目。</p>
<p>所有的 <code>Hadoop</code> 命令均由 <code>bin/hadoop</code> 脚本引发，若不指定参数运行 <code>Hadoop</code> 脚本会打印所有命令的描述。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop [--config confdir] [COMMAND] [GENERIC_OPTIONS] [COMMAND_OPTIONS]</span><br></pre></td></tr></table></figure>

<h5 id="DFSSh"><a href="#DFSSh" class="headerlink" title="DFSSh"></a><code>DFSSh</code></h5><p>运行一个常规的文件系统客户端，<code>HDFS</code> 以文件和目录的形式组织用户数据，<strong>提供了一个命令行接口 <code>DFSSh</code> 让用户与 <code>HDFS</code> 中的数据进行交互</strong>。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs [GENERIC_OPTIONS] [COMMAND_OPTIONS]</span><br></pre></td></tr></table></figure>
<p><small><code>bin/hadoop fs -help</code> 命令列出所有 <code>Hadoop Sh</code> 支持的命令。<code>bin/hadoop fs -help command-name</code> 命令能显示关于某个命令的详细信息。</small></p>
<ol>
<li><p><code>cat</code><br>将路径指定文件的内容输出到 <code>stdout</code>。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -<span class="built_in">cat</span> URI [URI …]</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>chgrp</code><br>改变文件所属的组。使用 <code>-R</code> 将使改变在目录结构下递归进行，并且命令的使用者必须是文件的所有者或者超级用户。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -<span class="built_in">chgrp</span> [-R] GROUP URI [URI …]</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>chmod</code><br>改变文件的权限。使用 <code>-R</code> 将使改变在目录结构下递归进行，并且命令的使用者必须是文件的所有者或者超级用户。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -<span class="built_in">chmod</span> [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; URI [URI …]</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>chown</code><br>改变文件的拥有者。使用 <code>-R</code> 将使改变在目录结构下递归进行，并且命令的使用者必须是超级用户。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -<span class="built_in">chown</span> [-R] [OWNER][:[GROUP]] URI [URI ]</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>ls</code><br>展示文件信息。如果参数是文件则展示文件信息；如果是目录则展示子目录的列表。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -<span class="built_in">ls</span> &lt;args&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>lsr</code><br><code>ls</code> 命令的递归版本，类似于 <code>-R</code>。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -lsr &lt;args&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>du</code><br>显示目录中所有文件的大小，或者当只指定一个文件时，显示此文件的大小。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -<span class="built_in">du</span> URI [URI …]</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>dus</code><br>显示文件的大小。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -dus &lt;args&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>mkdir</code><br>接受路径指定的作为参数，然后创建这些目录。其行为类似于 <code>mkdir -p</code> 会自动创建路径中的各级父目录。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -<span class="built_in">mkdir</span> &lt;paths&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>cp</code><br>将文件从源路径复制到目标路径。这个命令允许有多个源路径，但是目标路径必须是一个目录。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -<span class="built_in">cp</span> URI [URI …] &lt;dest&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>copyFromLocal</code><br>除了限定源路径是一个本地文件外，其余参数和 <code>put</code> 命令相似。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -copyFromLocal &lt;localsrc&gt; URI</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>copyToLocal</code><br>除了限定目标路径是一个本地文件外，其余参数和 <code>get</code> 命令类似。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -copyToLocal [-ignorecrc] [-crc] URI &lt;localdst&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>mv</code><br>将文件从源路径移动到目标路径。这个命令允许有多个源路径，但是目标路径必须是一个目录，另外不支持在不同的文件系统间移动文件。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -<span class="built_in">mv</span> URI [URI …] &lt;dest&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>movefromLocal</code><br>将本地文件上传到 <code>HDFS</code>，之后本地文件会被删除（可以理解为剪切）。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs fs -moveFromLocal &lt;src&gt; &lt;dst&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>get</code><br>复制文件到本地系统。可用 <code>-ignorecrc</code> 选项复制 <code>CRC</code> 校验失败的文件；使用 <code>-crc</code> 选项复制文件以及 <code>CRC</code> 信息。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -get [-ignorecrc] [-crc] &lt;src&gt; &lt;localdst&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>getmerge</code><br>接受一个源目录和一个目标文件作为输入，然后将源目录中的文件合并到本地文件中。<code>addnl</code> 选项是可选的，用于指定在每个文件结尾添加一个换行符。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -getmerge &lt;src&gt; &lt;localdst&gt; [addnl]</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>put</code><br>从本地文件系统中复制单个或多个源路径到目标文件系统，另外也支持从标准输入中读取输入写入目标文件系统。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put &lt;localsrc&gt; ... &lt;dst&gt;</span><br></pre></td></tr></table></figure>
<p><small><code>localsrc</code> 为 <code>-</code> 表示从标准输入中读取输入。</small></p>
</li>
<li><p><code>rm</code><br>删除指定的文件。只删除非空目录和文件。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -<span class="built_in">rm</span> URI [URI …]</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>rmr</code><br><code>rm</code> 的递归版本。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -rmr URI [URI …]</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>touchz</code><br>创建一个 <code>0</code> 字节的空文件。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -touchz URI [URI …]</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>setrep</code><br>改变一个文件的副本系数。<code>-R</code> 选项用于递归改变目录下所有文件的副本系数。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -setrep [-R] &lt;path&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>stat</code><br>返回指定路径的统计信息。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -<span class="built_in">stat</span> URI [URI …]</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>tail</code><br>将文件尾部 <code>1K</code> 字节的内容输出到 <code>stdout</code>。支持 <code>-f</code> 选项。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -<span class="built_in">tail</span> [-f] URI</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>test</code><br>检查文件。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -<span class="built_in">test</span> -[ezd] URI</span><br></pre></td></tr></table></figure>
<p>其中 <code>-[ezd]</code> 选项分别代表：</p>
<ul>
<li><code>-e</code>，检查文件是否存在。如果存在则返回 <code>0</code>。</li>
<li><code>-z</code>，检查文件是否是 <code>0</code> 字节。如果是则返回 <code>0</code>。</li>
<li><code>-d</code>，如果路径是个目录，则返回 <code>1</code>，否则返回 <code>0</code>。</li>
</ul>
</li>
<li><p><code>text</code><br>将源文件输出为文本格式。允许的格式是 <code>zip</code> 和 <code>TextRecordInputStream</code>。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -text &lt;src&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>expunge</code><br>清空回收站。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -expunge</span><br></pre></td></tr></table></figure></li>
</ol>
<h5 id="DFSAdmin"><a href="#DFSAdmin" class="headerlink" title="DFSAdmin"></a><code>DFSAdmin</code></h5><p>运行一个 <code>HDFS</code> 的 <code>dfsadmin</code> 客户端。<code>DFSAdmin</code> 命令用来<strong>管理 <code>HDFS</code> 集群</strong>，这些命令只有管理员才能使用。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop dfsadmin [GENERIC_OPTIONS] [-report] [-safemode enter | leave | get | <span class="built_in">wait</span>] [-refreshNodes] [-finalizeUpgrade] [-upgradeProgress status | details | force] [-metasave filename] [-setQuota &lt;quota&gt; &lt;<span class="built_in">dirname</span>&gt;...&lt;<span class="built_in">dirname</span>&gt;] [-clrQuota &lt;<span class="built_in">dirname</span>&gt;...&lt;<span class="built_in">dirname</span>&gt;] [-<span class="built_in">help</span> [cmd]]</span><br></pre></td></tr></table></figure>
<p><small><code>bin/hadoop dfsadmin</code> 命令支持一些 <code>HDFS</code> 管理相关的操作。<code>bin/hadoop dfsadmin -help</code> 命令能列出所有当前支持的命令。</small></p>
<ol>
<li><p><code>report</code><br>报告 HDFS 的基本统计信息，当然有些信息也可以在 <code>NameNode Web</code> 服务首页看到。</p>
</li>
<li><p><code>safemode enter | leave | get | wait</code><br>虽然通常并不需要，但是管理员可以手动让 <code>NameNode</code> 进入或离开安全模式。</p>
</li>
<li><p><code>refreshNodes</code><br>重新读取 <code>hosts</code> 和 <code>exclude</code> 文件，更新允许连接到 <code>Namenode</code> 但是退出或加入的 <code>Datanode</code> 的集合。</p>
</li>
<li><p><code>finalizeUpgrade</code><br>删除上一次升级时制作的集群备份。终结 <code>HDFS</code> 的升级操作，<code>Datanode</code> 删除前一个版本的工作目录并且之后 <code>Namenode</code> 也这样做，这个操作会结束整个升级过程。</p>
</li>
<li><p><code>upgradeProgress status | details | force</code><br>请求当前系统的升级状态，状态的细节，或者强制升级操作进行。</p>
</li>
<li><p><code>metasave filename</code><br>保存 <code>Namenode</code> 的主要数据结构到 <code>hadoop.log.dir</code> 属性指定的目录下的文件中。</p>
</li>
<li><p><code>setQuota &lt;quota&gt; &lt;dirname&gt;...&lt;dirname&gt;</code><br>为每个目录设定配额，目录配额应该是一个长整型整数，强制限定了目录树下的名字个数。</p>
</li>
<li><p><code>clrQuota &lt;dirname&gt;...&lt;dirname&gt;</code><br>清除每一个目录的配额设定。</p>
</li>
</ol>
<h5 id="fsck"><a href="#fsck" class="headerlink" title="fsck"></a><code>fsck</code></h5><p><code>fsck</code> 命令来<strong>检查系统中的各种不一致状况</strong>，运行 <code>HDFS</code> 文件系统检查工具。这个命令被设计来报告各种文件存在的问题，比如文件缺少数据块或者副本数目不够，另外不同于在本地文件系统上传统的 <code>fsck</code> 工具，这个命令并不会修正它检测到的错误。一般来说 <code>NameNode</code> 会自动修正大多数可恢复的错误。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fsck [GENERIC_OPTIONS] &lt;path&gt; [-move | -delete | -openforwrite] [-files [-blocks [-locations | -racks]]]</span><br></pre></td></tr></table></figure>

<ol>
<li><p><code>&lt;path&gt;</code><br>检查的起始目录。</p>
</li>
<li><p><code>move</code><br>移动受损文件到 <code>/lost+found</code>。</p>
</li>
<li><p><code>delete</code><br>删除受损文件。</p>
</li>
<li><p><code>openforwrite</code><br>打印出写打开的文件。</p>
</li>
<li><p><code>files</code><br>打印出正被检查的文件。</p>
</li>
<li><p><code>blocks</code><br>打印出块信息报告。</p>
</li>
<li><p><code>locations</code><br>打印出每个块的位置信息。</p>
</li>
<li><p><code>racks</code><br>打印出 <code>data-node</code> 的网络拓扑结构。</p>
</li>
</ol>
<h5 id="jar"><a href="#jar" class="headerlink" title="jar"></a><code>jar</code></h5><p><strong>运行 <code>jar</code> 文件</strong>。可以将 <code>Map Reduce</code> 代码写到 <code>jar</code> 文件中，然后使用这个命令执行。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar &lt;jar&gt; [mainClass] args...</span><br></pre></td></tr></table></figure>

<h5 id="job"><a href="#job" class="headerlink" title="job"></a><code>job</code></h5><p><strong>用于和 <code>Map Reduce</code> 作业交互和命令</strong>。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop job [GENERIC_OPTIONS] [-submit &lt;job-file&gt;] | [-status &lt;job-id&gt;] | [-counter &lt;job-id&gt; &lt;group-name&gt; &lt;counter-name&gt;] | [-<span class="built_in">kill</span> &lt;job-id&gt;] | [-events &lt;job-id&gt; &lt;from-event-<span class="comment">#&gt; &lt;#-of-events&gt;] | [-history [all] &lt;jobOutputDir&gt;] | [-list [all]] | [-kill-task &lt;task-id&gt;] | [-fail-task &lt;task-id&gt;]</span></span><br></pre></td></tr></table></figure>

<ol>
<li><p><code>submit</code><br>提交作业。</p>
</li>
<li><p><code>status</code><br>打印 <code>map</code> 和 <code>reduce</code> 完成百分比和所有计数器。</p>
</li>
<li><p><code>counter</code><br>打印计数器的值。</p>
</li>
<li><p><code>kill</code><br>杀死指定作业。</p>
</li>
<li><p><code>events</code><br>打印给定范围内 <code>jobtracker</code> 接收到的事件细节。</p>
</li>
<li><p><code>history</code><br>打印作业的细节、失败及被杀死原因的细节。更多的关于一个作业的细节比如成功的任务，做过的任务尝试等信息可以通过指定 <code>[all]</code> 选项查看。</p>
</li>
<li><p><code>list</code><br>显示所有作业。<code>-list</code> 只显示将要完成的作业。</p>
</li>
<li><p><code>kill-task</code><br>杀死任务。被杀死的任务不会不利于失败尝试。</p>
</li>
<li><p><code>fail-task</code><br>使任务失败。被失败的任务会对失败尝试不利。</p>
</li>
</ol>
<h5 id="pipes"><a href="#pipes" class="headerlink" title="pipes"></a><code>pipes</code></h5><p><strong>运行 <code>pipes</code> 作业</strong>。用法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop pipes [-conf &lt;path&gt;] [-jobconf &lt;key=value&gt;, &lt;key=value&gt;, ...] [-input &lt;path&gt;] [-output &lt;path&gt;] [-jar &lt;jar file&gt;] [-inputformat &lt;class&gt;] [-map &lt;class&gt;] [-partitioner &lt;class&gt;] [-reduce &lt;class&gt;] [-writer &lt;class&gt;] [-program &lt;executable&gt;] [-reduces &lt;num&gt;]</span><br></pre></td></tr></table></figure>

<ol>
<li><p><code>conf</code><br>作业的配置。</p>
</li>
<li><p><code>jobconf</code><br>增加&#x2F;覆盖作业的配置项。</p>
</li>
<li><p><code>input</code><br>输入目录。</p>
</li>
<li><p><code>output</code><br>输出目录。</p>
</li>
<li><p><code>jar</code><br><code>Jar</code> 文件名。</p>
</li>
<li><p><code>inputformat</code><br><code>InputFormat</code> 类。</p>
</li>
<li><p><code>map</code><br><code>Java Map</code> 类。</p>
</li>
<li><p><code>partitioner</code><br><code>Java Partitioner</code></p>
</li>
<li><p><code>reduce</code><br><code>Java Reduce</code> 类。</p>
</li>
<li><p><code>writer</code><br><code>Java RecordWriter</code></p>
</li>
<li><p><code>program</code><br>可执行程序的 <code>URI</code>。</p>
</li>
<li><p><code>reduces</code><br><code>reduce</code> 个数。</p>
</li>
</ol>
<h4 id="安全模式"><a href="#安全模式" class="headerlink" title="安全模式"></a>安全模式</h4><p><code>NameNode</code> 启动时会从 <code>fsimage</code> 和 <code>edits</code> 日志文件中<strong>装载文件系统的状态信息</strong>，然后等待各个 <code>DataNode</code> 向它<strong>报告各自的数据块状态</strong>，这样 <code>NameNode</code> 在副本充足的情况下就不会过早地开始复制数据块。<br>在开始时这个阶段 <code>NameNode</code> 处于<strong>安全模式</strong>，其本质上是 <code>HDFS</code> <strong>集群的一种只读模式</strong>，此时集群不允许任何对文件系统或者数据块修改的操作，通常 <code>NameNode</code> 在开始阶段完成后会自动地退出安全模式。但若是需要可以通过 <strong><code>bin/hadoop dfsadmin -safemode</code></strong> 命令显式地将 <code>HDFS</code> 置于安全模式，另外 <code>NameNode</code> 首页也会显示当前是否处于安全模式。</p>
<hr>

<h3 id="常见组件介绍"><a href="#常见组件介绍" class="headerlink" title="常见组件介绍"></a>常见组件介绍</h3><h4 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a><code>Hive</code></h4><p>是基于 <code>Hadoop</code> 的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，通过类 <code>SQL</code> 语句快速实现简单的 <code>MapReduce</code> 统计，不必开发专门的 <code>MapReduce</code> 应用，并且十分适合数据仓库的统计分析。</p>
<h4 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a><code>Spark</code></h4><p>是专为大规模数据处理而设计的快速通用计算引擎。</p>
<h4 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a><code>HBase</code></h4><p>是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统，利用 <code>HBase</code> 技术可在廉价 <code>PC Server</code> 上搭建起大规模结构化存储集群。</p>
<h4 id="Pig"><a href="#Pig" class="headerlink" title="Pig"></a><code>Pig</code></h4><p>是一个基于 <code>Hadoop</code> 的大规模数据分析工具，它提供的 <code>SQL-LIKE</code> 语言叫 <code>Pig Latin</code>，该语言的编译器会把类 <code>SQL</code> 的数据分析请求转换为一系列经过优化处理的 <code>MapReduce</code> 运算。</p>
<h4 id="Sqoop-和-DataX"><a href="#Sqoop-和-DataX" class="headerlink" title="Sqoop 和 DataX"></a><code>Sqoop</code> 和 <code>DataX</code></h4><p><code>Sqoop</code> 是一个用来将 <code>Hadoop</code> 和关系型数据库中的数据相互转移的工具。它可以将一个关系型数据库中的数据导进到 <code>Hadoop</code> 的 <code>HDFS</code> 中，也可以将 <code>HDFS</code> 的数据导进到关系型数据库中。<br><code>DataX</code> 是阿里巴巴开源的离线数据同步工具，支持各种异构数据源之间高效的数据同步。</p>
<h4 id="Hue"><a href="#Hue" class="headerlink" title="Hue"></a><code>Hue</code></h4><p>是一个基于 <code>WEB</code> 的监控和管理系统，实现对 <code>HDFS</code>、<code>MapReduce/YARN</code>、<code>HBase</code>、<code>Hive</code>、<code>Pig</code> 的操作和管理。</p>
<h4 id="Ambari"><a href="#Ambari" class="headerlink" title="Ambari"></a><code>Ambari</code></h4><p>是一种基于 <code>Web</code> 的工具，支持 <code>Hadoop</code> 集群的供应、管理和监控。</p>
<hr>

<h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><hr>

<h3 id="个人备注"><a href="#个人备注" class="headerlink" title="个人备注"></a>个人备注</h3><p><strong>此博客内容均为作者学习所做笔记，侵删！</strong><br><strong>若转作其他用途，请注明来源！</strong></p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Hadoop/" rel="tag"># Hadoop</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/%E6%99%BA%E8%83%BD%E9%A3%8E%E6%8E%A7-%E9%A3%8E%E6%8E%A7%E6%A8%A1%E5%9E%8B%E4%BD%93%E7%B3%BB/" rel="prev" title="智能风控-风控模型体系">
      <i class="fa fa-chevron-left"></i> 智能风控-风控模型体系
    </a></div>
      <div class="post-nav-item">
    <a href="/Hadoop-HDFS/" rel="next" title="Hadoop-HDFS">
      Hadoop-HDFS <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AE%80%E4%BB%8B"><span class="nav-number">1.</span> <span class="nav-text">简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%8F%8A%E7%94%A8%E9%80%94"><span class="nav-number">2.</span> <span class="nav-text">架构设计及用途</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F"><span class="nav-number">2.1.</span> <span class="nav-text">文件系统</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%89%AF%E6%9C%AC%E5%A4%8D%E5%88%B6"><span class="nav-number">2.2.</span> <span class="nav-text">数据副本复制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%81%A5%E5%A3%AE%E6%80%A7"><span class="nav-number">2.3.</span> <span class="nav-text">健壮性</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%90%AD%E5%BB%BA%E9%9B%86%E7%BE%A4"><span class="nav-number">3.</span> <span class="nav-text">搭建集群</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="nav-number">3.1.</span> <span class="nav-text">环境准备</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%8B%E8%BD%BD%E5%8F%8A%E9%85%8D%E7%BD%AE"><span class="nav-number">3.2.</span> <span class="nav-text">下载及配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%8C%E6%AD%A5%E9%85%8D%E7%BD%AE"><span class="nav-number">3.3.</span> <span class="nav-text">同步配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%AF%E5%8A%A8-Namenode-%E8%8A%82%E7%82%B9"><span class="nav-number">3.4.</span> <span class="nav-text">启动 Namenode 节点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A3%80%E6%9F%A5%E6%98%AF%E5%90%A6%E6%88%90%E5%8A%9F"><span class="nav-number">3.5.</span> <span class="nav-text">检查是否成功</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4"><span class="nav-number">4.</span> <span class="nav-text">常用命令</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Web-%E6%8E%A5%E5%8F%A3"><span class="nav-number">4.1.</span> <span class="nav-text">Web 接口</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Shell-%E5%91%BD%E4%BB%A4"><span class="nav-number">4.2.</span> <span class="nav-text">Shell 命令</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#DFSSh"><span class="nav-number">4.2.1.</span> <span class="nav-text">DFSSh</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#DFSAdmin"><span class="nav-number">4.2.2.</span> <span class="nav-text">DFSAdmin</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#fsck"><span class="nav-number">4.2.3.</span> <span class="nav-text">fsck</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#jar"><span class="nav-number">4.2.4.</span> <span class="nav-text">jar</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#job"><span class="nav-number">4.2.5.</span> <span class="nav-text">job</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#pipes"><span class="nav-number">4.2.6.</span> <span class="nav-text">pipes</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%89%E5%85%A8%E6%A8%A1%E5%BC%8F"><span class="nav-number">4.3.</span> <span class="nav-text">安全模式</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E8%A7%81%E7%BB%84%E4%BB%B6%E4%BB%8B%E7%BB%8D"><span class="nav-number">5.</span> <span class="nav-text">常见组件介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Hive"><span class="nav-number">5.1.</span> <span class="nav-text">Hive</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Spark"><span class="nav-number">5.2.</span> <span class="nav-text">Spark</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HBase"><span class="nav-number">5.3.</span> <span class="nav-text">HBase</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Pig"><span class="nav-number">5.4.</span> <span class="nav-text">Pig</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Sqoop-%E5%92%8C-DataX"><span class="nav-number">5.5.</span> <span class="nav-text">Sqoop 和 DataX</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hue"><span class="nav-number">5.6.</span> <span class="nav-text">Hue</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Ambari"><span class="nav-number">5.7.</span> <span class="nav-text">Ambari</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%95%E7%94%A8"><span class="nav-number">6.</span> <span class="nav-text">引用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%AA%E4%BA%BA%E5%A4%87%E6%B3%A8"><span class="nav-number">7.</span> <span class="nav-text">个人备注</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="vgbhfive"
      src="https://i.loli.net/2019/12/10/JF3dKDSkZoPz7h6.jpg">
  <p class="site-author-name" itemprop="name">vgbhfive</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">148</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">50</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/vgbhfive" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;vgbhfive" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:vgbhfive@foxmail.com" title="E-Mail → mailto:vgbhfive@foxmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://vgbhfive.com/" title="Web-Site → https:&#x2F;&#x2F;vgbhfive.com" rel="noopener" target="_blank"><i class="fab fa-chrome fa-fw"></i>Web-Site</a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        
  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">陕ICP备20002937号-1 </a>
  </div>

<div class="copyright">
  
  &copy; 2016 – 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">vgbhfive</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '2ff0dea213e4c7c0bbcc',
      clientSecret: '7f3d808240b513b00a1dbf20d725809acc316b67',
      repo        : 'vgbhfive.github.io',
      owner       : 'vgbhfive',
      admin       : ['vgbhfive'],
      id          : '37fbe1e605380efe84872bdb963e9888',
        language: 'zh-CN',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

</body>
</html>
