<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Vgbhfive&#39;s Blog</title>
  
  
  <link href="https://blog.vgbhfive.cn/atom.xml" rel="self"/>
  
  <link href="https://blog.vgbhfive.cn/"/>
  <updated>2023-01-01T15:27:16.556Z</updated>
  <id>https://blog.vgbhfive.cn/</id>
  
  <author>
    <name>vgbhfive</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>智能风控-风控模型体系</title>
    <link href="https://blog.vgbhfive.cn/%E6%99%BA%E8%83%BD%E9%A3%8E%E6%8E%A7-%E9%A3%8E%E6%8E%A7%E6%A8%A1%E5%9E%8B%E4%BD%93%E7%B3%BB/"/>
    <id>https://blog.vgbhfive.cn/%E6%99%BA%E8%83%BD%E9%A3%8E%E6%8E%A7-%E9%A3%8E%E6%8E%A7%E6%A8%A1%E5%9E%8B%E4%BD%93%E7%B3%BB/</id>
    <published>2022-11-25T14:00:04.000Z</published>
    <updated>2023-01-01T15:27:16.556Z</updated>
    
    <content type="html"><![CDATA[<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p><strong>风控模型</strong>是风控系统的核心，应用模型进行风险决策是识别风险的主要途径，也是控制风险的重要方法。</p><span id="more"></span><p>在信贷风控领域中 <strong>模型</strong>主要是指预测风险的方法，通常以数学公式或行数的方式存在。<br>这其中<strong>模型</strong>和<strong>算法</strong>不可混为一谈，算法通常是指各种数学、统计或人工智能方法，而模型是指基于这些方法得到的具体实例；因此才会出现使用了某种算法构建多个风险模型。假设两者相比较的话，可以将算法比作<strong>类</strong>，而模型则是 <strong>实例对象</strong>。</p><p>构建风控模型并不是 <em>必须</em> 使用机器学习算法，如策略人员基于人工经验和统计分析，利用 <em>评分卡模型</em> 来汇总各类风险指标，赋予各类风险指标一个分数之后，最后汇总即可。但这种方法也存在弊端，即无法处理更多维度的数据，也很难处理不同维度数据之间的关联信息，评估准确性较低、局限性很大。因此随着技术的发展，机器学习方法逐渐成为主要的建模方法。</p><p><strong>机器学习</strong>是一种从历史数据中学习潜在规律，同时预测未来行为的方法。其核心的三要素：<strong>数据</strong>、<strong>模型</strong>、<strong>算法</strong>。其中数据和算法是搭建机器学习模型的 <em>必要条件</em>，每种算法都包含多个待定的参数或结构，模型是算法在数据上运算得到特定的参数或结构的 <em>结果</em>。<br><img src="https://s2.loli.net/2022/12/01/fRUOPIwSEZQNMJp.png" alt="risk_3_1.jpg"><br>其中根据数据集中是否已知样本标签，机器学习任务又可以分为：<strong>有监督学习</strong>是指从有标签的训练数据中学习；<strong>无监督学习</strong>是指从无标签的训练数据中学习。<br><small>有标签的训练数据是指每个训练样本都包含输入和期望的输出；相反无标签则是指每个训练样本只包含输入不包含输出。</small></p><p>采用多种机器学习算法搭建风控模型的主要步骤都是相同的，主要包含以下几个步骤：</p><ul><li>问题定义</li><li>样本的选择与划分</li><li>模型架构设计</li><li>数据准备与描述分析</li><li>数据清洗</li><li>特征选择</li><li>模型训练与效果评估</li><li>部署上线</li><li>模型监控与异常处理</li><li>模型调优</li></ul><p><img src="https://s2.loli.net/2022/12/01/k7Jb3ACYBSRyLFK.png" alt="risk_3_2.jpg"></p><hr><h3 id="开发方法论"><a href="#开发方法论" class="headerlink" title="开发方法论"></a>开发方法论</h3><p>开发好样本是开发好模型的基础。构建好样本是指从项目需求中<strong>定义问题</strong>、<strong>定义标签</strong>、<strong>选择合适的建模数据集</strong>以及<strong>分析和预处理数据</strong>的过程。<br>构建好模型是指在经过预处理的数据中进行<strong>特征选择</strong>、<strong>特征提取</strong>、<strong>模型训练</strong>、<strong>分数转化</strong>和<strong>效果评估</strong>。</p><hr><h3 id="开发方法论-立项分析"><a href="#开发方法论-立项分析" class="headerlink" title="开发方法论-立项分析"></a>开发方法论-立项分析</h3><h4 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h4><p>问题定义旨在明确项目的背景和目标，根据背景和目标将业务问题转化为机器学习建模问题，包括定义预测目标、设计模型方案等。<br>在实际业务中开始分析目标时需要先了解<strong>预测对象粒度</strong>、<strong>标签定义</strong>和<strong>细分客群</strong>。</p><ol><li><p>预测对象粒度<br>在实际业务中会遇到不同层次的问题，基于不同层次的问题，需要将预测对象定义为不同的粒度。因此在实际业务中，需要根据业务模式和模型应用策略来选择合适的粒度进行建模。</p><ul><li><strong>渠道粒度</strong>，某些场景下借款申请人来自于同一个渠道，即一个渠道一条记录。</li><li><strong>客户粒度</strong>，借款人存在多笔借款，从借款人角度考虑风险即任何一笔借款出现逾期都表示风险事件，即一个人是一条记录。</li><li><strong>借款粒度</strong>，借款人的每次申请借款考虑风险，该笔借款出现逾期则表现出风险事件，即一次借款就是一条记录。</li><li><strong>还款粒度</strong>，每个借款人得到每一次借款可能都有不同的还款期限，预测每笔还款是否出现风险，即一次还款就是一条记录。</li></ul></li><li><p>标签定义<br>风控模型用来预测未来的风险是典型的<strong>有监督学习模式</strong>，因此需要定义<strong>样本标签</strong>。<br> <strong>标签</strong>是模型所要预测的结果，可以是二分类结果，例如“好”&#x2F;“坏”、“响应”&#x2F;“不响应”等；也可以是连续变量，例如收益、损失等。风险评估模型通常用来预测未来的表现是好是坏，其中标签定义需要明确的是在什么时间点预测未来多久发生的什么事件。<br>观测点前后分别是<strong>观察窗口</strong>和<strong>表现窗口</strong>。</p><ul><li><strong>观察窗口</strong>，用来观察客户行为的时间区间。观察窗口也称为观察期。</li><li><strong>表现窗口</strong>，用来考察客户的表现，从而确定标签定义的时间区间。表现窗口也称为表现期。</li></ul><p> 在风险标签定义中，对于如何确定好坏程度和表现窗口的长度，需要结合<strong>滚动率分析（<code>roll rate analysis</code>）</strong>和<strong>账龄分析（<code>vintage analysis</code>）</strong>。</p><ul><li><strong>滚动率分析</strong>，通过滚动率分析来确定客户的“好坏”程序。滚动率是指客户从某个观测点之前的一段时间的逾期状态向观测点之后的一段时间的逾期状态转化的比例。</li><li><strong>账龄分析</strong>，信贷行业经常使用 <code>Vintage</code> 曲线分析账户的成熟期、变化规律等。<code>Vintage</code> 曲线是根据账龄绘制的不同时间放款样本的逾期率变化曲线。逾期率有金额逾期和账单逾期两种口径。</li></ul><p> 综上所述，滚动率分析用于分析客户的“好坏”程度；账龄分析用于确定合适的表现期，可以尽可能多地覆盖“坏”客户。</p></li><li><p>细分客群<br>在建模任务中如果客群差异较大则需要进一步<strong>细分客群</strong>。根据不同产品拆分客群时，不同的<strong>进件渠道</strong>、<strong>借款期数</strong>、<strong>区域</strong>和<strong>借款金额</strong>等划分客群。除此之外还可以采用聚类等无监督学习方法划分客群。<br>至此细分客群建模还需要满足下列条件：</p><ul><li>细分客群之间的风险水平差异较大。</li><li>细分客群可以获得的特征维度不同。</li><li>每个细分客群的样本足够多。</li></ul><p> 通过细分客群建模可以使模型更加专注于细分客群风险模式的学习，从而提高模型效果。不过细分客群建模也存在弊端：细分客群建模会导致模型数量增多，需要投入的资源和时间增多，维护成本增加；细分客群将总样本分散到各个客群中，相比总样本量细分客群样本量减少，特别是细分客群的<strong>“坏”</strong>样本量不多，反而会降低模型的预测能力。</p></li></ol><h4 id="样本的选择与划分"><a href="#样本的选择与划分" class="headerlink" title="样本的选择与划分"></a>样本的选择与划分</h4><ol><li><p>样本选择<br>样本选择是指从业务数据选择部分合适的样本进行模型开发。<br>风控模型是一种预测模型，保证模型良好的预测效果的前提是客户未来的行为和过去相似，因此才可以从过去的数据中学习规律并预测未来的表现。其中选取的建模样本需要把握<strong>建模样本必须能够代表总体，与未来模型使用场景下的样本差异尽可能小</strong>，具体体现为以下四点：<strong>代表性</strong>；<strong>充分性</strong>；<strong>时效性</strong>；<strong>排除性</strong>。</p></li><li><p>样本集划分<br> <strong>数据是模型搭建的基础</strong>。<br>在模型开发过程中会将一部分数据划分用于训练模型，另一部分数据划分为验证模型效果。总体数据可以划分为<strong>训练集</strong>、<strong>验证集</strong>和<strong>测试集</strong>，其中训练集用于训练模型，验证集用来模型调参、训练过程中的参数选择或者模型选择，测试集用来验证模型最终表现（通常选用靠近当前时间的样本作为测试集，也称 <code>OOT（Out of Time sample）</code> 样本）。典型的训练样本、验证样本、<code>OOT</code> 样本划分比例是 <code>7:2:1</code>。<br><small>在特殊并且样本较少时，为了让更好的样本参与模型训练，可以将验证样本取消，保留训练样本和 <code>OOT</code> 样本，训练时采用交叉验证的方式进行模型参数选择。另外避免出现异常，可以先 <em>空跑</em> 一段时间观察模型情况。</small></p></li></ol><h4 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h4><p>在明确问题定义、确定样本和样本集划分之后，模型搭建的基本任务已经清晰，关于如何更好的预测目标，需要首先从宏观上考虑模型的架构。<br>从模型数据源维度考虑，模型架构可以分为：</p><ul><li>单一模型架构<br> 不区分数据源，将所有数据源特征放在一起进行建模，输出最终模型。</li><li>多子模型融合架构<br>将不同维度的数据源划分为若干个集合，先建立子模型，再将子模型进行二次融合，生成最终模型。<br><img src="https://s2.loli.net/2022/12/22/vb27ckLozjX4q6Z.png" alt="risk_3_6.jpg"></li></ul><p>模型架构除了可以从数据源维度进行划分之外，还可以：</p><ul><li>从目标逾期标签定义或表现期长短的角度，分别建立 <code>DPD10</code> 逾期模型、<code>DPD60</code> 逾期模型，长表现期子模型和短表现期子模型等。</li><li>结合客群细分，建立基于不同细分客群的子模型，再进行二次融合。</li><li>采用不同算法建立不同子模型，再进行二次融合。</li></ul><p>在实际业务条件下，面对的可变条件太多、数据量的大小、模型调参方法的差异和特征维度的差异都会导致模型结果出现偏差，因此在同等条件下可以采用<strong>如无必要，勿增实体</strong>的原则，即采用最简单的方案。</p><hr><h3 id="开发方法论-训练开发"><a href="#开发方法论-训练开发" class="headerlink" title="开发方法论-训练开发"></a>开发方法论-训练开发</h3><h4 id="数据的准备和描述"><a href="#数据的准备和描述" class="headerlink" title="数据的准备和描述"></a>数据的准备和描述</h4><ol><li><p>数据准备<br>数据准备是将构造完整的建模数据集，数据集的每一列为一个特征。风控模型中的特征是根据预测目标的粒度，基于底层的原始数据，通过汇总等方式加工而成的。而由于底层数据的不同，特征一般会分为不同的模块，每个特征模块包含若干个特征。</p><p> 在数据准备阶段将可用的特征模块逐一按照样本选择的范围和每个样本观测点计算出对应的特征。通常将事后计算以前某个时间点的特征的行为称为<strong>回溯</strong>。特别的需要确保特征数据是观测点时刻可以获取的当时状态，这样才能保证模型在应用时才能获取到相同的特征。当原始数据已经被修改，无法追溯到当时的特征时，特征就不能 <em>回溯</em>，因此也就无法使用此特征。</p><p> 特征无法回溯而造成特征值中包含观测点之后的信息，这被称为<strong>特征穿越</strong>或<strong>信息泄露</strong>。这种问题通常导致的后果就是特征效果和模型效果异常好，当真实场景使用时并不能得到相同的效果。因此<strong>特征穿越</strong>问题需要尽可能在数据准备阶段尽力排除，排除此问题共有以下三种方法：</p><ul><li>回溯数据与线上实时计算数据的一致性检查。</li><li>单个变量与预测标签的效果指标分析。</li><li>单个样本特征计算逻辑分析。</li></ul></li><li><p>数据描述<br>数据描述即<strong>探索性数据分析（<code>Exploratory Data Analysis, EDA</code>）</strong>是指对特征进行统计分析，统计每个特征的<strong>缺失率</strong>、<strong>唯一值个数</strong>、<strong>最大值</strong>、<strong>最小值</strong>、<strong>平均值</strong>和<strong>趋势性变化</strong>等指标，使模型开发人员对数据集有清晰、细致的了解。<br>数据描述的目的在于<strong>了解特征分布，确认数据质量</strong>，在得到所有特征的统计指标后，需要首先确认数据质量，分析每个指标是否合理，而非直接进行数据清洗。</p><p> 数据问题通常包含两类：</p><ul><li>由于非正常因素导致的异常，如系统故障导致的数据缺失。</li><li>业务调整导致的异常，业务调整对某些特征是否影响的，会造成特征分布偏移。</li></ul></li></ol><h4 id="数据预处理（清洗）"><a href="#数据预处理（清洗）" class="headerlink" title="数据预处理（清洗）"></a>数据预处理（清洗）</h4><p>在进行特征选择和构建模型之前需要对数据进行预处理，使得数据能够全面反映全体样本信息，以适用于机器学习模型。<br>数据预处理包含<strong>异常值处理</strong>、<strong>特征缺失值处理</strong>、<strong>特征无量纲化</strong>、<strong>连续特征离散化</strong>、<strong>类别特征数值化</strong>和<strong>特征交叉组合</strong>。</p><ol><li><p>异常值处理<br>在实际业务中由于种种因素，通常会遇到<strong>异常值</strong>，如果不处理这些异常值将会导致后续数据分析和模型训练出现严重误差。</p><ul><li><p>异常值检测<br> 异常值检测主要有三种方法：</p><ul><li>基于统计的方法。基于统计的方法一般会构建一个概率分布模型，并计算对象符合该模型的概率，把具有低概率的对象视为异常点。</li><li>基于聚类的方法。基于聚类算法将训练样本划分为若干类，如果某一个类的样本数很少，而且类中心和其他类的距离都很远，那么这个类中的样本极有可能就是异常点。</li><li>专业的异常点检测算法。孤立森林（<code>lsolation Forest</code>）是一种应用官方的异常点检测算法。</li></ul></li><li><p>异常值处理<br> 在检测出异常值后，一般常见的处理方式有两种：</p><ul><li>直接删除包含异常值的样本。</li><li>结合特征含义选择置空异常值，或者填充为其他值。</li></ul><p> 另外有两种<strong>“异常”</strong>是无法通过技术手段检测出来的，需要结合具体业务含义识别</p><ul><li>周期性变化的特征。这类特征会严重影响模型的稳定性，应予以剔除。</li><li>具有明显缺陷的特征，如有些埋点后续不会再有，相关特征应予以剔除。</li></ul></li></ul><p> 需要强调的是处理异常值必须谨慎。通过算法筛选出的异常值是否真正异常，需要从业务含义角度再次确认，避免将正常数据过滤掉。</p></li><li><p>特征缺失值处理<br>在处理<strong>特征缺失值</strong>之前，需要先判断缺失的原因。在实际业务中，出现缺失的原因有两种：</p><ul><li>非正常缺失。是指由于原始数据存储、数据接口出现异常而导致的回溯的特征缺失。</li><li>正常缺失。对于需要客户授权的数据，部分客户拒绝会导致数据缺失；另外特殊的特征计算也会造成特征缺失。特征缺失值是否需要填充，需要根据建模时使用的算法综合考虑。<ul><li>使用线性回归算法时，可以根据特征含义使用均值、众数和中位数等填充。</li><li>在使用逻辑斯谛回归建立传统评分卡模型时，由于模型训练前会对特征进行分箱处理，因此会将特征缺失值单独作为一箱。</li><li>使用决策树建模时，例如 <code>XGBoost</code> 算法会自动处理特征缺失值，因此不需要填充。</li></ul></li></ul><p> 不同缺失的处理方案如下：</p></li></ol><p><img src="https://s2.loli.net/2022/12/29/kpjbL4DmU7XnZ6C.png" alt="risk_3_7.jpg"></p><ol start="3"><li><p>特征无量纲化<br>特征无量纲化主要是通过特征的标准化将<strong>特征“缩小”到同一量纲</strong>。<br>对于建模特征，如果特征的单位或大小相差较大，或者特征的方差比其他几个特征高几个数量级，那么就很容易影响目标结果，使得线性模型无法学习其他特征，此时有必要进行特征标准化处理。常见的标准化处理方式如下：</p><ul><li><code>max-min</code> 标准化<br> <strong><code>max-min</code> 标准化</strong>也称为“归一化”，是通过对原始特征进行变换，把特征值映射到 <code>[0, 1]</code>。其中 <code>Xmax</code> 表示特征最大值，<code>Xmin</code> 表示特征最小值，<code>X</code> 表示原始特征值，变换公式如下： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X&#x27; = (X - Xmin) / (Xmax - Xmin)</span><br></pre></td></tr></table></figure></li><li><code>z-score</code> 标准化<br> <strong><code>z-score</code> 标准化</strong>是常见的特征预处理方式，线性模型在训练数据之前基本都会进行 <code>z-score</code> 标准化。对原始特征进行变换可以把特征分布变换到均值为 <code>0</code>，标准差为 <code>1</code>，变换公式如下所示，其中 <code>u</code> 为特征均值，<code>a</code> 为特征标准差。 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X&#x27; = (X - u) / a</span><br></pre></td></tr></table></figure></li></ul><p> <small>在使用 <code>max-min</code> 标准化时，如果测试集里的特征存在小于 <code>Xmin</code> 或大于 <code>Xmac</code> 的值，就会导致 <code>Xmin</code> 和 <code>Xmax</code> 发生变化。</small></p></li><li><p>连续特征离散化<br>连续特征离散化也称特征分箱，是指将<strong>连续属性的特征进行分段，使其变成一个个离散的区间</strong>。<br>在使用逻辑斯谛回归建立风控评分卡模型时，通常会对来连续特征进行离散化分箱，离散化后的特征对异常值有很强的<strong>鲁棒性</strong>，降低模型过拟合的风险，模型会更加稳定。此外单个特征离散化为多个分箱之后，再对分箱进行数值转换（例如 <code>WOE</code> 转换），此过程可以对非线性的关系进行线性转化，提高线性模型的表达能力。当建模的样本量较少时，离散化特征就非常重要，经过离散化后可以丢弃数据的细节信息，有效降低过拟合风险。<br>常见的特征分箱如下：</p><ul><li><strong>等频分箱</strong>是指分箱后，每个箱内的样本量相等。等频分箱能够确保每箱有足够的样本量，更有统计意义且在实际种应用广泛。</li><li><strong>等距分箱</strong>是指按照相同宽度将特征值分为若干等份，各箱的特征值跨度相同。等距分箱的缺点是受到异常值的影响比较大，各箱之间的样本量不均衡，甚至有可能出现箱的样本量为 <code>0</code> 的情况。</li><li><strong>卡方分箱</strong>是依赖于卡方校验的分箱方法，其基本思想是判断相邻的两个区间是否有分布差异，基于卡方统计量的结果进行自下而上的合并，直到满足分箱的终止条件为止。终止条件包括分箱个数和卡方阈值。</li><li><strong>决策树分箱</strong>是指利用决策树算法，根据树节点的分割点，将特征划分为不同的分箱区间，属于有监督的分箱方法。</li></ul><p> <small>特征是否需要分箱是跟建模算法有关。风控评分卡模型需要很强的业务可解释性，所以在使用逻辑斯谛回归建模时，通常需要分箱处理；然而在使用 <code>XGBoost</code>、<code>LightGBM</code> 等机器学习算法时，通常是不需要分箱。</small></p></li><li><p>类别特征离散化<br>逻辑斯谛回归和支持向量机等算法要求所有特征是<strong>数值型变量</strong>，但在实际业务中会存在部分特征是<strong>类别型变量</strong>（例如性别、身份和职业等）。类别型变量可以分为两种：第一种是没有任何先后顺序或等级关系的<strong>标称类别变量（<code>nominal category variable</code>）</strong>，例如性别、省份等；第二种则是有先后顺序或等级关系的<strong>有序类别型变量（<code>ordinal category variable</code>）</strong>，例如学历、满意程度等。<br>处理类别特征通常采用的方式是<strong>编码</strong>。编码分为两种：一种是<strong>无监督编码方式</strong>，主要有<strong>序数编码</strong>和 <strong><code>one-hot</code> 编码</strong>；另一种则是<strong>有监督编码方式</strong>，主要有 <strong><code>Binary</code> 编码</strong>、**<code>Hashing</code> 编码<strong>、</strong><code>CatBoost</code> 编码**等。<br><small>当特征类别取值较多时，通常是先进行分箱，合并一些类别后再对分箱进行编码处理。</small><br>无监督编码方式：</p><ul><li>序数编码<br>   <strong>序数编码（<code>ordinal encoding</code>）</strong>是一种简单的编码方式，直接对特征中的每个类别设置一个标号，<strong>将非数值特征转化为数值特征</strong>。一个有 <code>N</code> 种类别的特征可以与 <code>[0, N-1]</code> 中的整数一一对应。<br>   <small>需要注意的是，序数编码只是将类别型变量更换了一种表达方式，其本质上还是离散的，数值化后的大小关系没有实际意义。</small></li><li><code>one-hot</code> 编码<br>   <code>one-hot</code> 编码（<code>one-hot encoding</code>）也称“独热”编码，是指<strong>对每一种分类单独创建一个列，用 <code>0</code> 或 <code>1</code> 填充</strong>。<br>   <img src="https://s2.loli.net/2022/12/29/NMKFmT1eAP6fxSI.png" alt="risk_3_8.jpg"><br>   <small>需要注意的是，对于类别特别多的类别型变量，<code>one-hot</code> 编码会导致特征维度激增，特征更加稀疏，影响模型效果。</small></li></ul><p> 有监督编码方式：</p><ul><li>目标编码<br> <strong>目标编码（<code>target encoding</code>）</strong>也称<strong>均值编码</strong>，是一种有效表示类别型变量的方法。<br> 该方法将<strong>类别型变量的值映射为和标签 <code>y</code> 相关的统计指标</strong>，属于有监督编码方式。具体是将特征中的每个字替换为该类别的标签 <code>y</code> 的均值。但该方法严重依赖因变量的分布，会导致大大减少生成编码后特征的数量。<ul><li>在 <em>分类模型</em> 中，标签 <code>y</code> 的取值一般只有 <code>0</code> 和 <code>1</code> 两种，目标编码公式如下： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X&#x27; = p(y=1 | X=Xtarget)</span><br></pre></td></tr></table></figure> 计算特征值等于类别 <code>Xtarget</code> 时 <code>y=1</code> 的概率。</li><li>在 <em>回归模型</em> 中，标签 <code>y</code> 是连续数值，目标编码公式如下： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X&#x27; = sum(y | X=Xtarget) / sum(X=Xtarget)</span><br></pre></td></tr></table></figure> <code>y | X=Xtarget</code> 表示特征值等于类别 <code>Xtarget</code> 是 <code>y</code> 的取值。</li></ul></li><li><code>WOE</code> 编码<br> <strong><code>WOE</code>（<code>Weight of Evidence</code>，证据权重）</strong>是针对对原始特征的一种编码形式。<br> <strong><code>WOE</code> 编码（<code>WOE encoding</code>）</strong>适用于<strong>二分类问题的特征预处理</strong>。具体做法是使用特征中每种类别 <code>y=1</code> 的概率和 <code>y=0</code> 的概率的比值的对数替代每种类别的特征值。计算公式如下： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WOEi = ln(p(Badi)/p(Goodi)) = ln((Badi/BadT)/(Goodi/GoodT)) = ln(Badi/BadT) - ln(Goodi/GoodT)</span><br></pre></td></tr></table></figure> 其中 <code>Badi</code> 为类别 <code>i</code> 中标签为 <code>1</code> 的样本数，<code>Goodi</code> 为类别 <code>i</code> 中标签为 <code>0</code> 的样本数，<code>BadT</code> 为所有样本中标签为 <code>1</code> 的样本数，<code>GoodT</code> 为所有样本中标签为 <code>0</code> 的样本数。因此 <code>WOE</code> 可以表示<strong>“当前类别中坏样本占所有坏样本的比例”</strong>和<strong>“当前类别中好样本占所有好样本的比例”</strong>的差异。<br> <small><code>WOE</code> 编码不仅可以处理类别特征，也可以处理连续特征。尤其是在评分卡模型中，使用逻辑斯谛回归算法拟合特征与逾期率的关系，首先会对连续特征进行分箱，然后利用各箱的 <code>WOE</code> 值代替特征值。</small></li></ul></li><li><p>特征交叉组合<br>特征交叉组合是数据特征的一种处理方式，该方式可以<strong>增加特征的维度</strong>，组合的特征能够反映更多的非线性关系。<br><small>实践中，通常会对类别特征进行组合；而对于连续特征，可以先进行分箱，再进行组合，也可以直接进行特征交叉衍生。</small></p><ul><li>离散特征分类组合<br>   对于<strong>类别型变量</strong>特征的交叉组合，特征 <code>A</code> 取值类别有 <code>m</code> 种，特征 <code>B</code> 取值类别有 <code>n</code> 种，可以通过<strong>笛卡尔积</strong>的方式进行特征组合，可以重新得到组合后的 <code>m*n</code> 个组合特征。</li><li>连续特征交叉衍生<br> 特征交叉衍生的方式有很多种，常用的方式有：<ul><li>利用数值型特征之间的<strong>加、减、乘、除操作</strong>得到新特征；</li><li>对已选定特征进行<strong>奇异值分解（<code>SVD</code>）</strong>，将奇异值作为新特征；</li><li>根据已选特征进行<strong>聚类</strong>，将所在类别的平均目标值或出现最多的值作为新特征，或者将所在类别与其他类别的距离作为新特征等；</li><li>此外还可以利用<strong>深度学习技术衍生新特征</strong>，利用神经网络中某层的数据作为新特征也是一种思路。</li></ul></li></ul><p> <small>特征交叉组合会导致特征维度激增，组合后的特征因此可能会很稀疏，因此在实践中，需要根据特征含义组合出具有业务含义的特征。</small></p></li></ol><h4 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h4><p>特征选择（<code>feature selection</code>）是指选择能够使模型获得最佳性能的特征子集。特征的必要性包括：</p><ul><li><p>特征池中的特征并非都对模型有益，如果选取不稳定的的特征训练模型，那么最终生成的模型的稳定性较差。</p></li><li><p>线性模型要求特征间不能多重共线性，因此需要选择无严重共线性的特征建模。</p></li><li><p>选取尽可能对模型有增益的特征，剔除无用特征，从而降低特征维度缩短模型训练时间和减少对机器资源的损耗。</p><p> 特征选择一般都是反复迭代、验证，并且和模型训练过程循环进行，最终可以得到性能优异的模型。特征选择可以从<strong>基于特征属性选择</strong>、<strong>基于特征效果选择</strong>和<strong>基于特征稳定性</strong>三个方面。</p></li></ul><p><img src="https://s2.loli.net/2022/12/04/XzvGq4ukioealpN.png" alt="risk_3_3.jpg"></p><h5 id="基于特征属性选择"><a href="#基于特征属性选择" class="headerlink" title="基于特征属性选择"></a>基于特征属性选择</h5><p>基于特征属性选择特征，不需要任何标签信息，直接根据特征值分布或特征之间的关系进行选择，计算速度快，一般用于特征初筛。主要方法有<strong>缺失率选择法</strong>、<strong>变异系数选择法</strong>、<strong>相关性选择法</strong>和<strong>多重共线性选择法</strong>。</p><ol><li><p>缺失率选择法<br>一般情况下，当特征缺失率超过 <code>95%</code> 时就不再适合参与建模，首先要做的就是剔除特征。而当特征缺失率不超过 <code>95%</code> 时，可以采用缺失值处理方法进行处理。对于缺失率阈值，可以根据具体业务场景灵活调整。</p></li><li><p>变异系数选择法<br> <strong>变异系数（<code>coefficient of variation</code>）又称 <em>离散系数</em></strong> 是概率分布离散程度的一个归一化量度，其定义为标准差与均值之比。<br>变异系数反映了特征分布的离散程度，相比方差，变异系数是一个无量纲量，因此在比较两组量纲不同或均值不同的数据时，应该用变异系数而不是标准差。特征选择过程中会首先过滤变异系数为 <code>0</code> 的特征。<br><small>如果某个特征的变异系数很小，则表示样本在这个特征上没有差异，可能特征中的大多数值都是一样的，甚至整个特征取值全部相同。</small></p></li><li><p>相关性选择法<br>相关性是衡量<strong>两个特征之间依赖关系</strong>的指标。度量特征相关性的指标有很多，常见的有以下三种：</p><ul><li><strong><code>Person</code> 相关系数</strong><br>  用来度量特征的 <em>线性相关性</em>，取值范围为 <code>[-1, 1]</code>，大于 <code>0</code> 表示两个特征正相关，小于 <code>0</code> 表示两个特征负相关，等于 <code>0</code> 则表示两个特征非线性相关。</li><li><strong><code>Spearman</code> 相关系数</strong><br>  用来度量特征 <em>单调相关性</em>，取值范围为 <code>[-1, 1]</code>，大于 <code>0</code> 表示两个特征正相关，小于 <code>0</code> 表示两个特征负相关，等于 <code>0</code> 则表示两个特征非单调相关。</li><li><strong><code>Kendall</code> 相关系数</strong><br>  用来度量特征 <em>有序分类特征相关性</em>，取值范围为 <code>[-1, 1]</code>，大于 <code>0</code> 表示两个特征正相关，小于 <code>0</code> 表示两个特征负相关，等于 <code>0</code> 则表示两个特征排名独立。</li></ul><p>  <small>逻辑斯谛回归等算法要求特征之间不得具有很强的相关性，否则会导致无法用特征系数解释最终模型的入模特征（即模型使用的特征）与目标变量之间的关系。</small></p></li><li><p>多重共线性选择法<br>多重共线性描述的是<strong>一个自变量与其他自变量（可以多个）</strong>之间的完全线性关系。<strong>方差膨胀系数（<code>Variance Inflation Factor, VIF</code>）</strong>是一种衡量共线性程度的常用指标，表示回归系数估计量的方差与假设特征间不线性相关时的方差的比值。<br><code>VIF</code> 计算公式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">VIF = 1 / (1 - R^2)</span><br></pre></td></tr></table></figure><p> <code>R^2</code> 是某个特征对其余特征做回归分析的复相关系数。<code>VIF</code> 越大，该特征与其他特征的关系越复杂，多重共线性越严重。<code>VIF &lt; 10</code> 则认为不存在多重共线性；<code>10 &lt;= VIF &lt; 100</code> 则认为存在较强的多重共线性；<code>VIF &gt;= 100</code> 则认为存在严重的多重共线性。</p></li></ol><h5 id="基于特征效果选择"><a href="#基于特征效果选择" class="headerlink" title="基于特征效果选择"></a>基于特征效果选择</h5><ol><li><p><code>IV</code> 选择<br> <strong><code>IV</code>（<code>Information Value</code>，信息价值）</strong>是衡量特征预测能力的关键指标。<code>IV</code> 和 <code>WOE</code> 之间的关系可以描述为：<code>WOE</code> 描述了特征和目标变量之间的关系；<code>IV</code> 用来衡量这种关系的强弱程度。<br><code>WOE</code> 分析特征各个分箱对于目标变量的预测能力，<code>IV</code> 用来反映特征的总体预测能力。<code>IV</code> 的计算公式即在第 <code>i</code> 箱 <code>WOE</code> 的基础上乘以系数，该系数表示该分箱坏样本比例和好样本比例的差。</p><table><thead><tr><th><code>IV</code> 范围</th><th>描述</th></tr></thead><tbody><tr><td>iv &lt; 0.02</td><td>无预测能力，需放弃</td></tr><tr><td>[0.02, 0.1)</td><td>较弱的预测能力</td></tr><tr><td>[0.1, 0.3)</td><td>预测能力一般</td></tr><tr><td>[0.3, 0.5)</td><td>预测能力较强</td></tr><tr><td>iv &gt; 0.5</td><td>预测能力极强，需检查</td></tr></tbody></table></li><li><p>卡方校验<br>卡方校验是一种以<strong>卡方分布</strong>为基础的检验方法，主要用于类别变量，根据样本数据推断总体分布与期望分布是否有显著差异，或者推断两个类别变量是否相关或相互独立。其原假设为：观察频数与期望频数没有差别。</p></li><li><p>包裹法</p><ul><li><p>逐步回归<br>   <strong>逐步回归（<code>stepwise regression</code>）</strong>是一种筛选并剔除引起多重共线性变量的方法，广泛应用于逻辑谛斯回归模型。<br>  其基本思想是将解释变量逐个引入模型，每引入一个解释变量都进行统计性假设检验，当原来引入的解释变量由于后来解释变量的引入变得不再显著时则将其删除，以确保每次引入新变量之前，回归方程中只包含显著性变量。<br>  逐步回归共有三种方式：</p><ul><li>前向逐步回归，将特征逐步加入。</li><li>后向逐步回归，从所有特征集中将特征逐步剔除。</li><li>双向逐步回归，前向加入与后向剔除同时进行，即在每次加入新特征的同时，将显著性水平低于阈值的特征剔除。</li></ul><p>  <small>一般情况下，双向逐步回归的效果比前向逐步回归和后向逐步回归好。</small></p></li><li><p>递归特征消除<br>   <strong>递归特征消除（<code>Recursive Feature Elimination, RFE</code>）</strong>也是常用的包裹法特征选择方法，其基本思想是使用一个 <em>基模型</em> 进行多轮训练，每轮训练之后消除若干重要性低的特征（线性模型特征归一化后使用特征系数衡量其重要性），再基于特征集进行下一轮训练。</p></li></ul></li><li><p>嵌入法</p><ul><li>基于 <code>L1</code> 范数<br>  <strong>线性模型</strong>可以被看作是多项式模型，其中每一项的系数都可以表征这一维特征的重要性，越重要的特征在模型中对应的系数越大，而与输出变量相关性越小的特征，对应的系数越接近 <code>0</code>。<br>  <code>L1</code> 正则化将系数的 <code>L1</code> 范数作为 <em>惩罚</em> 项加到损失函数中，由于正则项非零，则会导致不重要的特征系数变为 <code>0</code>，因此使用 <code>L1</code> 正则化的模型往往稀疏，这使得 <code>L1</code> 正则化成为很好的特征选择方法。<br>  <small>在使用线性模型进行 <code>L1</code> 正则化特征选择时，应先消除多重共线性。</small></li><li>基于树模型<br>  建立<strong>树模型</strong>的过程就是特征选择。基于树模型的特征选择会根据信息增益或基尼不纯度的准则来选择特征进行建模，输出各个特征的重要度，依此进行特征筛选。</li></ul></li></ol><h5 id="基于特征稳定性"><a href="#基于特征稳定性" class="headerlink" title="基于特征稳定性"></a>基于特征稳定性</h5><ol><li><p><code>PSI</code> 选择<br><code>PSI</code> 指特征的<strong>稳定性指标</strong>，用于识别分布变化大的特征，充分了解其背后的特征分布变化的原因，判断是否可接受。其中稳定性是有参照的，在建模时将训练样本的分布作为<strong>预期分布（<code>expected distributiopn</code>）</strong>，将 <code>OOT</code> 样本作为作为<strong>实际分布（<code>actual distributiopn</code>）</strong>。<br>在计算 <code>PSI</code> 时需要先将特征值分箱。<code>PSI</code> 计算公式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PSI_i = (p(Actual_i) - p(Expected_i)) * ln(p(Actual_i)/p(Expected_i)) </span><br><span class="line">      = (Actual_i/Actual_t - Expected_i/Expected_t) * ln((Actual_i/Actual_t)/(Expected_i/Expected_t))</span><br></pre></td></tr></table></figure><p>其中 <code>PSI_i</code> 表示第 <code>i</code> 个分箱稳定性指标的结果，<code>Actual_i</code> 为第 <code>i</code> 个分箱实际样本个数，<code>Expected_i</code> 为第 <code>i</code> 个分箱期望样本个数，<code>Actual_t</code> 为实际样本总数，<code>Expected_t</code> 为期望样本总数。</p><p> <code>PSI</code> 表示实际样本分布和期望样本分布的差异。</p><table><thead><tr><th><code>PSI</code> 范围</th><th>稳定性</th></tr></thead><tbody><tr><td>iv &lt; 0.1</td><td>变化不太显著</td></tr><tr><td>[0.1, 0.25]</td><td>有比较显著的变化</td></tr><tr><td>iv &gt; 0.25</td><td>变化剧烈，需要特殊关注</td></tr></tbody></table></li><li><p>逾期率变化选择<br>在风控业务中，有些特征的不稳定性表现在对逾期率排序的衰减上，随着时间的变化特征对预测变量的排序会发生颠倒，称之为<strong>“倒箱”</strong>。<br><small><code>PSI</code> 反映的主要是特征分布的不稳定性，而“倒箱”体现特征对预测变量区分能力的不稳定性。</small></p></li></ol><h4 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h4><p>特征提取（<code>feature extraction</code>）是指从原有较多的特征中计算出较少的特征，用新特征替换原有特征，达到降维的目的，即通过从样本中学习一个映射函数 <code>f</code>，将原特征矩阵 <code>X1</code> 映射到 <code>X2</code>，其中 <code>X2</code> 的维度小于 <code>X1</code>。<br><small>特征选择和特征提取都是为了特征降维，二者实现效果相同，当采用的方法不同。特征提取采用的是通过属性间的关系，如组合不同属性得到新属性以此改变原有的特征空间；特征选择采用的是从原始特征数据集中选用子集，这是一种包含关系并没有改变原始特征空间。</small><br>特征提取方法分为两大类：</p><ul><li>线性特征提取方法<ul><li><strong>主成分分析方法（<code>Principal Component Analysis, PCA</code>）</strong>，映射后的样本具有更大的发散性。</li><li><strong>线性判别分析法（<code>Linear Discriminant Analysis, LDA</code>）</strong>，映射后的样本具有较好的的分类性能。</li></ul></li><li>非线性特征提取方法<ul><li><strong>局部线性嵌入（<code>Locally Linear Embedding, LLE</code>）</strong>，保持邻域内样本之间的线性关系。</li><li><strong>多维尺度变换（<code>Multiple Dimensional Scaling, MDS</code>）</strong>，保持降维后的样本间距离不变。</li></ul></li></ul><h5 id="线性特征提取"><a href="#线性特征提取" class="headerlink" title="线性特征提取"></a>线性特征提取</h5><ol><li><p><code>PCA</code><br><code>PCA</code> 将<strong>高维的特征向量合并为低维的特征向量</strong>，是一种<strong>无监督</strong>的特征提取方法。其基本原理是通过线性投影，将高维数据映射到低维空间中表示，并且期望在所投影的维度上数据的方差最大（最大方差理论），以此使用较少的数据维度，留存较多的原始数据特性。<br><code>PCA</code> 是我们常用的特征提取方法，其优点如下：</p><ul><li>仅需要以<strong>方差</strong>衡量信息量，不受数据集以外的因素影响。</li><li>各主成分之间正交，可消除原始数据成分间相互影响的因素。</li></ul><p> 缺点如下：</p><ul><li>主成分各个特征维度的含义不如原始特征的解释性强。</li><li>非主成分也可能含有重要信息，丢弃后会降低模型效果。</li></ul></li><li><p><code>LDA</code><br><code>LDA</code> 是一种<strong>基于分类模型进行特征属性合并</strong>的操作，是一种<strong>有监督</strong>的特征提取方法。其基本原理是将带有标签的数据投影到维度更低的空间中，使得投影后的点按类别区分，相同类别的点会在投影后的空间中更接近，用一句话概括就是：投影后相同类间方差最小，不同类间方差最大。<br><code>LDA</code> 的优点如下：</p><ul><li>在特征提取的过程中，可以使用类别的先验知识。</li><li>在分类过程中，依赖<strong>均值</strong>而不是方差的时候，其优于 <code>PCA</code> 之类的算法。</li></ul><p> 缺点如下：</p><ul><li>不适合对<strong>非高斯分布样本</strong>进行特征提取。</li><li>可能过度拟合数据。</li></ul><p> 除了 <code>PCA</code> 和 <code>LDA</code> 之外，线性特征提取方法还有因子分析（<code>Factor Analysis, FA</code>）、奇异值分解（<code>Singular Value Decomposition, SVD</code>）和独立成分分析（<code>Independent Component Analysis, ICA</code>）等。</p></li></ol><h5 id="非线性特征提取"><a href="#非线性特征提取" class="headerlink" title="非线性特征提取"></a>非线性特征提取</h5><ol><li><p><code>LLE</code><br><code>LLE</code> 是一种基于 <em><strong>流形学习</strong></em> 的方法（流形学习假设所处理的数据点分布在嵌入外围欧氏空间的一个潜在的流形体上，或者说这些数据点可以构成这样的一个潜在的流形体），其能够使特征提取后的数据较好地保存原有流形结构。<code>LLE</code> 假设数据在较小的局部是线性的，即每一个数据点都可以由其近邻点线性表示。<br><code>LLE</code> 主要分为三步，首先寻找每个样本点的 <code>k</code> 个近邻点；然后由每个样本点的近邻点计算出该样本点的权重；最后由该样本点的权重在低维空间中重构样本数据。至此就可以将特征映射到低维空间中。<br><code>LLE</code> 的优点如下：</p><ul><li>可以学习任意维度局部线性的低维流形。</li><li>该方法归结为<strong>稀疏矩阵特征分解</strong>，计算复杂度较小且实现容易。</li></ul><p> 缺点如下：</p><ul><li>学习的流形只能是不闭合的，且样本集是稠密、均匀的。</li><li>该方法对最近邻接样本数的选择敏感，不同近邻数对最终结果有很大影响。</li></ul></li><li><p><code>MDS</code><br><code>MDS</code> 是将<strong>高维空间中的样本点投影到低维空间</strong>中，让样本彼此之间的距离尽可能不变。其基本原理是首先计算得到高维空间中样本之间的<strong>距离矩阵</strong>，接着计算得到低维空间的<strong>内积矩阵</strong>，然后对低维空间的内积矩阵进行特征值分解，并按照从大到小的顺序取前 <code>d</code> 个（<code>d</code> 表示低维空间的维度）特征值和特征向量，最后得到在 <code>d</code> 维空间中的距离矩阵。<br><code>MDS</code> 的优点如下：</p><ul><li>不需要先验知识，计算简单。</li><li>保留样本在原始空间的相对关系，可视化效果较好。</li></ul><p> 缺点如下：</p><ul><li>当有样本的先验知识时，他无法被充分利用，因此无法得到预期效果。</li><li>该方法认为各维度对目标的贡献相同，忽略了维度间的差剧。</li></ul><p> 除了 <code>LLE</code> 和 <code>MDS</code> 之后，非线性特征提取方法还有等度量映射（<code>Isometric Feature Mapping, ISOMAP</code>）和 <code>t-SNE</code> 等。</p></li></ol><h4 id="训练、概率转化和效果评估"><a href="#训练、概率转化和效果评估" class="headerlink" title="训练、概率转化和效果评估"></a>训练、概率转化和效果评估</h4><p>特征选择和特征提取之后就是关键的模型训练环节，首先<strong>模型训练基础知识</strong>，其次<strong>概率转化方法</strong>，最后<strong>评价模型效果</strong>以及<strong>选择合适的模型</strong>。</p><h5 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h5><p>机器学习的模型训练其本质是<strong>参数优化过程</strong>。其参数可以分为两种：一种是<strong>模型参数（<code>parameter</code>）</strong>；另一种是<strong>超参数（<code>typerparameter</code>）</strong>。<br><strong>模型参数</strong>是可以直接通过数据估计得到的，如线性回归模型中的回归参数。<strong>超参数</strong>是用来定义模型结构或优化策略的，通常需要在模型训练前根据经验给定，如正则化系数。因此模型训练的目标是找到使得最终模型最好的超参数组合。</p><p>模型调参是寻找最优超参数组合的过程。常见的模型调参方法有以下几种：<strong>网格搜索（<code>grid search</code>）</strong>；<strong>随机搜索（<code>random search</code>）</strong>；<strong>贝叶斯优化（<code>bayesian optimization</code>）</strong>。</p><p>交叉验证的方法有以下几种：<strong>留 <code>p</code> 法交叉验证</strong>；<strong>留一法交叉验证</strong>；**<code>K</code> 折交叉验证**。</p><h5 id="概率转化"><a href="#概率转化" class="headerlink" title="概率转化"></a>概率转化</h5><p>风控模型（如 <code>XGBoost</code> 模型、<code>LighrGBM</code> 模型、<code>LR</code> （逻辑斯谛回归）模型）直接输出的是客户逾期概率，在风控信贷场景中，需要<strong>将概率转化为评分，通过分数量化客户的风险等级</strong>。<br>转换为评分的额方法如下：设 <code>p</code> 为客户逾期概率，那么客户逾期概率与未逾期概率的比值 <code>p/(1-p)</code> 记为 <code>oods</code>。转换为评分的计算公式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">score = A - B * log(odds) = A - B * log(p / 1-p)</span><br></pre></td></tr></table></figure><p> 客户逾期概率越低，评分越高。在通常情况下，这是分值的变动方式，即高分值代表低风险，而低分子代表高风险。其中 <strong><code>A</code> 和 <code>B</code> 都是常数</strong>，在计算时通常需要做出两个假设：给定 <code>odds = Ratio</code> 时，预期分数为 <code>Base</code>；<code>odds</code> 翻倍时，分数减少值为 <code>PDO(Point of Double Odds)</code>。由此可以得到 <code>A = Base + B * log(2 * Ratio), B = PDO / log2</code>。</p><h5 id="模型效果评估"><a href="#模型效果评估" class="headerlink" title="模型效果评估"></a>模型效果评估</h5><p>根据模型对样本的预测分数和样本的真实标签，可以通过不同角度的指标来评估模型的效果。<br>通过多种指标对模型性能进行评价，不同的评价指标往往产生不同的评价效果，这表明模型的 <em>好坏</em> 是相对的，具体使用何种指标取决于实际使用场景。<br>样本根据其<strong>真实类别和模型预测类别</strong>可形成以下四种组合：</p><ul><li><strong>真正例（<code>True Positive, TP</code>）</strong>：真实类别为正例，预测类别为正例。</li><li><strong>假正例（<code>False Positive, FP</code>）</strong>：真实类别为负例，预测类别为正例。</li><li><strong>假负例（<code>False Negative, FN</code>）</strong>：真实类别为正例，预测类别为负例。</li><li><strong>真负例（<code>True Negative, TN</code>）</strong>：真实类别为负例，预测类别为负例。<br><img src="https://s2.loli.net/2022/12/22/DMNZFGvq5iTQen8.png" alt="risk_3_5.jpg"></li></ul><p>对于回归任务，常见的评价指标有 <code>RMSE</code>（平方根误差）、<code>MAE</code>（平均绝对误差）、<code>MSE</code>（平均平方误差）和 <code>coefficient of determination</code>（决定系数）。对于分类任务，常见的评价指标有准确率、精确率、召回率、<code>F1</code> 值、<code>AUC</code> 和 <code>KS</code> 等。</p><ul><li><strong>准确率</strong><br>  准确率（<code>accuracy</code>）是指正确预测的正负例样本数和总样本数的比值。<code>accuracy = (TP + TN) / (TP + FP + FN + TN)</code>。</li><li><strong>精确率</strong><br>  准确率（<code>precision</code>）又称查准率，是指预测为正例的样本中真正是正例的样本比例。<code>precision = TP / (TP + FP)</code>。</li><li><strong>召回率</strong><br>  召回率（<code>recall</code>）又称查全率，是指实际正例样本中模型预测为正例的样本比例。<code>recall = TP / (TP + FN)</code>。</li><li><strong><code>F1</code> 值</strong><br>  <code>F1</code> 值是精确率和召回率的调和值，更接近于两个数中较小的那个，因此精确率和召回率接近时，<code>F1</code> 值更大。<code>F1 = (2 * precision * recall) / (precision + recall)</code>。</li><li><strong><code>AUC</code></strong><br>  <code>AUC(Area Under Curve)</code> 为 <code>ROC</code> 曲线下的面积。<code>ROC(Receiver Operating Characterstic, 接收者工作特征)</code> 曲线源于雷达信号分析技术，<code>ROC</code> 曲线的横坐标为 <code>FPR</code>（假正率），<code>FPR = FP / (FP + TN)</code>，即被预测为正例的负样本数与真实负样本数的比值；纵坐标为 <code>TPR</code>（真正率），<code>TPR = TP / (TP + FN)</code>，即被预测为正例的正样本数与实际正样本数的比值。<code>AUC</code> 的取值范围为 <code>0~1</code>。</li><li><strong><code>KS</code></strong><br>  <code>KS（Kolmogorov-Smirnov）</code> 指标主要用来验证模型对客户 <em>好坏</em> 的区分能力，用以检验两个经验分布是否不同，或者一个经验分布与一个理想分布是否不同。<br>  在计算风控模型 <code>KS</code> 指标时，通常是在模型对样本打分后，对分数进行分箱，然后分别统计每箱累积 <em>好</em> 客户和累积 <em>坏</em> 客户与 <em>好</em> 客户和 <em>坏</em> 客户总体的比值，累计 <em>坏</em> 客户比例与累计 <em>好</em> 客户比例的差值即为每箱对应的 <code>KS</code> 值。<br>  模型 <code>KS</code> 定义为各分箱 <code>KS</code> 值得最大值：<code>KS = max(Pcum(Bad) - Pcum(Good))</code>，<code>KS</code> 值越高，模型越好。但过高的 <code>KS</code> 值可能意味者过度拟合或特征 <em>穿越</em> 等。<br>  <small>相比 <code>KS</code>，<code>AUC</code> 更加稳健。而相比准确率、召回率、<code>F1</code> 值等指标，<code>AUC</code> 指标优势在于不需要设定分类阈值，只需要关注预测概率的排序，因此一般在二分类模型中主要将 <code>AUC</code> 作为模型效果的评价指标。</small></li></ul><hr><h3 id="开发方法论-上线和维护"><a href="#开发方法论-上线和维护" class="headerlink" title="开发方法论-上线和维护"></a>开发方法论-上线和维护</h3><p>模型训练通常在本地环境中进行，训练完成后，首先选择最优模型并部署到线上环境，然后验证模型在线上环节运行是否准确无误，确认无误后，才会使用。</p><h4 id="部署及上线验证"><a href="#部署及上线验证" class="headerlink" title="部署及上线验证"></a>部署及上线验证</h4><ol><li>模型部署<br>模型部署是将训练完成的模型部署到线上环境。考虑其是否可以跨语言部署，模型文件通常可以选择保存为以下两种方式：</li></ol><ul><li><code>pickle</code> 格式<br>  <code>pickle</code> 是 <code>Python</code> 语言独有的格式。若线上为 <code>Python</code> 环境，那么就可以通过 <code>pickle</code> 格式实现模型的快速读取。  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 pickle 格式保存和读取模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_model_as_pkl</span>(<span class="params">model, path</span>):</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">pickle.dump(model, f, protocol=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_model_from_pkl</span>(<span class="params">path</span>):</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">model = pickle.load(f)</span><br><span class="line"><span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>  <small>保存模型时设置 <code>protocol=2</code> ，表示以二进制协议对模型内容进行序列化存储，以此解决 <code>Python3</code> 环境中保存的模型在 <code>Python2</code> 环境中部署。</small></li><li><code>PMML</code> 格式<br>  预测模型标记语言（<code>Predictive Model Markup Language, PMML</code>）是一套与平台和环境无关的模型标记语言，可实现跨平台的机器学习模型部署。</li></ul><ol start="2"><li>上线验证<br>模型部署到线上环境后，通常先作为<strong>空跑</strong>一段时间使用，当积累一定样本量时可以进行上线验证。上线验证的目的在于确认模型在线上环境中按照预期运行。验证方式主要有以下三种：<strong>预测分数的一致性</strong>；<strong>模型分分布的差异性</strong>；<strong>模型效果的一致性</strong>。</li></ol><h4 id="监控和异常处理"><a href="#监控和异常处理" class="headerlink" title="监控和异常处理"></a>监控和异常处理</h4><p>模型上线之后，为了保证模型有效运行，需要对模型相关指标进行监控。当遇到异常状况时，可以通过多种途径发出预警。</p><h5 id="模型监控"><a href="#模型监控" class="headerlink" title="模型监控"></a>模型监控</h5><p>模型监控主要以报表方式展示各项监控指标。</p><ul><li>模型监控内容<br>  模型监控包含<strong>准确性</strong>、<strong>稳定性</strong>和<strong>有效性</strong>三个方面。<ul><li>准确性是模型有效运行的基础。模型打分准确性监控是要确保<strong>线上模型的结果与线下模型计算的结果一致</strong>。</li><li>稳定性是模型有效运行的保障。稳定性监控主要是监测模型分和特征是否稳定，可以从以下两个方面来判断：<strong>模型分布变化</strong>；<strong>特征值的分布变化</strong>。</li><li>有效性是模型运行的目标。模型有效性监控是指持续监控模型的预测能力，识别其是否有衰减。监控指标主要依赖于 <strong><code>KS</code></strong> 和 <strong><code>AUC</code></strong> 指标，以及特征的 <strong><code>IV</code></strong> 指标。</li></ul></li><li>模型监控形式<br>  模型监控可以按照<strong>日报</strong>、<strong>周报</strong>和<strong>月报</strong>形式，采用<strong>邮件</strong>或<strong>可视化页面</strong>的方式展示监控结果。</li></ul><h5 id="模型预警"><a href="#模型预警" class="headerlink" title="模型预警"></a>模型预警</h5><p>模型预警主要是根据预警条件触发预警信息，提示模型异常，因此需要定义预警指标触发条件和预警形式。<br>对每一项监控设定预警指标并定义预警阈值，当监控的指标值偏离该范围时就会发出预警。对应模型的<strong>准确性</strong>、<strong>稳定性</strong>和<strong>有效性</strong>监控，预警指标有<strong>一致性</strong>、**<code>PSI</code>** 和 **<code>KS</code>**，然后进一步根据指标的风险程度划分预警等级。<br>预警指标阈值没有统一的设置规范，不同业务场景对风险的容忍度有所差别，因此需要结合具体场景和业务相关人员共同确定阈值。</p><h5 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h5><p>模型异常处理是指模型发生异常时，需要快速分析问题和解决问题，将影响尽可能降到最低。导致模型的准确性、稳定性和有效性异常的原因有很多，下面为常见的原因：</p><ul><li>模型准确性异常处理<br>  导致模型准确性异常的原因通常有以下两种：<strong>运行环境发生改变</strong>；<strong>特征预处理逻辑发生改变</strong>。</li><li>模型稳定性异常处理<br>  导致模型稳定性异常的原因通常有以下两种：<strong>数据源异常</strong>；<strong>客群变化</strong>。</li><li>模型有效性异常处理<br>  导致模型有效性异常的原因通常有：<strong>数据源异常</strong>；<strong>客群变化</strong>；<strong>模型自身效果衰减</strong>。</li></ul><h4 id="迭代优化"><a href="#迭代优化" class="headerlink" title="迭代优化"></a>迭代优化</h4><p>模型上线之后，客群的变化、数据维度的增加、业务调整某些数据无法使用等都可能导致模型效果出现波动。面对这些情况对模型的迭代和优化就显得格外重要，当然模型迭代优化的目的在于提升线上模型效果，使得模型在近期样本上表现更好。<br>模型的迭代优化可以从<strong>模型融合</strong>、<strong>建模时效</strong>和<strong>拒绝推断</strong>三个方面进行。</p><h5 id="模型融合"><a href="#模型融合" class="headerlink" title="模型融合"></a>模型融合</h5><p>模型融合角度优化是指将多个模型的结果相互组合或再训练，以提升最终模型效果。<br>不同样本之间的信息千差万别，不同算法从样本中学到的信息也各不相同，因此可以利用这些差异结合不同类型、不同时间段模型相互融合，提炼出更加丰富的客群信息。融合模型突破了以往单一模型的局限性，具有多个子模型的优点，比单一模型具有更好的效果。</p><ol><li><p>模型融合方法<br>模型融合的方法有很多种，常用的有以下三种：</p><ul><li><strong>模型结果简单加权</strong>是指直接给各个子模型分配权重，通过加权求和得到融合模型的输出。</li><li><strong>模型结果再训练</strong>是指将各个子模型的结果作为特征，采用机器学习算法再次建模，最终得到融合模型。</li><li><strong>集成学习</strong>通过构建多个学习器来完成建模任务。集成学习中常用的四种模型融合方法：<ul><li><strong><code>Bagging</code></strong> 是在多轮采样获取的数据子集上训练多个个体学习器，然后通过投票法或平均法对个体学习其进行集成的方法。</li><li><strong><code>Boosting</code></strong> 是一种在训练过程中，不断对训练样本分布进行调整，基于调整后的样本分布训练下一轮个体学习器的集成学习方法。</li><li><strong><code>Stacking</code></strong> 是一种将多种个体学习器整合在一起来取得更好表现的集成学习方法。一般情况下，<code>Stacking</code> 的训练过程分为两步，第一步训练第一层的多个不同模型，第二部以第一层各个模型的输出来训练得到最终模型。</li><li><strong><code>Blending</code></strong> 与 <code>Stacking</code> 类似，区别体现在于：第一步在训练集上，<code>Blending</code> 不是通过 <code>K</code> 折交叉验证策略得到预测值，而是采用 <code>Hold-Out</code> 策略，即保留固定比例的样本并将其作为验证集，在其余样本上训练出多个模型，分别在验证集和测试集上进行预测，将预测值作为新特征；第二步基于验证集和测试集的新特征，训练得到最终模型。</li></ul></li></ul></li><li><p>模型融合方式<br>模型融合方式有很多，包括<strong>不同标签模型融合</strong>、<strong>不同样本模型融合</strong>和<strong>不同数据源模型融合</strong>。</p><ul><li>不同标签模型融合是指将<strong>不同样本标签</strong>开发模型继续宁融合。基于不同样本标签，模型能够学到样本不同维度的信息，融合后的模型学到的信息更加丰富。</li><li>不同样本模型融合是指将<strong>不同样本</strong>开发的模型进行融合。根据产品、时间等信息，将样本分群，分别训练子模型，再将子模型融合。</li><li>不同数据源模型融合是指先根据<strong>不同数据源特征</strong>分别建立子模型，再将不同数据源子模型融合。</li></ul></li></ol><h5 id="建模时效"><a href="#建模时效" class="headerlink" title="建模时效"></a>建模时效</h5><p>从建模时效角度优化是指快速迭代模型，及时根据线上客群变化做出调整。因为通常情况下在模型上线后，模型更新周期会较长，不能快速反映客群变化，即使发现了线上模型效果衰减，再次开发新的模型也需要一段时间。为此解决建模时效问题的常见做法是应用<strong>模型自动快速迭代</strong>和<strong>在线学习</strong>。</p><ol><li><p>模型自动快速迭代<br><strong>模型自动快速迭代</strong>是指加入最新有表现样本，快速更新迭代模型。<br>核心部分主要包含样本选择、数据准备、数据预处理、特征选择、模型训练和效果评估。为此可以构建一套完整的模型自动化平台，将样本选择、数据准备、自动测试和部署上线也实现自动化，这样就构建了完整的模型自动快速迭代体系。该模型自动快速迭代体系主要包括 <em>特征自动回溯系统</em>、<em>自动建模系统</em>、<em>自动测试系统</em> 和 <em>自动上线系统</em> 四个部分。</p></li><li><p>在线学习<br><strong>在线学习（<code>online learning</code>）</strong>是指根据线上的实时数据，快速进行模型调整，使得模型及时反映线上的变化，提高线上模型的效果。<br>在线学习种具有代表性的算法：**<code>Bayesian Online Learning</code>** 和 **<code>Follow The Regularized Leader(FTRL)</code>**。<br><small>传统模型开发是使用离线数据处理方式进行开发的，开发完成后再部署到线上，这种模型上线后一般是静态的，不会与线上的业务数据有任何互动。</small><br><small>相比模型自动快速迭代，在线学习方法不需要每次使用全量样本重建模型，只需要使用新增样本更新模型参数，建模成本低。</small></p></li></ol><h5 id="拒绝推断"><a href="#拒绝推断" class="headerlink" title="拒绝推断"></a>拒绝推断</h5><p>拒绝推断通常是基于放款样本，但贷前风险预测模型使用场景是所有的授信申请客户，其中包含拒绝样本，即训练模型使用的客群仅是预测人群中的一部分，存在<strong>“样本偏差”</strong>问题。如果能在建模样本中加入被拒绝的样本，那么模型的效果可以得到保障，但是问题在于，被拒绝的样本没有标签，而推测被拒绝样本的标签就是<strong>“拒绝推断”</strong>的主要内容。</p><ol><li><p>使用场景<br>拒绝推断经常使用的场景：<strong>总体风险异质</strong>；<strong>风险通过率很低</strong>；<strong>历史数据与当前数据显著不同</strong>。<br><strong>已知推断比（<code>known-to-inferred odds ratio, KI</code>）</strong>常用来衡量拒绝推断的风险是否合理，定义式如下：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KI = (Gk/Bk)/(Gi/Bi)</span><br></pre></td></tr></table></figure><p>其中 <code>Gk</code>、<code>Bk</code>、<code>Gi</code>、<code>Bi</code> 分别表示已知好客户、已知不良客户、推断好客户、推断不良客户的样本数量。<code>KI</code> 值越高，说明推断人群中不良客户的比例越高，推断人群的风险也就越高。通常<strong>合理的 <code>KI</code> 值在 <code>2 ~ 4</code> 之间</strong>，而业界倾向于更大的值。</p><p> 拒绝推断场景中常见的三种模型如下：</p><ul><li><strong><code>AR(Accept Reject)</code> 模型</strong>：以是否放贷为标签，是在全量样本上构建的模型。</li><li><strong><code>KGB(known Good Bad)</code> 模型</strong>：以逾期表现为标签，是在已知好坏标签的样本上构建的模型。</li><li><strong><code>AGB(All Good Bad)</code> 模型</strong>：以逾期表现为标签，是在全部授信申请样本上构建的模型。建模样本包含已知好坏标签（真实标签）的样本和推断出“伪标签”的样本。</li></ul></li><li><p>常用方法<br>解决样本偏差问题的方法有两类：</p><ul><li>数据法<ul><li><strong>增量下探法</strong><br> 增量下探法是指从本该拒绝的样本中，随机选取部分样本授信通过，以便获取该部分样本的真实标签。</li><li><strong>同生表现法</strong><br> 同生表现法是指通过客户在其他产品或机构的贷后表现，推断出本产品上的伪标签。</li></ul></li><li>推断法<ul><li><strong>硬截断法</strong><br> 硬截断法（<code>hard cutoff</code>）也称简单展开法（<code>simple augmentation</code>），是指根据通过样本构建 <code>KGB</code> 模型，利用 <code>KGB</code> 模型对拒绝样本预测打分，设置截断阈值，高于该阈值的样本认定为正样本，低于该阈值的样本认定为负样本，最终将有真实标签的通过样本和推测得到的伪标签的拒绝样本合并，构建最终模型。</li><li><strong>模糊展开法</strong><br> 模糊展开法（<code>fuzzy augmentation</code>）是指根据通过样本构建 <code>KGB</code> 模型，利用 <code>KGB</code> 模型预测拒绝样本的逾期概率，然后将每条拒绝样本复制为不同类别、不同权重的两条，每条通过样本的权重为 <code>1</code>，最终将有真实标签的通过样本和推断得到伪标签的决绝样本合并，考虑不同样本的权重，构建最终模型。</li><li><strong>重新加权法</strong><br> 重新加权法（<code>reweighting</code>）是指根据通过样本构建 <code>KGB</code> 模型，利用 <code>KGB</code> 模型对全部样本预测打分，然后分箱统计不同分数段的通过样本数和拒绝样本数，计算每箱的权重，添加通过样本不同分数段的权重，然后利用通过样本构建最终模型。<br> 权重方式计算如下： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">weight = (Accepti + Rejecti) / Accepti</span><br></pre></td></tr></table></figure> 其中 <code>Accepti</code> 表示第 <code>i</code> 分箱通过样本数，<code>Rejecti</code> 表示第 <code>i</code> 分箱拒绝样本数。</li><li><strong>外推法</strong><br> 外推法（<code>extrapolation</code>）是指根据通过样本构建 <code>KGB</code> 模型，利用 <code>KGB</code> 模型对拒绝样本预测打分，然后对通过样本模型分等频分箱，统计每箱的逾期率，将逾期率的 <code>KI</code> 倍数设为拒绝样本相同分箱的期望逾期率，并按照期望逾期率对拒绝样本随机标记伪标签，最终和通过样本一起构建最终模型。</li><li><strong>迭代再分类法</strong><br> 迭代再分类法（<code>iterative reclassification</code>）是指通过多次迭代，使得最终模型参数逐步趋于稳定。迭代再分类的具体做法：首先利用硬截断法获得拒绝样本的伪标签，然后训练得到最终模型，并利用最终模型重新给拒绝样本预测打分，更新伪标签，直到任何一个有价值的指标收敛。<br> 迭代再分类法利用启发式思想，经过多次迭代，可以保证修正偏差后的最终模型的效果。其中设置的迭代终止条件可以是任何一个有价值的指标收敛。</li><li><strong>双变量推断法</strong><br> 双变量推断法（<code>bivariate inference</code>）是指首先分别利用通过样本构建 <code>KGB</code> 模型和全部样本构建 <code>AR</code> 模型，然后利用两个模型分别对拒绝样本预测打分，并将加权求和的结果作为最终预测打分，然后利用 <em>“外推法”</em> 设置伪标签，最终和通过样本一起构建模型。<br> 拒绝样本的模型分计算公式如下： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Rejects = a * ARs + (1-a) * KGBs</span><br></pre></td></tr></table></figure> 其中 <code>ARs</code> 是 <code>AR</code> 模型的打分，<code>KGBs</code> 是 <code>KGB</code> 模型的打分，<code>0 &lt; a &lt; 1</code> 表示权重。</li></ul></li></ul></li></ol><hr><h3 id="模型体系搭建"><a href="#模型体系搭建" class="headerlink" title="模型体系搭建"></a>模型体系搭建</h3><p>信贷产品生命周期主要包括<strong>营销</strong>、<strong>贷前</strong>、<strong>贷中</strong>和<strong>贷后</strong>四个阶段，每个阶段都有风险控制的需求。</p><ul><li>贷前阶段主要获取并筛选客户流量，以营销响应模型和流量筛选模型为主。</li><li>贷前阶段一般会通过部署多种风控规则和模型来识别风险，风控规则可以识别小部分高风险客户，大部分仍然需要模型预测。贷前阶段的模型主要有反欺诈模型、信用风险模型。</li><li>贷中阶段会通过贷中行为预测客户的风险情况，制订账户管理等策略，同时利用交易风险模型对客户贷中的提现、消费等交易行为进行风险判断。</li><li>贷后阶段通过还款预估模型预测客户的还款可能性，制订合理的催收策略，提升还款率；利用失联预估模型预测客户的失联概率，优化催收策略。</li></ul><p>完整的风控体系需要对信贷产品生命周期的每一个阶段进行有效的风险控制，以下为信贷产品生命周期的不同阶段包含的主要风控模型。<br><img src="https://s2.loli.net/2022/12/22/1AXbaVD75ieRCBp.png" alt="risk_3_4.jpg"></p><h4 id="营销阶段"><a href="#营销阶段" class="headerlink" title="营销阶段"></a>营销阶段</h4><p>营销是业务开展的第一步，获取优质客群是营销阶段得到重要目标，通常是利用营销响应模型评估客户的响应概率，再利用流量筛选模型选择目标客群。</p><ol><li><p>营销响应模型<br>营销响应模型是通过营销时对客户进行评估来预测客户响应概率的模型。营销场景主要包含<strong>纯新客户名单营销</strong>、<strong>流失客户营销召回</strong>和<strong>存量客户的交叉销售</strong>等，采用营销响应模型将客户分级，对于响应概率高的客群，业务人员可以重点营销，即可以大幅提升营销效率，降低营销成本。</p></li><li><p>流量筛选模型<br>流量筛选模型也称前筛模型，用来识别资质明显差的客群。拦截这部分高风险客群是风险控制的第一项任务同时节省后续申请授信环节的数据成本。其中流量筛选模型一般用于与其他流量提供方合作的场景中。</p></li></ol><h4 id="贷前阶段"><a href="#贷前阶段" class="headerlink" title="贷前阶段"></a>贷前阶段</h4><p>贷前是有效控制风险的重要阶段，因为一旦高风险客户通过贷前授信，后期在贷中和贷后阶段会面临被动局面，因此贷前阶段一般通过部署多种模型来尽可能多识别风险。</p><ol><li><p>反欺诈模型<br>反欺诈模型用于识别欺诈风险高的客户。常见的欺诈类型有：<strong>第一方欺诈</strong>，即利用不实信息欺诈，欺诈者故意提供虚假申请信息以获得授信审批；<strong>第三方欺诈</strong>，即冒用他人身份欺诈，欺诈者偷取他人信息，以他人名义申请。<br>因此在实践中可通过<strong>身份验证</strong>、<strong>活体识别</strong>和<strong>第三方数据验证</strong>等方式识别欺诈，并且可以通过反欺诈模型综合多维度信息进行识别。</p></li><li><p>信用风险模型<br>信用风险模型是通过对信贷申请人的信用状况进行评估来预测其未来逾期概率的模型，即<strong>申请评分卡</strong>，也称 <strong><code>A</code> 卡（<code>Application scorecard</code>）</strong>。信用风险模型有重要作用，该模型的预测评分不仅可以审批准入，还可以用于额度和费率的设定。</p></li></ol><h4 id="贷中阶段"><a href="#贷中阶段" class="headerlink" title="贷中阶段"></a>贷中阶段</h4><p>贷中阶段可以获得客户交易、还款和 <code>APP</code> 使用等行为数据，通过这些数据可以全面、客观、准确地预测客户的未来表现，从而制订有针对性的贷中管理策略。</p><ol><li><p>贷中行为模型<br>贷中行为模型即<strong>行为评分卡</strong>，也称 <strong><code>B</code> 卡（<code>Behavior scorecard</code>）</strong>是根据客户借款后的行为表现，预测其未来逾期概率的模型。</p></li><li><p>交易风险模型<br>交易行为模型是在已经获得授信的客户发生支用或消费交易等行为时进行风险预估的模型。该模型用于拦截高风险交易，及时止损，交易风险模型与信用风险模型类似，只是交易风险模型在获得的特征维度上会包含更多的贷中行为数据。</p></li></ol><h4 id="贷后阶段"><a href="#贷后阶段" class="headerlink" title="贷后阶段"></a>贷后阶段</h4><p>贷后阶段的模型根据客户放贷后的行为表现，预测客户的还款概率。原始催收表现为尽可能多地联系客户，然后依靠客户近期的逾期行为调整策略。</p><ol><li><p>还款预估模型<br>还款预估模型即<strong>催收评分卡</strong>，也称 <strong><code>C</code> 卡（<code>Collection scorecard</code>）</strong>是预测已逾期的客户在未来一段时间的还款概率的模型。通常逾期客户在早期还款的可能性较大，越往后还款越困难，因此可以利用还款预估模型制订差异化的催收策略，提高还款率。</p></li><li><p>失联预估模型<br>失联预估模型预测已逾期的借款人在未来一段时间是否会失联。在催收后期，通常会出现无法联系到客户的情况出现，这对催收有很大的影响，如果可以在早期获得客户失联的可能性，即可以对催收工作的开展提供指导。</p></li></ol><hr><h3 id="术语介绍"><a href="#术语介绍" class="headerlink" title="术语介绍"></a>术语介绍</h3><ol><li><p>样本、特征、标签<br>样本是构建机器学习模型时需要一个数据集。<br>特征是用来表征关注对象的特点或属性的一系列数据。<br> <strong>标签</strong>是机器学习模型将要学习和预测的目标。</p></li><li><p>账龄<br><strong>账龄（<code>Month on Book, MOB</code>）</strong>是指多期信贷产品从首次放款起所经历的月数。<br>通常使用 <code>MOBn</code> 表示账龄，以月末时间点来看放款日经历 <code>n</code> 个完整的月数，具体如下：</p><ul><li><code>MOB0</code>：放款日到当月月底，观察时间点为放款当月月末。</li><li><code>MOB1</code>：放款后第二个月，观察时间点为放款第二个月月末。</li><li>以此类推 <code>MOB</code> 的最大值取决于信贷产品的 <em>账期</em>。</li></ul></li><li><p>逾期<br>逾期的概念有以下几种：</p><ul><li><strong>逾期天数（<code>Days Past Due, DPD</code>）</strong>：实际还款日与应还款日的相差天数。</li><li><strong>首期逾期天数（<code>First Payment Deliquency, FPD</code>）</strong>：分期产品中第一期实际还款日与应还款日的相差天数。</li><li><strong>逾期期数</strong>：贷款产品中客户的逾期期数，也指将逾期期数按区间划分后的逾期状态。<br>  通常以 <code>30</code> 天为区间划分，英文字母 <code>M</code> 来表示，具体如下：<ul><li><code>M0</code>：当前未逾期。</li><li><code>M1</code>：逾期一期，或逾期 <code>1~30</code> 天。</li><li><code>M2</code>：逾期两期，或逾期 <code>31~60</code> 天。</li><li>以此类推，<code>M2+</code> 表示逾期两期以上，或逾期天数未 <code>61</code> 天以上，和 <code>DPD60+</code> 含义一致。</li></ul></li><li><strong>逾期率</strong>：分为订单逾期率和金额逾期率。订单逾期率是指逾期订单数与总放款订单数的比值。金额逾期率是指逾期金额与总放款金额的比值。</li></ul></li></ol><hr><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><hr><h3 id="个人备注"><a href="#个人备注" class="headerlink" title="个人备注"></a>个人备注</h3><p><strong>此博客内容均为作者学习所做笔记，侵删！</strong><br><strong>若转作其他用途，请注明来源！</strong></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;风控模型&lt;/strong&gt;是风控系统的核心，应用模型进行风险决策是识别风险的主要途径，也是控制风险的重要方法。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Risk" scheme="https://blog.vgbhfive.cn/tags/Risk/"/>
    
  </entry>
  
  <entry>
    <title>智能风控-特征画像体系</title>
    <link href="https://blog.vgbhfive.cn/%E6%99%BA%E8%83%BD%E9%A3%8E%E6%8E%A7-%E7%89%B9%E5%BE%81%E7%94%BB%E5%83%8F%E4%BD%93%E7%B3%BB/"/>
    <id>https://blog.vgbhfive.cn/%E6%99%BA%E8%83%BD%E9%A3%8E%E6%8E%A7-%E7%89%B9%E5%BE%81%E7%94%BB%E5%83%8F%E4%BD%93%E7%B3%BB/</id>
    <published>2022-11-12T15:07:59.000Z</published>
    <updated>2023-01-01T15:36:53.971Z</updated>
    
    <content type="html"><![CDATA[<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>特征挖掘是从原始数据构造特征的过程。<br>特征是数据和模型之间的纽带，数据和特征决定机器学习的上限，而模型和算法只是无限逼近这个上限。<br>特征挖掘的完整流程包含<strong>原始数据分析</strong>、<strong>数据清洗</strong>、<strong>中间数据集构建</strong>、<strong>特征设计和生成</strong>、<strong>特征评估</strong>和<strong>特征的上线、监控、维护和下线</strong>。</p><span id="more"></span><p><small>在实际运行中，特征挖掘不一定是严格线性的，某些环节可能存在反复多次进行的情形。</small><br><img src="https://s2.loli.net/2022/11/13/WMcXFUxuZ9lzKtL.png" alt="risk_2_1.jpg"></p><hr><h3 id="挖掘方法论"><a href="#挖掘方法论" class="headerlink" title="挖掘方法论"></a>挖掘方法论</h3><p>业务中的数据类型繁多，不同的数据类型需要采用不同的方法进行挖掘，下面是通用的特征挖掘方法。</p><h4 id="原始数据分析"><a href="#原始数据分析" class="headerlink" title="原始数据分析"></a>原始数据分析</h4><p>原始数据分析是为了提取原始数据中有用的信息而对其加以分析的过程。原始数据分析的目的是对数据价值进行初步判断，避免错误使用数据，为后续的数据清洗与处理提供依据，最大化利用原始数据。<br>原始数据分析可以利用从<strong>数据流转分析</strong>、<strong>数据质量分析</strong>和<strong>数据时效性分析</strong>方面进行。</p><ol><li><p>数据流转分析<br>数据流转分析是指对数据来源、中间处理和最终存储环节的数据进行分析。通过数据流转分析，可以了解数据在业务流程中的演变过程，从而全面认识数据并发现潜在问题。数据流转分析可以从<strong>业务逻辑角度</strong>和<strong>实际数据角度</strong>分别进行：</p><ul><li>业务逻辑角度<br>  从业务逻辑角度分析是基于业务梳理出数据的产生、中间处理、最终存储和数据的更新机制。业务逻辑分析主要是为了整体把控底层数据的完整生命周期变化情况，也是为了补充数据层面分析无法获知的信息。</li><li>实际数据角度<br>  从实际数据角度分析是指利用业务中产生的实际数据与理解的业务逻辑进行交叉比对，并且对其变化进行详细分析。这样就可以发现实际数据和业务逻辑中不一致的地方并加以确认和纠正，同时可以发现数据源的稳定性问题、计算问题和存储问题等异常，以此来保证数据的准确性和完整性。</li></ul></li><li><p>数据质量分析<br>数据质量分析可以从数据的<strong>覆盖率</strong>、<strong>规范性</strong>和<strong>准确性</strong>方面进行。</p><ul><li>覆盖率是指数据中非空记录的占比。</li><li>规范性是指数据取值是否符合一定的规范。</li><li>准确性是指数据接近真实值的程度。</li></ul></li><li><p>数据时效性分析<br>数据时效性分为<strong>采集时效性</strong>和<strong>获取时效性</strong>两个方面。获取时效性不仅受采集时效性影响，而且数据传输、中间处理和存储都会影响。</p><ul><li>采集时效性是指数据从产生到采集的时间间隔。</li><li>获取时效性是指从数据产生到风控生产系统中实际获取的时间间隔。</li></ul></li></ol><h4 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h4><p>数据清洗一般包含<strong>重复数据处理</strong>、<strong>缺失数据处理</strong>、<strong>异常值处理</strong>和<strong>时间数据处理</strong>。数据清洗是为了数据质量达到特征挖掘使用的标准，避免因数据质量问题而导致特征挖掘阶段，甚至建模阶段的返工。</p><ol><li><p>重复数据处理<br>业务流程中产生的数据一般都需要完整保存，在维持数据完整性的同时，可能会引入重复数据，至此需要判断重复数据是否有业务含义，如果有业务含义则需要挖掘与业务含义相关的特征；若没有业务意义则需要冗余处理。<br>冗余数据处理包括直接过滤和整合应用：直接过滤是指随机选取一条数据，丢弃其他；整合应用则是将多条数据整合或校准之后形成完整和可靠的记录，之后记录并使用。<br><img src="https://s2.loli.net/2022/11/21/9gY8OB56MhuiHKZ.png" alt="risk_2_8.jpg"></p></li><li><p>缺失数据处理<br>在特征挖掘阶段根据数据确实情况，尽早发现隐藏的数据问题，有很多的机会采取措施以降低甚至消除数据缺失的影响，产出稳定的特征。<br>缺失数据处理需要先判断数据是否未正常缺失，再根据判断结果采取合适的处理方式，如填充缺失值、修复数据和丢弃数据等。<br><img src="https://s2.loli.net/2022/11/21/QcKxwOSaJUI1YfZ.png" alt="risk_2_9.jpg"></p></li><li><p>异常值处理<br>异常值即数据中存在的不合理的值，同时异常值也称为<strong>离群点</strong>。对于发现的异常值，一方面可以及时研究数据是否可以修复；另一方面在特征开发阶段，可以增加对应处理逻辑，降低特征异常值出现的概率。<br>异常值的处理方式通常如下：</p><ul><li>删除含有异常值的记录。</li><li>将异常值视为缺失，使用缺失值填充的方式来处理。</li><li>用特定值（如平均值、中位数或固定值等）来填充。</li></ul></li><li><p>时间数据处理<br>特征挖掘通常使用时间窗口来切分数据，而时间切分错误就会导致整个模块绝大部分特征无法使用。<br>时间数据处理主要包含两个方面：<strong>对时间格式做统一的规范化处理</strong>；<strong>对数据进行时间维度上的过滤</strong>。<br>时间格式的规范化需要注意以下三个方面：</p><ul><li>统一时区。</li><li>统一时间格式。</li><li>选择合适的时间跨度。</li></ul><p> 数据在时间维度上的过滤主要从两个方面进行：</p><ul><li>避免引入未来数据。</li><li>避免时间未对齐问题。</li></ul></li></ol><h4 id="中间数据集构建"><a href="#中间数据集构建" class="headerlink" title="中间数据集构建"></a>中间数据集构建</h4><p>中间数据集构建是将清洗完成的原始数据初步处理成结构化的数据或者适用于某些特定算法的数据格式。<br>结构化数据是高度组织、格式整齐的数据，通常是可以用统一的结构（二维表）来表达的数据。结构化数据一般使用关系型数据库且以行为单位表示，与之对应的是非结构化数据，非结构化数据是数据结构不规则或不完整，没有预定义的数据模型，不方便用数据库二维逻辑表来表达的数据，通常存储在非关系型数据库中。</p><ol><li><p>结构化数据<br>结构化数据本身是适合特征计算的，但是需要注意数据本身的粒度。风控业务中的原始数据按照粒度从大到小依次为渠道、客户、借款、还款等，另外在不同的场景下特征挖掘需要不同的数据粒度。<br>结构化数据应用时一般会遇到两种情况：一种情况是假设数据是合适的粒度，那就可以直接作为特征在模型或规则中应用；另一种情况则是数据需要经过聚合汇总才能转换成建模可用的粒度。</p><ul><li>客户行为埋点数据<br>  同一个客户存在多条埋点数据，并且客户每次登录的操作序列可能不同，业务通常以客户每次登录的维度来生成客户行为埋点数据，以客户 <code>ID</code> 作为本次登录的所有埋点行为数据的唯一标识。</li><li>客户历史订单数据<br>  业务一般以订单维度保存订单数据，每个客户可能存在多个订单数据。将历史订单数据整理成包含客户 <code>ID</code> 的中间数据集，后续挖掘特征时可以基于中间数据集进行对比、分组、聚合等。</li><li>客户账单数据<br>  挖掘贷后特征应用于贷后 <code>C</code> 卡模型需要订单粒度的特征，中间数据集为账单粒度的数据。</li></ul></li><li><p>文本数据<br>文本数据就是用文本形式表示的数据。文本数据的特征挖掘方法常用的有以下三种：</p><ul><li>提取关键字并将文本数据转化为结构化数据，再进行特征挖掘。<br>  具体做法是构建关键字集合，再根据关键字在每条文本中出现的次数构建中间数据集。关键字集合的构建一般是基于业务经验，并结合原始数据的分析。</li><li>基于机器学习或深度学习算法从文本中提取特征。<br>  首先对每条文本做清洗和预处理，包括过滤标点符号、特殊字符、删除停用词；然后做分词形成文本序列；最后合并一个客户的多条文本序列并作为输入。</li><li>使用文本分类算法训练文本模型，然后将模型输出的概率值作为特征使用。</li></ul></li><li><p>关系网络数据<br>关系网络数据通常是指用来描述实体之间关系的数据。关系网络数据中的实体可能存在多种类型，实体之间也可能存在多种关系。处理关系网络数据通常分为以下两步：</p><ul><li>从复杂的现实关系网络中抽取有价值的实体和关系并将其表达为图结构。<br> <img src="https://s2.loli.net/2022/11/20/QNg4hixtTEmZycs.png" alt="risk_2_2.jpg"></li><li>构建中间数据集，转化为结构化数据或者构建适用于图算法的中间数据。<br>  在将关系网络数据用于传统特征挖掘时，构建中间数据集通常需要三步：计算所有节点的特征，可以使用结构化数据特征挖掘的办法；针对每个节点抽取子图结构，基于计算效率的考虑，抽取子图结构目前只针对一度和二度邻居节点进行；将所有节点的特征按照子图中心节点来整理，形成中间数据集。</li></ul></li></ol><h4 id="特征设计与生成"><a href="#特征设计与生成" class="headerlink" title="特征设计与生成"></a>特征设计与生成</h4><p>在特征的设计与生成阶段会完成从原始数据到特征的转化，对于那些取自规范、含义清晰、汇总力度符合需求的字段可以直接当作特征输出，其他的需要进行汇总计算以产生新特征。<br>在风控业务中特征设计最重要的点在于客户风险的区分度上，而特征设计通过采用不同的方法：<strong>基于业务逻辑生成特征</strong>；<strong>半自动化方法生成特征</strong>；<strong>基于智能算法生成特征</strong>。<br><img src="https://s2.loli.net/2022/11/20/nIjHyJu2vapd1b7.png" alt="risk_2_3.jpg"></p><h4 id="特征评估"><a href="#特征评估" class="headerlink" title="特征评估"></a>特征评估</h4><p>特征评估是指选取特定的数据集对特征进行综合评估，以决定对特征模块的下一步处理方式。特征评估一般包括<strong>覆盖率</strong>、<strong>离散度</strong>、<strong>时间相关性</strong>、<strong>稳定性</strong>和<strong>效果</strong>等方面。</p><ol><li><p>特征覆盖率<br>特征覆盖率检查首先可以检查出覆盖率较低的特征，避免输出；其次可以发现覆盖率异常的特征，进而反推出检查原始数据字段是否有之前的问题。<br>特征覆盖率检查的实现一般是比较简单的，直接计算样本集中非空特征占比即可。</p></li><li><p>特征离散度<br>特征离散度是指特征值分布的离散程度。<br>计算特征离散程度时通常使用变异系数，与极差、方差和标准差相比，变异系数不受数据量纲的影响，但是只在平均值不为 <code>0</code> 时才有意义。</p></li><li><p>特征时间相关性<br>特征时间相关性衡量特征值与时间的相关性。特征时间相关性检查能发现一些与时间强相关当无意义的特征。<br><small>实际中 <strong><code>Pearson</code> 相关系数</strong>大于 <code>0.8</code>，表明特征与时间存在强相关性，应当谨慎使用。</small></p></li><li><p>特征稳定性<br>特征稳定性主要使用 <strong><code>PSI</code>（<code>Population Stability Index</code>，群体稳定性指标）</strong>来表示。<br>在实际风控业务中，对于 <code>PSI &gt; 0.1</code> 的特征需要关注并分析原因，然后根据原因是否可接受来决定特征是否继续使用。<br><small>在样本量很小的时候，<code>PSI</code> 的波动情况可能会因为随机情况导致不能表示真实的业务情况。</small></p><table><thead><tr><th><code>PSI</code> 范围</th><th>稳定性</th><th>表现&#x2F;建议</th></tr></thead><tbody><tr><td><code>0</code> ~ <code>0.1</code></td><td>好</td><td>特征基本稳定</td></tr><tr><td><code>0.1</code> ~ <code>0.25</code></td><td>略不稳定</td><td>持续监控后续变化</td></tr><tr><td>大于 <code>0.25</code></td><td>不稳定</td><td>剧烈变化，分析原因，找到应对方案</td></tr></tbody></table></li><li><p>特征效果<br>特征效果通常使用 <code>IV</code> 值来衡量。<br>在评价特征区分度时，为了消除样本数据本身差异的影响，可以预先选择基准特征作为参考。基准特征有两种选择方式：</p><ul><li>选择效果已知的特征，在同一个数据集上对比两个特征的效果。</li><li>在特征子模型中引入随机变量，查看随机变量的重要性排序，方便评估特征模块的整体效果。<br> <small>重要性排在随机变量之后的特征可以被视为无区分度而不输出。</small></li></ul></li></ol><h4 id="特征上下线"><a href="#特征上下线" class="headerlink" title="特征上下线"></a>特征上下线</h4><p>特征开发完成并评估有效后会部署上线，在上线运行期间需要持续监控，当数据源不可用或者特征版本更新时，就会涉及到特征下线操作。</p><ol><li><p>特征上线<br>特征上线一般分为两种方式：</p><ul><li>实时计算部署，即接受计算请求后在线获得原始数据并实时计算特征。实时计算的特征需要同时在线上系统和离线回溯系统中部署。</li><li>离线批量计算方式部署，即离线计算好所有客户的特征，并推送到线上等待调用。为此需要保证特征更新机制正常运行，上线前需要进行充分的测试。</li></ul><p> 特征上线之后通常需要先<strong>空跑</strong>，而不先应用于模型或规则。在线上积累足够多的样本之后，此时需要进行线上验证。上线验证通常包含三个方面：</p><ul><li>数据源接入验证<br>  首先确认特征依赖的数据源是否已上线或同时上线；其次检查所有数据是否已正常接入且数据格式正确；接下来确认数据调用位置是否正确；最后确认数据源的更新频率是否符合预期。</li><li>特征统计分析<br>  主要包含三个方面：特征线上维度、覆盖率、缺失值填充方式和分布是否符合预期；特征监控配置是否正确；特征离线回溯是否正常运行。</li><li>特征稳定性验证<br>  取近期的线下样本计算特征，然后与线上样本特征计算 <code>PSI</code>。</li></ul></li><li><p>特征下线<br>特征下线通常发生在数据不可用或特征升级后新版本特征已经覆盖旧版本时，及时下线特征可以节省线上资源。<br>特征的下线需要注意以下几点：</p><ul><li>无策略或特征引用此特征。</li><li>不影响原始数据落表。</li><li>若后续评估特征效果，则需要判断是否积累足够的样本。</li></ul></li></ol><hr><h3 id="挖掘特征"><a href="#挖掘特征" class="headerlink" title="挖掘特征"></a>挖掘特征</h3><h4 id="特征衍生"><a href="#特征衍生" class="headerlink" title="特征衍生"></a>特征衍生</h4><p>在现有特征的基础之上，可以使用 <code>GBDT</code>、神经网络等算法构建模型，而模型的中间产出或输出结果作为新的特征。</p><ol><li><p>树模型算法<br>使用已有特征训练 <code>GBDT</code> 模型，再利用模型中的树的叶子节点构造新特征，此思路源于 <code>Facebook</code> 发表的 <code>Practical Lessons from Predicting CLicks on Ads at Facebook</code> 论文。<br>按照这种思路构造的新特征向量取值是 <code>0</code> 或 <code>1</code>，向量中的每个元素对应 <code>GBDT</code> 模型中的树的叶子节点，特征长度等于集成模型中所有树的叶子节点之和。当一个样本点通过某棵树最终落在其一个叶子节点上时，新特征向量中的这个叶子节点对应的元素取值为 <code>1</code>，而这棵树的其他叶子节点对应的元素取值为 <code>0</code>。</p></li><li><p>聚类算法<br>聚类算法在特征挖掘中的主要应用是基于已有特征进行样本聚类，并将聚类结果作为新特征。<br>算法原理：聚类算法是一种无监督算法。<code>K-means</code> 是典型的聚类算法，原理如下：</p><ul><li>初始时，随机选择 <code>k</code> 个质心。</li><li>把每个观测划分到离他最近的质心，并与质心形成新的类。</li><li>重新计算每个类的质心。</li><li>重复第二、三步骤。迭代停止条件为质心不变或达到最大迭代次数。</li></ul></li></ol><p> 聚类完成之后，可以针对最终生成的 <code>N</code> 个聚类算法，输出样本 <em>是否属于聚类 <code>X</code></em> 特征或样本 <em>与聚类质心得距离</em> 特征。</p><h4 id="文本特征挖掘"><a href="#文本特征挖掘" class="headerlink" title="文本特征挖掘"></a>文本特征挖掘</h4><p>文本特征挖掘是指把文本数据转换为特征。文本数据加工成特征的方法包括常规的提取关键词和直接使用文本挖掘类算法将文本转换为向量。</p><ol><li><p>文本特征提取方法<br>词袋（<code>bag of words</code>）模型是最初的将文本表示成向量的方法。<br>词袋模型将文本看作一系列单词的集合，即把一段文本当作一个 <em>袋子</em>，里面装的是 <em>单词</em>。词袋模型一般需要收集一些文本，并将它们作为模型建立的基础，而这些文本被称为语料（<code>corpus</code>），经过筛选、加工和标注等处理后，大批语料构成的数据库称为 <strong>语料库</strong>。<br>词袋模型的基本原理是先构建词典，再根据文本中的单词在词典中出现的频率生成文本的向量，生成的向量与单词在原文本中出现的次序没有关系。生成向量主要有两种方法：基于词频统计的方法和基于 <code>TF_IDF</code>（<code>Term Frequency - Inverse Document Frequency</code>）算法的方法。前者简单统计文本中的单词出现的次数，后者综合 <em>考虑</em> 单词出现的频率和在整个语料库中的 <em>稀有程度</em>。<br><small><code>TF_IDF</code> 等于 <code>TF</code> 和 <code>IDF</code> 的乘积，其中 <code>TF</code> 表示单词出现的频率，即某个单词在当前文本中出现的次数；<code>IDF</code> 是逆文档频率，<code>DF</code> 表示语料库中包含某个单词的文档的数目，<code>IDF</code> 即反映某个单词在整个语料库中的重要性。</small></p></li><li><p>文本分类算法<br>再除了将文本表达为向量方式外，还有一些直接基于文本进行分类的算法，算法会输出一个概率，这个概率可以在后续的模型中使用。</p><ul><li>朴素贝叶斯算法</li><li><code>fastText</code> 算法</li></ul></li></ol><h4 id="图特征挖掘"><a href="#图特征挖掘" class="headerlink" title="图特征挖掘"></a>图特征挖掘</h4><p>之前介绍了使用邻接矩阵表示图结构，当邻接矩阵通常是 <em>高维且稀疏</em> 的，为了利用图的优势并构建有效的机器学习模型，需要得到高效的关系网络数据表示方法，这正是<strong>图表示学习</strong>的范畴。<br><small><strong>表示学习</strong>是指机器学习模型自动学习数据中隐含的有效特征。</small></p><p>图表示学习也称<strong>图嵌入（<code>graph embedding</code>）</strong>，其主要目标是将图转换为 <em>低维且稠密</em> 的向量，并近可能保持图原有的拓扑关系。图表示学习生成的图特征向量可以作为图任务学习的输入。<br>图表示学习主要包含三种方法：</p><ul><li>基于矩阵分解的方法<br> 通过对邻接矩阵进行矩阵分解，将节点转换到低维向量空间，同时保留图结构。</li><li>基于随机游走的方法<br> 借鉴词向量的表示方法将图的节点看作词，将在图中随机游走而产生的序列看作句子，然后借助 <code>Word2Vec</code> 算法学习得到图节点的表示，该方法使用的典型算法有 <code>DeepWalk</code> 和 <code>Node2Vec</code>。</li><li>基于深度学习的方法<br> 基于图神经网络的图表示学习，可以用于图表示学习的图神经网络算法有图卷积神经网络、图自编码器和图注意力网络。</li></ul><ol><li><p>基于随机游走的方法<br>基于随机游走（<code>random walk</code>）的方法将在图中随机游走而产生的序列看作句子，之后借助 <code>Word2Vec</code> 算法学习得到图节点的表示。在随机游走序列的生成方面，共有两种不同的思路：</p><ul><li><code>DeepWalk</code> 算法。</li><li><code>Node2Vec</code> 算法。</li></ul></li><li><p>图卷积神经网络<br>图卷积神经网络是图神经网络（<code>Graph Neural Network, GNN</code>）的一种，是将卷积神经网络应用于图表示学习而得到的。<br>卷积神经网络处理的图像数据是整齐的矩阵格式，转换成关系网络结构来看其节点的邻居数量是固定的；而图网络属于非欧几里得空间结构，节点的邻居数量不固定。因此在欧几里得空间内，不能直接将用固定大小的卷积核抽象图像像素特征的操作迁移到图结构，其本质是找到适用于图的可学习卷积核；而图卷积神经网络则是以图卷积层为主体，堆叠多层的神经网络模型。</p></li></ol><hr><h3 id="特征画像体系"><a href="#特征画像体系" class="headerlink" title="特征画像体系"></a>特征画像体系</h3><p>风控特征画像是从多个角度描述客户风险的工具。为了描述客户风险需要对客户有全面准确的认识，其中风控特征画像可以从多个维度尽量全面地描述客户在多个维度的风险属性，其中维度的细分更加有助于准确地刻画每个具体维度的差异，从而达到准确认识客户的目的。</p><h4 id="营销阶段"><a href="#营销阶段" class="headerlink" title="营销阶段"></a>营销阶段</h4><p>在营销特征数据中，对于历史存量客户，包含有客户基本信息、历史申请信息和多头借贷信息；对于新客户，数据较少，当包含有浏览行为数据、客户的基本部分信息和第三方数据。<br>客户基本信息主要是客户在历史申请时自填的信息，通常包含客户本人的学历、年龄、性别、从事行业和居住地等；对于多头借贷信息，通常包含从第三方数据中的客户在多个机构的申请、放款和预期情况；历史申请记录是指客户在本机构的历史申请情况。<br><img src="https://s2.loli.net/2022/11/20/XR56qJrCynM2hBu.png" alt="risk_2_4.jpg"></p><h4 id="贷前阶段"><a href="#贷前阶段" class="headerlink" title="贷前阶段"></a>贷前阶段</h4><p>贷前特征画像主要应用在反欺诈、信用风险评估和风险定价阶段，主要考虑的目标是客户的还款能力、守约概率等。<br><img src="https://s2.loli.net/2022/11/20/dJknRCaK4Y1shfM.png" alt="risk_2_5.jpg"></p><h4 id="贷中阶段"><a href="#贷中阶段" class="headerlink" title="贷中阶段"></a>贷中阶段</h4><p>在数据维度上，贷中特征画像可以使用贷前特征画像的所有数据，另外还能使用当前未完结（或已完结）订单的数据、贷中行为埋点数据、审批结果和还款提醒数据等。<br><img src="https://s2.loli.net/2022/11/20/GXLlVS8JsRxYfFa.png" alt="risk_2_6.jpg"></p><h4 id="贷后阶段"><a href="#贷后阶段" class="headerlink" title="贷后阶段"></a>贷后阶段</h4><p>贷后特征画像主要反映客户在贷后的违约风险（主要体现客户还款的意愿和能力），可以将其应用于贷后风险模型或规则中。<br><img src="https://s2.loli.net/2022/11/20/deDc1bOEYiUxT5l.png" alt="risk_2_7.jpg"></p><hr><h3 id="监控和异常处理"><a href="#监控和异常处理" class="headerlink" title="监控和异常处理"></a>监控和异常处理</h3><p>特征监控是指监控特征的准确性、有效性、稳定性和一致性，以及特征依赖的原始字段的分布情况。通过特征监控能够及时发现原始字段或特征分布的偏移，以便分析原因并采取合理的方式来处理，避免特征异常带来的损失。</p><h4 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h4><ol><li><p>一致性<br>特征的一致性监控是指监测<strong>特征离线回溯与线上调用是否一致</strong>，以及线上不同时间点的调用是否一致，其通常包括特征的<strong>线上与线下一致性</strong>，以及特征的<strong>前后一致性</strong>。</p><ul><li>特征的线上与线下不一致是指对同一个客户，基于相同业务时间，离线回溯计算的特征值和线上调用特征计算的结果不一致。</li><li>特征前后不一致是指对于同一个客户，基于相同业务时间点，在不同时间点回溯计算特征时会得到不同结果。</li><li>特征的一致性监控方法通常定期采样一定比例的客户离线回溯特征，并将其与线上调用特征进行对比。</li></ul><p> <small>特征监控以小时、天、周或月为周期，监控结果可采用邮件方式反馈和可视化报表方式展示。</small></p></li><li><p>原始字段分布<br>原始字段分布监控是指监测原始字段分布的变化情况。原始字段的分布变化通常会带来相关特征取值分布的变化，对原始字段监控可以进行监控可以直接、迅速地发现潜在的数据问题。<br>原始字段分布监控包含覆盖度监控和取值分布监控。覆盖度监控即将最近一段时间的客户按天汇总，监控空值占比的变化。<br>原始字段的覆盖率可以用偏差率 <code>r</code> 来表示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r = |x - base| / base</span><br></pre></td></tr></table></figure><p><small><code>x</code> 为监控时段覆盖度，<code>base</code> 为基准覆盖度。通常设置 <code>r &gt; 0.1</code> 时触发预警。</small></p></li></ol><h4 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h4><p>特征异常处理是指在发现特征异常时，需要快速分析原因并给出解决方案，尽量减少异常对线上业务的影响。</p><ol><li><p>特征不一致<br>特征不一致的原因通常包含三种：</p><ul><li>在线数据和离线数据不一致。</li><li>在线特征和离线特征的处理逻辑不同。</li><li>数据状态曾发生变化。</li></ul></li><li><p>原始字段异常<br>原始字段的覆盖率及取值分布出现异常的原因会有多种，通常数据采集、处理、存储和应用环节都有可能出现上述异常，业务团队需要和技术团队配合，具体问题具体分析。</p></li></ol><hr><h3 id="术语介绍"><a href="#术语介绍" class="headerlink" title="术语介绍"></a>术语介绍</h3><ol><li><p>原始数据<br>原始数据是业务中产生的各类数据，通常是为了业务目的而组织和保存的底层数据，相对于建模使用的特征，原始数据一般是<strong>未经汇总处理的数据</strong>。</p></li><li><p>特征工程<br>特征工程是在给定数据、模型和任务的额情况下设计合适特征的过程。特征工程包含<strong>特征挖掘</strong>、<strong>特征筛选</strong>、<strong>特征组合应用</strong>等。</p></li><li><p><code>IV</code> 值<br><code>IV</code> 即信息价值（<code>Information Value</code>）也可称为信息量。 <code>IV</code> 值是用来衡量变量的预测能力，IV值越大，表示该变量的预测能力越强。</p><table><thead><tr><th><code>IV</code> 范围</th><th>描述</th></tr></thead><tbody><tr><td>iv &lt; 0.02</td><td>无预测能力，需放弃</td></tr><tr><td>0.02 &lt;&#x3D; iv &lt; 0.1</td><td>较弱的预测能力</td></tr><tr><td>0.1 &lt;&#x3D; iv &lt; 0.3</td><td>预测能力一般</td></tr><tr><td>0.3 &lt;&#x3D; iv &lt; 0.5</td><td>预测能力较强</td></tr><tr><td>iv &gt; 0.5</td><td>预测能力极强，需检查</td></tr></tbody></table></li><li><p><code>WOE</code> 值<br><code>WOE</code> 即证据权重（<code>Weight of Evidence</code>），<code>WOE</code> 是对原始自变量的一种编码形式。要对一个变量进行 <code>WOE</code> 编码，需要首先把这个变量进行分组处理（也叫离散化、分箱），分组后，对于第 <code>i</code> 组 <code>WOE</code> 的计算公式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WOEi = ln((Yi/Yt) / (Ni/Nt)) = ln(Pyi/Pni)</span><br></pre></td></tr></table></figure><p><small><code>Pyi</code> 是该组中响应客户在该组中的比例。<code>Pni</code> 是该组中未响应客户在该组中的比例。<code>Yi</code> 是该组中响应客户数据量。<code>Ni</code> 是该组中该组中未响应客户数据量。<code>Yt</code> 是该组中响应客户总数据量。<code>Nt</code> 是该组中未响应客户总数据量。响应客户指正样本，未响应客户指负样本。</small></p></li><li><p><code>PSI</code> 值<br>特征稳定性主要使用 <strong><code>PSI</code>（<code>Population Stability Index</code>，群体稳定性指标）</strong>来表示。<br>在实际风控业务中，对于 <code>PSI &gt; 0.1</code> 的特征需要关注并分析原因，然后根据原因是否可接受来决定特征是否继续使用。<br><small>在样本量很小的时候，<code>PSI</code> 的波动情况可能会因为随机情况导致不能表示真实的业务情况。</small></p><table><thead><tr><th><code>PSI</code> 范围</th><th>稳定性</th><th>表现&#x2F;建议</th></tr></thead><tbody><tr><td><code>0</code> ~ <code>0.1</code></td><td>好</td><td>特征基本稳定</td></tr><tr><td><code>0.1</code> ~ <code>0.25</code></td><td>略不稳定</td><td>持续监控后续变化</td></tr><tr><td>大于 <code>0.25</code></td><td>不稳定</td><td>剧烈变化，分析原因，找到应对方案</td></tr></tbody></table></li></ol><hr><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><hr><h3 id="个人备注"><a href="#个人备注" class="headerlink" title="个人备注"></a>个人备注</h3><p><strong>此博客内容均为作者学习所做笔记，侵删！</strong><br><strong>若转作其他用途，请注明来源！</strong></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h3&gt;&lt;p&gt;特征挖掘是从原始数据构造特征的过程。&lt;br&gt;特征是数据和模型之间的纽带，数据和特征决定机器学习的上限，而模型和算法只是无限逼近这个上限。&lt;br&gt;特征挖掘的完整流程包含&lt;strong&gt;原始数据分析&lt;/strong&gt;、&lt;strong&gt;数据清洗&lt;/strong&gt;、&lt;strong&gt;中间数据集构建&lt;/strong&gt;、&lt;strong&gt;特征设计和生成&lt;/strong&gt;、&lt;strong&gt;特征评估&lt;/strong&gt;和&lt;strong&gt;特征的上线、监控、维护和下线&lt;/strong&gt;。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Risk" scheme="https://blog.vgbhfive.cn/tags/Risk/"/>
    
  </entry>
  
  <entry>
    <title>智能风控-策略体系</title>
    <link href="https://blog.vgbhfive.cn/%E6%99%BA%E8%83%BD%E9%A3%8E%E6%8E%A7-%E7%AD%96%E7%95%A5%E4%BD%93%E7%B3%BB/"/>
    <id>https://blog.vgbhfive.cn/%E6%99%BA%E8%83%BD%E9%A3%8E%E6%8E%A7-%E7%AD%96%E7%95%A5%E4%BD%93%E7%B3%BB/</id>
    <published>2022-10-31T04:03:37.000Z</published>
    <updated>2023-01-01T15:42:54.922Z</updated>
    
    <content type="html"><![CDATA[<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>风控策略是指根据<strong>不同业务场景和客群</strong>，通过<strong>一系列规则策略与模型策略的组合</strong>，对<strong>客户的风险进行判断</strong>，从而实现<strong>准入</strong>、<strong>反欺诈</strong>、<strong>授信</strong>、<strong>风险定价</strong>和<strong>催收</strong>等阶段目标，最终<strong>达成风险控制</strong>的目的。</p><span id="more"></span><p>风控策略的核心目标是将风险控制在合适的范围。但是风险并不是越低越好，应该在遵守监管政策和满足客户利益的前提下，实现收益的最大化。要想收益的最大化，因此也要了解信贷业务的利润组成，其中<strong>信贷业务的利润 &#x3D; 息费收入 - 运营成本 - 坏账损失</strong>。</p><p><strong>息费收入</strong>是金融机构的主要收入来源。但是息费不是越高越好，因为首先需要满足金融行业的政策要求，其次息费的高低会直接影响信贷产品吸引的客群质量。因此我们需要制定合理的风险定价策略给予不同客户合适的费率。</p><p><strong>运营成本</strong>是指金融机构运营过程中产生的各项成本。运营成本主要包含有获客成本、数据成本、人力成本和资金成本等，因此需要在风险可控的前提下持续优化经营成本。</p><p><strong>坏账损失</strong>是评估金融机构中的业务是否健康的重要指标。当然坏账并不是越低越好，需要在业务的发展速度和盈利水平之间均衡。</p><p>因此金融机构应该通过合理定价以提高收入、优化流程以降低运营成本、改进风控策略以降低风险，找到风险与收益的平衡点，从而实现收益的最大化。</p><hr><h3 id="方法论"><a href="#方法论" class="headerlink" title="方法论"></a>方法论</h3><h4 id="规则分析方法"><a href="#规则分析方法" class="headerlink" title="规则分析方法"></a>规则分析方法</h4><p>规则是基于特征的一系列判断条件的组合，例如 <em>男性</em>、<em>年龄</em> 特征，制定 <em>年龄大于50岁且为男性</em> 规则。</p><p>规则策略是指通过一系列规则对客户进行细分筛选，使得筛选出来的客户在风险或其他维度上与未被选中的客户存在明显差异，从而可以拒绝客户或接受规则命中的客户。当然风控规则的作用也就是准确识别出高风险人群，然后拒绝这部分用户，从而有效规避特定风险。</p><p>相较于模型，规则的优势如下：</p><ul><li>规则能够识别出特定的风险点。</li><li>规则明确，具有可解释性。</li><li>规则的的灵活性高，可以根据风险变化对规则快速调整。</li></ul><p>关于规则如何产生通常有两种方法：</p><ul><li>人工。</li><li>量化。</li></ul><p><img src="https://s2.loli.net/2022/11/02/PsRdcLSo4VwbM3j.png" alt="risk_1_1.jpg"></p><h5 id="制订人工规则"><a href="#制订人工规则" class="headerlink" title="制订人工规则"></a>制订人工规则</h5><p>制订<em>人工</em>规则共分为两步：第一步就是寻找风险点。而第二步则是根据已知风险点制订人工规则。</p><ol><li><p>寻找风险点</p><ul><li>市场调研。指通过公开信息、同业反馈等方式进行调研，为风控策略提供可参考与借鉴的风险信息。</li><li>信审人员和催收人员反馈。信审人员与催收人员会审阅贷款申请人的相关资料，或者通过电话与其直接沟通，此过程容易发现异常案件。</li><li>关联图谱识别。关联图谱是一种基于图的数据结构，是借款人之间有效的关系表达式。通过分析关联图谱，可以及时发现复杂关系中存在的潜在风险。</li><li>黑产分析。指通过互联网或者线下渠道收集相关得到欺诈情报或者线索，并基于此开展专题分析。</li><li>实时数据监控。通过分析和监控设备指纹（<code>IMEI</code>、<code>WIFI</code>）聚集性、地点（<code>GPS</code>、申请中的自填地址）聚集性发现其潜在的风险。</li></ul></li><li><p>根据风险点制订人工规则<br>制订人工规则是指将风险点识别的过程中的潜在风险点量化成规则。其大致过程就是设计特征和规则阈值，为了使规则具有更好的灵活性，需要考虑特征的兼容性和可塑性。</p></li></ol><h5 id="制订量化规则"><a href="#制订量化规则" class="headerlink" title="制订量化规则"></a>制订量化规则</h5><p><em>人工</em>规则的制订主要依靠业务经验和市场调查结果为依据，<em>量化</em>规则则是基于数据与事实。</p><ol><li><p>样本选取<br>样本选取需要遵守<strong>代表性</strong>、<strong>充分性</strong>、<strong>时效性</strong>和<strong>排除性</strong>四个原则。其中对时效性的要求最高，需要选择使用最近的有表现的样本集，因为只有近期样本的贷后风险才能代表当前环境下真实的风险情况。<br>在样本集选取结束后还需要对样本集进行划分，一般划分为<strong>训练集（<code>Train</code>）</strong>和<strong>验证集（<code>OOT</code>）</strong>，其中训练集用于规则开发，而验证集则用于规则效果验证。当然数据集的划分也是有其必要性，训练集保证规则有效的同时，验证集校验规则未来的适用性。</p></li><li><p>单规则的制订<br>单规则是指由单个特征形成的风险规则。其优点是可解释性较强，便于线上监控和调整。单规则的制订有 <strong><code>IV</code> 分析法</strong>和<strong>极端值检测法</strong>两种方式：</p><ul><li><code>IV</code> 分析法<br>  <code>IV</code> 分析法是指基于<strong>特征分箱</strong>后的结果与目标变量进行交叉统计，通过 <code>IV</code> 值的大小选择对目标变量区分度大的特征，计算特征每一分箱对应的逾期率，发现特征中高风险的分箱区间，从而提取有效的风险规则。<br>  <small>特征分箱是指将连续特征离散化，通常选择<strong>等距分箱</strong>或<strong>决策树分箱</strong>方式进行特征分箱，不使用<strong>等频分箱</strong>是因为等频分箱会将少数极端样本与正常样本划分到一箱，<strong>掩盖</strong>可能的高风险群体。</small></li><li>极端值检测法<br>  极端值检测方式假定不良（<code>bad</code>）客户区别于其他客户，不良客户在特征上的表现集中在极端值处，即特征值越小或越大，不良客户的<em>比例</em>越高。基于此可以使用<strong>分位数</strong>，枚举可能的极端值将其作为阈值，然后制订单规则。<br>  但是使用极端值检测方式容易受到样本量小的影响而产生波动，因此需要均衡考虑<strong>规则命中率（<code>hit_rate</code>）</strong>和<strong>命中坏样本率（<code>hit_bad_rate</code>）</strong>的关系。</li></ul></li><li><p>组合规则的制订<br>组合规则是指基于常识、业务经验和数据挖掘技术，将两个或多个不同特征进行组合而形成的规则。相比单规则，组合规则可以筛选出同时满足多个特征的细分人群，实现人群的精准刻画。</p></li></ol><h5 id="规则评估"><a href="#规则评估" class="headerlink" title="规则评估"></a>规则评估</h5><p>在制订规则后需要对规则进行合理评估。评估规则可以帮助我们从不同的角度发现规则的价值和不足。</p><ol><li><p>规则效果<br>规则效果是规则评估的重要维度。在不同的时间窗口，规则效果评估的差异较大，则需要判断是规则无效还是客群变化引起的，必要时需要及时调整规则阈值，然后再次进行评估。<br>规则的效果主要体现在<strong>样本逾期率（<code>hit_bad_rate</code>）</strong>和<strong>整体逾期率（<code>total_bad_rate</code>）</strong>的倍数差异，即<strong>提升度（<code>lift</code>）</strong>。因此需要根据业务经验，确定提升都或者判断命中样本逾期率的值是否达到业务拒绝阈值，以确定规则是否有效。<br><small><code>left</code> 为规则提升度，表示此规则对不良客户的识别能力高于随机识别的倍数。</small></p></li><li><p>规则的稳定性<br>规则的稳定性主要体现在时间窗口的规则命中率、命中量是否稳定。在训练集中命中样本较少的规则一般来说都不太稳定，有可能是随即导致的，因此需要重点验证其在验证集样本上的命中率和逾期率的稳定性。</p></li><li><p>规则的收益性<br>规则能够拒绝一部分不良客户，但是有时候还是会 <em>误伤</em> 一部分的好客户，另外规则本身可能有额外的数据成本，因此我们需要对规则的收益性进行评估。<br>规则的收益性评估是指从 <em>利润最大化</em> 角度出发，评估引入的规则是否能真正为业务带来利润。<br><strong>规则收益性评估</strong>主要包含以下方面：</p><ul><li>数据单价：规则所使用的数据源单词调用价格。</li><li>命中率：外部规则在放款样本上的命中率。</li><li>规则命中坏账率：命中放款样本上的坏账率。</li><li>盈亏平衡坏账率：当坏账率为此数值时，放款的收益等于成本与损失之和。</li><li>件均：放款金额平均值。</li></ul></li></ol><h5 id="规则上线"><a href="#规则上线" class="headerlink" title="规则上线"></a>规则上线</h5><p>规则上线是将已经制订完成且评估有效的规则在决策引擎中进行配置并发布到生产环境中。<br><strong>决策引擎</strong>是一套用于部署风控规则、机器学习模型，进行风控策略实验并输出决策结果的系统。决策引擎为风控策略的快速实施带来了极大便利，其主要功能包括配置规则、决策表、评分卡、决策流、模型管理、额度管理和账期利率管理等。</p><p>在规则上线之后我们需要对已上线的规则进行及时的验证，确保规则执行与预期一致，通常从以下四个方面进行验证：</p><ul><li>阈值是否正确<br>  判断线上应用的规则阈值与线下制订规则时的阈值是否一致。</li><li><code>A/B</code> 测试分流比例是否正确<br>  <code>A/B</code> 测试分流比例也是验证项之一，如果决策引擎中 <code>A/B</code> 测试分流比例配置正确，那么正常情况下实际分流比例与配置比例基本一致。</li><li>规则命中率是否正常<br>  <strong>规则命中率</strong>是触发规则与进入规则数量的比值。规则命中率异常将直接导致影响线上实际业务的<strong>风控转化率</strong>。</li><li>规则回顾<br>  规则回顾是指对线上测试中的 <strong>空跑</strong> 或者 <strong>阈值实验</strong> 分流组再次进行效果评估，目的是验证规则上线后的实际效果是否得到延续。</li></ul><h4 id="模型策略分析方法"><a href="#模型策略分析方法" class="headerlink" title="模型策略分析方法"></a>模型策略分析方法</h4><p>模型策略是基于已有风控模型制订最优决策的整体方法，已有风控模型决定了模型价值是否能够被充分发挥，直接影响信贷业务的盈利水平。<br><strong>模型策略分析流程</strong>主要包含<strong>样本提取</strong>、<strong>模型策略的制订</strong>、<strong>模型策略评估</strong>、<strong>模型策略的上线与验证</strong>和<strong>模型策略回顾</strong>。<br><img src="https://s2.loli.net/2022/11/07/4clL1UGfB7sj2dI.png" alt="risK_1_2.jpg"></p><ol><li><p>样本选取<br>样本选取是指选取制订模型策略所需的样本集，通常包括风控模型开发的<strong>跨时间验证集（<code>OOT</code>）</strong>和<strong>近期授信样本集（<code>BackScore</code>）</strong>。跨时间验证集需要包含订单标识、模型分和逾期标签列，近期授信样本集需要包含订单标识和模型分列。</p></li><li><p>模型策略的制订<br>模型策略的制订主要决定模型的组合方式和阈值。在制订方案时需要平衡转化率和坏账率之间的关系，以实现收益最大化。<br>模型策略应用方案可分为以下两种：</p><ul><li>单模型策略<br>  单模型策略是指利用<strong>单一模型分</strong>进行决策，故只需要确定单一模型的最优决策点。通常单模型适用于以下场景：信贷业务开展前期，线上只有一个模型；信贷业务开展中期，虽然线上模型增多，但模型间关联性较强。<br>  单模型通常有以下几种制订方式：<ul><li>基于模型通过率和坏账率的决策点设定<br>  在模型通过率和坏账率之间寻找一个决策点，理想的状态是该决策点的设立可以提高通过率并降低坏账率，但是在现实中则会出现其他情况：保持目标模型通过率，降低坏账率；提升模型通过率，保持坏账率；提高模型通过率，同时降低坏账率。</li><li>基于 <code>lift</code> 的决策点设定<br>  <code>lift</code> 表示风控模型对预测目标中不良客户的识别比例高于随机识别比例的倍数。通常情况下，<code>lift</code> 的值越大越好。</li></ul></li><li>多模型组合策略<br>  多模型组合策略是基于<strong>两个或多个以上模型分</strong>组合生成的模型应用方案。多模型的优势在于：能够充分发挥多个模型之间的性能互补；内外部模型组合的使用能够有效降低数据成本。<br>  多模型组合策略的应用方式有以下几种：<ul><li>多模型融合准入，通常是指利用加权或者其他方式将多个模型分融合成一个模型分，再划分风险等级上线决策。</li><li>多模型串行准入，通常是指将多个模型以串行的方式按照先后顺序依次决策准入，前一个模型决策通过的样本再经过下一个模型决策进行评估，以此类推，直至最后一个模型生成风险等级。</li><li>多模型交叉准入，通常分为两个阶段：准入阶段，由前置模型完成；交叉阶段，由后置的两个模型共同生成风险等级。</li></ul></li></ul></li><li><p>模型策略评估<br>从业务角度关注新模型和旧模型之间的性能差异，通常会用到<strong>交换集分析（<code>swap set analysis</code>）</strong>和<strong>拒绝推断</strong>：</p><ul><li>交换集分析<br>  交换集分析是指利用<strong>新旧模型通过和拒绝客户不一致</strong>的情况，通过<strong>分析这些不一致的客户对坏账率和通过率的影响</strong>以评价模型策略的效果。<br>  <strong>换出（<code>swap out</code>）</strong>是指新模型拒绝而旧模型通过的客群，<strong>换入（<code>swap in</code>）</strong>是指新模型通过而旧模型拒绝的客群。通常希望新模型能够换出更多的不良客户，换入更多的好客户，从而用好客户代替不良客户，以降低整体的坏账率。</li><li>拒绝推断<br>  如何进行合理的拒绝推断呢？最直接的方式就是<strong>利用新模型各分数段在有表现样本上的坏账率来估算旧模型拒绝样本上的坏账率</strong>。<br>  但是上述结果也是存在问题的，因为此时的坏账率是在旧模型通过的条件下计算出来的，而要想推断新模型的坏账率则需要进行一定的处理：<code>Universe Test</code> 推断；<code>A/B</code> 测试组推断；线性拟合推断。</li></ul></li><li><p>模型策略上线和验证<br>与规则上线类似，模型策略上线确保其线上实际执行效果与预期一致，主要有以下三个方面：</p><ul><li>模型<strong>阈值</strong>是否正确。</li><li><code>A/B</code> 测试的<strong>分流比例</strong>是否正确。</li><li><strong>模型通过率</strong>是否符合预期。</li></ul></li><li><p>模型策略回顾<br>模型策略回顾就是<strong>使用线上数据定期验证模型策略 <code>A/B</code> 测试</strong>的方案，最终基于比对的情况，选择适合当前环境的方案来进行决策。</p></li></ol><h4 id="额度-x2F-利率-x2F-账期策略分析方法"><a href="#额度-x2F-利率-x2F-账期策略分析方法" class="headerlink" title="额度&#x2F;利率&#x2F;账期策略分析方法"></a>额度&#x2F;利率&#x2F;账期策略分析方法</h4><p>额度&#x2F;利率&#x2F;账期策略是基于产品属性或客户的某些特性制订的差异化方案。在符合监管的要求下差异化的额度&#x2F;利率&#x2F;账期可以保证金融机构的收益最大化。从金融机构的收益角度来看，差异化的额度&#x2F;利率&#x2F;账期可以保持件均额度不变的情况下，有效降低金额损失率；或者在贷后损失率不变的情况下，提升件均额度，从而提高金融机构的利润。<br><img src="https://s2.loli.net/2022/11/08/yXwU8K3TmqupnNH.png" alt="risk_1_3.jpg"></p><ol><li><p>额度&#x2F;利率&#x2F;账期策略的制订<br>额度&#x2F;利率&#x2F;账期策略是设定借款人的授信额度方案，而额度策略又可以分为：</p><ul><li>单一额度策略。对于首贷用户可以设置相同的额度；而对于复贷用户，可以随着贷款次数逐步增加额度。</li><li>单因子额度策略。将单个维度数据作为额度差异化的依据，基于信用评分模型给出的风险等级给出差异化的额度。</li><li>多因子额度策略。将客户更多维度数据作为额度差异化的依据，使用多项数据组成额度矩阵根据用户的风险等级和还款能力组合出最适合的额度。</li></ul></li><li><p>策略评估<br>策略评估即对比使用前和使用后的真实贷后差异，如在件均不变的情况下，观察能够降低多少的坏账率。</p></li><li><p>策略的上线与验证<br>在明确策略的 <code>A/B</code> 测试方案后，需要在决策引擎中配置相应的方案，设置分流比例等其他参数，确保及时、准确地分布。<br>为了确保策略上线后的实际运行情况与预期一致，需要从以下三个方面进行验证：配置是否正确；<code>A/B</code> 测试分流比例是否正确；件均额度是否符合预期。</p></li><li><p>策略回顾<br>在策略的 <code>A/B</code> 测试方案线上稳定且有贷后数据表现时，需要及时进行策略回顾。因为即使同一风险等级，在有额度差异的情况下，坏账率也会存在显著差异，因此需要从利润最大化的角度来选择最适合的方案。另外随着信贷市场的变化，也需要重新定制新的 <code>A/B</code> 测试方案，如此才会适应市场变化，满足客户需求。</p></li></ol><h4 id="A-B-测试"><a href="#A-B-测试" class="headerlink" title="A/B 测试"></a><code>A/B</code> 测试</h4><p><code>A/B</code> 测试也可以被成为冠军挑战者实验，是指在同一时间、同一对象上测试多种方案，并通过分析找到最优的方案。也就是说需要提前式设计多种方案，然后对同一客群的不同客户应用不同方案，分别记录每种方案对应客户的使用或转化指标，最后通过分析选择出最优的方案，并确定是否要推广到全部流量中。</p><ol><li><p>方案设计<br><code>A/B</code> 测试方案设计主要包含：确定实验组和对照组的内容；流量分配。<br>在金融风控领域，<code>A/B</code> 测试主要用来验证新旧模型或规则的效果是否存在显著差异，即实验组对应新模型策略，对照组对应旧模型策略。在流量分配方面，因为新模型策略的实际效果未知，因此一旦出错容易造成资金流失。最终在流量分配方面，实验组会获得少量流量，对照组会获得较多流量。<br><img src="https://s2.loli.net/2022/11/09/HrSZNfTems8L1ob.png" alt="risk_1_4.jpg"></p></li><li><p>测试结果分析<br><code>A/B</code> 测试结果分析主要基于两部分：</p><ul><li>实验有效性判断，主要包含：判断测试的样本量是否达到所需的最小样本量，从而可以尽快可能地避免两类统计（无效判断为有效，有效判断为无效）错误的发生；判断样本的有效性，即判断采用 <code>A/A</code> 测试结果得到两组之间是否存在显著差异，若不存在显著差异，则任务测试效果有效。</li><li>测试结果的比较，在对测试有效性判断之后，就可以对结果进行比较，通常会比对实验组和对照组的结果，判断他们之间是否存在显著差异，从而判断新旧方案在业务方面是否有显著提升。</li></ul></li><li><p>注意事项</p><ul><li>流量分配，要保证同时性、同质性、唯一性和均匀性。</li><li>上线后的数据验证，确保实验组和对照组指标符合预期，否则需要排查和修复异常并重新开始测试。</li><li>多测试同时展开，不是同时开展一个测试，在确保其他变量可控和流量可分的情况下，可以开展多个测试。</li></ul></li></ol><hr><h3 id="策略体系搭建"><a href="#策略体系搭建" class="headerlink" title="策略体系搭建"></a>策略体系搭建</h3><p>风控策略体系的搭建是指贯穿营销、贷前、贷中和贷后的完整策略体系架构，因此需要在各个阶段设置合适的风控策略，灵活运用规则和模型的组合，才能做到有效的风险控制并取得收益最大化。</p><h4 id="营销阶段"><a href="#营销阶段" class="headerlink" title="营销阶段"></a>营销阶段</h4><p>营销策略是指在营销获客阶段执行的策略，用于排除高风险客户，选择高响应客户，以达到降本增效的目的。<br>从客户的类型来划分，营销可以分为针对<strong>纯新客的营销</strong>和<strong>存量客户的营销</strong>。纯新客是指没有在本金融机构完成借款的客户，金融机构可以获取的客户信息较少；而存量客户是指在本金融机构已经存在借款记录的客户，金融机构可以获得的信息较为丰富。<br>从客户的来源来划分，可以分为已有名单的客户和第三方导流的客户，虽然客户的来源不同，但是基本的营销策略类似，都是排除高风险客户，然后选择高响应客户，最后针对高响应客户进行营销和接下来的授信。</p><ol><li><p>排除高风险客户<br>排除高风险客户可以采用以下措施：</p><ul><li>黑名单。此部分数据来源于营销名单中的黑名单和逾期客户的黑名单。</li><li>风险规则。</li><li>流量筛选模型。</li></ul></li><li><p>选择高响应客户<br>排除高风险客户之后，可以进一步对营销概率更高的客户进行筛选，选择高响应客户可以采用以下措施：</p><ul><li>高响应规则。</li><li>营销响应模型。</li></ul></li></ol><h4 id="贷前阶段"><a href="#贷前阶段" class="headerlink" title="贷前阶段"></a>贷前阶段</h4><p>贷前策略是针对客户的信贷申请制订的策略，用于拦截逾期概率高的客户，并对客户匹配合适的产品。贷前策略主要包括<strong>风险准入策略</strong>、<strong>反欺诈策略</strong>、<strong>信用评估策略</strong>和<strong>贷前额度策略</strong>。</p><ol><li><p>风险准入策略<br>风险准入策略是判断借款客户身份是否符合当前业务准入条件的策略。风险准入策略可以降低非目标客户带来的风险，其主要是依据信贷产品定位和政策要求制订，主要包含<strong>身份信息认证</strong>、<strong>基础信息准入</strong>、<strong>黑&#x2F;白名单策略</strong>和<strong>其他准入策略</strong>。</p><ul><li>身份信息认证。<br>  身份认证信息包含<strong>身份证信息认证</strong>、<strong>人脸比对认证</strong>、<strong>银行卡四要素认证</strong>和<strong>运营商三要素</strong>。</li><li>基础信息准入。<br>  基础信息准入是判断借款人是否符合当地的信贷政策，以验证客户身份是否符合法律法规和相关的政策要求。基础信息的准入可以归纳为：<strong>年龄准入</strong>；<strong>贷款用途准入</strong>；<strong>地域准入</strong>；<strong>行业准入</strong>。</li><li>黑&#x2F;白名单策略。<br>  黑名单包含金融机构拒绝放款的客户，主要包含有<strong>历史严重逾期客户</strong>、<strong>存在欺诈行为客户</strong>、<strong>存在违法行为客户</strong>和<strong>恶意投诉客户</strong>。<br>  白名单是金融机构将资产信用良好的客户单独整理出来的名单，与黑名单相比，白名单是命中即通过。</li><li>其他准入策略。<br>  金融机构根据自身的风险偏好，根据历史记录得出的一些简单、可靠的判断准则纳入风险准入策略。</li></ul></li><li><p>反欺诈策略<br>反欺诈策略是为了防范恶意客户采取欺诈行为谋取利益的策略，目的是通过对欺诈行为的识别，遏制欺诈风险，及时止损。<br>目前应对欺诈风险的有效措施包括<strong>反欺诈规则</strong>和<strong>反欺诈模型</strong>。</p><ul><li>反欺诈规则。<br>  反欺诈规则的优点：能够有效遏制特定的欺诈行为；可解释性强，应对欺诈手段可以快速调整。<br>  常见的反欺诈规则如下：<ul><li><code>ID</code> 关联异常。例如身份证号、手机号、银行卡号和设备号存在一对多的异常关联。</li><li><code>App</code> 操作行为异常。例如操作时间过短或某些操作之间的时间间隔过短。</li><li>位置行为异常。例如短时间内 <code>GPS</code> 移动距离过大。</li><li>安装高风险类 <code>App</code>。例如安装作弊类、欺诈类、赌博类等 <code>App</code>。</li><li>移动设备异常。例如设备有 <code>root</code> 记录、安装有模拟器等。</li><li>交叉验证信息不一致。例如 <code>GPS</code> 定位地址、工作地址、居住地等地址信息对比不一致。</li><li>特殊手机号。例如虚拟手机号。</li><li>特殊银行卡。例如虚拟银行卡。</li><li>紧急联系人异常。例如借款人和其他借款人有相同的紧急联系人。</li><li>团伙欺诈特征。例如相同公司、相同地址等。</li><li>社交关系网络风险。例如一度&#x2F;二度联系人申请比例过高。</li><li>疑似撸贷。例如短期内多次提前还款然后再次立刻借款。</li><li>身份欺诈。例如同一人像却对应不同的证件。</li></ul></li><li>反欺诈模型。<br>  反欺诈模型是通过机器学习算法将客户各个维度的数据特征与欺诈行为建立关联关系，并给出欺诈的概率。<br>  反欺诈模型的优点：可以充分利用弱特性；对抗性好，可增加欺诈成本。<br>  常见的欺诈模型包含<strong>有监督学习</strong>和<strong>无监督学习</strong>。</li></ul></li><li><p>信用风险策略<br>信用风险是指客户在有偿还意愿的前提下因偿还能力不足或其他原因而产生的风险。即为了防范正常客户因偿还能力不足导致逾期风险而制订的策略，其目标就是合理评估客户的偿还能力，保证客户能在借款到期时能够及时履约。<br>目前有效的信用风险策略包含：</p><ul><li>信用风险规则。<br>  信用风险规则侧重客户的资产负债情况，如<strong>收入水平</strong>、<strong>负债水平</strong>、<strong>借贷信用历史</strong>等。其优点在于：识别准确性较高；可根据业务变化及时调整。</li><li>信用风险模型。<br>  信用风险模型是将客户多维数据特征整合，利用机器学习算法训练得到，通常采用有监督学习方式。</li></ul></li><li><p>贷前额度策略<br>贷前额度策略是为新客户授予初始额度的策略。信贷产品的设计共分为两类：一类是对客户单次授信单次借款的模式，另一种则是对客户授予额度并可以多次支用的的循环额度模式。</p></li></ol><h4 id="贷中阶段"><a href="#贷中阶段" class="headerlink" title="贷中阶段"></a>贷中阶段</h4><p>贷中策略是针对在贷客群制订的一系列策略，用于降低在贷客户风险，提高在贷客户价值。<br>当申请人通过了贷前审核，成为金融机构的客户，因此我们希望客户可以持久和更多的使用我们的信贷产品，为了<strong>持续带来营收</strong>、<strong>最大限度留住客户</strong>、<strong>延长使用期限</strong>，随着时间的变化，客户的还款能力可能发生变化，因此金融机构要及时做出调整，这体现了贷中策略的重要性。<br><small>贷中策略主要针对的是使用<strong>循环额度模式</strong>的信贷产品。</small></p><ol><li><p>贷中支用策略<br>客户在获得授信之后，可能在贷中发生多次支用行为，但是客户的资质是在持续变化，因此每次支用时都应当检查客户的风险情况。</p><ul><li>支用风险规则。</li><li>支用风险模型。</li></ul></li><li><p>贷中额度策略<br>对在贷客户进行风险评估，重新确定客户的授信额度并加以调整，以提升客户满意度，提高客户价值。对于低风险客户，最直接激励的方式就是调额。而对于高风险客户最有效控制损失的方式就是降低额度。<br>对于贷中额度的调整可以从以下方面入手：</p><ul><li>风险规则。对于潜在风险较高的客户，应该禁止调额，可以通过类似贷前和贷中支用的风险规则进行拦截。</li><li>使用规则。额度使用率较低的客户没必要进行调额，可以通过制订规则将这部分客户排除。</li><li>贷中行为模型。</li></ul></li></ol><h4 id="贷后阶段"><a href="#贷后阶段" class="headerlink" title="贷后阶段"></a>贷后阶段</h4><p>贷后模型主要针对的是逾期客户的一系列策略，用于<strong>提高催收效率</strong>，<strong>提升催收回款率</strong>。<br>常见的催收还款方式有：</p><ul><li>短信。</li><li>电话。</li><li>电子邮件。</li><li>上门催收。</li><li>法院诉讼。</li></ul><p>按照渠道催收可以分为内部催收和委外催收，内部催收即金融机构安排内部员工催收，而委外催收就是委托三方机构或人员来催收。</p><p>根据逾期持续的时长，催收可以被划分为<strong>早期催收</strong>、<strong>中期催收</strong>和<strong>晚期催收</strong>三个阶段，具体时间是根据金融机构的产品形态和回款率衰减情况设定的：</p><ul><li>早期催收。早期催收阶段是整个催收管理流程中最为重要的一个阶段。该阶段的逾期客户的特点：逾期客户量很大；还款率较高。其中风险等级较低的大部分客户并非恶意拖欠，可能是忘记还款日期或者临时资金短缺，一旦提醒就会立刻还款。</li><li>中期催收。中期催收阶段的客户风险较高，相较短期逾期客户，还款率大幅降低。在此阶段应对各个风险等级的客户加大催收力度，多采用电话催收方式。</li><li>晚期催收。在晚期催收阶段的逾期客户数量已经大幅减少，但每个逾期客户的还款率都极低。一般来说逾期至晚期催收阶段的客户没有还款意愿或还款能力。此阶段应该关注风险等级较低的客户，对于风险等级较高的客户可以委外处理或资产转让。</li></ul><p>另外还可以将需要催收的客户进行等级划分，采用催收规则和催收模型结合的方式：</p><ul><li>催收规则。根据客户的行为制订规则，以识别逾期后难以催收的客户。</li><li>催收模型。根据客户的贷中和贷后行为，建立催收模型，可以很好地预测客户在一定时间内是否还款，同时根据模型预测的还款概率，可以轻松的进行风险等级划分。</li></ul><hr><h3 id="监控、预警和异常处理"><a href="#监控、预警和异常处理" class="headerlink" title="监控、预警和异常处理"></a>监控、预警和异常处理</h3><p>风控策略在制订并上线部署之后，其执行的准确性和稳定性对信贷业务至关重要。</p><h4 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h4><p>为了能够在第一时间内发现风控策略的问题，因此需要全面的动态监控，可以从<strong>贷前转化监控</strong>、<strong>贷后逾期监控</strong>和<strong>资产监控</strong>三个维度进行监控</p><ol><li><p>贷前转化监控<br>贷前转化监控是对客户从激活 <code>App</code> 到放款的整个流程中各个环节转化率的变化进行监控。转化主要涉及<strong>激活 <code>App</code><strong>、</strong>注册</strong>、<strong>进件</strong>和<strong>放款环节</strong>，根据信贷业务流程将其归纳之后可以分为<strong>产品转化（激活 <code>App</code> 到进件）监控</strong>和<strong>风控转化（进件到放款）监控</strong>。</p><ul><li>产品转化监控<br>  产品转化监控一般是指对客户从激活 <code>App</code> 到申请借款之前的转化率进行监控。通过产品转化监控可以发现客户在使用产品过程中出现流失的主要环节，然后可以优化对应步骤从而提升产品效能和优化体验。<br>  产品转化监控主要包含<strong>激活量</strong>、<strong>注册量</strong>和<strong>进件量</strong>等指标，时间周期可以是天、周或月等。必要时可以增加实时监控。</li><li>风控转化监控<br>  风控转化监控是指监控客户从进件到放款的转化率，涉及到的有<strong>规则策略</strong>、<strong>模型策略</strong>和<strong>人审策略</strong>等。<br>  风控转化监控的对象主要包含<strong>规则命中率</strong>、<strong>模型通过率</strong>、<strong>机审转化率</strong>、<strong>人审通过率</strong>和<strong>风控转化率</strong>等，时间周期一般以天、周、月和小时为主。</li></ul></li><li><p>贷后逾期监控<br>贷后逾期监控是指对放款客户的逾期率进行相关指标进行监控。其可以及时的反应风控策略的有效性，发现市场风险的变化，以利于及时制订和调整风控策略，保证风险持续可控。<br>在针对不同的信贷产品，其贷后逾期监控的指标有所不同，因此在设计监控方案时应根据<strong>新老客户</strong>、<strong>不同渠道客群</strong>等分别监控，对于监控指标的设计可以考虑以下几点：</p><ul><li>统计样本的口径。</li><li>统计的表现时间范围。</li><li>统计的对象。</li><li>统计的数值。</li><li>监控的更新周期。</li></ul></li><li><p>资产监控<br>资产监控是指在一个周期内（一般是月或者季度）内对信贷业务放款量、放款金额和贷款余额等指标进行监控。其可以看到各个阶段的放款实际情况，从而控制放款节奏。资产监控包含有<strong>交易量监控</strong>和<strong>资产余额监控</strong>。</p><ul><li>交易量监控<br>  交易量监控主要关注信贷业务的实际放款情况，监控周期一般以日为单位，监控指标有<strong>不同渠道的放款金额</strong>、<strong>放款量</strong>、<strong>平均放款额度</strong>、<strong>平均期限</strong>和<strong>预计全月放款额度</strong>等。</li><li>资产余额监控<br>  资产余额监控主要关注的是贷款余额变化，监控周期一般以周为单位，监控指标有<strong>贷款余额</strong>、<strong>未到期余额</strong>和<strong>逾期余额（可以分为不同逾期天数的在逾金额）</strong>等。</li></ul></li></ol><h4 id="预警"><a href="#预警" class="headerlink" title="预警"></a>预警</h4><p>风险预警是在监控指标变化超过合理阈值时进行报警，主要包含有<strong>贷前转化预警</strong>和<strong>贷后风险预警</strong>。风险预警可以通过企业微信、电子邮件、短信、飞书、钉钉、电话等方式进行报警。</p><ul><li>贷前转化预警<br>  贷前转化预警一般是指某一时段内的转化率指标值超过预警阈值，而预警阈值需要根据业务的实际运行情况进行设置，可以根据产品、渠道等拆分。</li><li>贷后风险预警<br>  贷后风险预警的触发条件是到期日的风险指标超过预警阈值。预警阈值可以设置为过去某一段周期内平均值的 <code>120%</code> ，当实际值的变化波动超过 <code>25%</code> 时会触发预警。</li></ul><h4 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h4><p>风险监控和预警只能通知在风控流程中发生的异常以及所处的阶段，而异常处理则是根据预警针对性的分析异常并给出对应的解决方案。<br>解决方案需要根据具体原因来确定，一般可以分为临时性解决方案、根本性解决方案和防止复发性解决方案。在没有找到根本原因时一般先采用临时性解决方案，而后基于数据、事实的分析找到真正原因，并根据真正原因制订对应的方案从根本上解决问题。</p><ol><li><p>转化异常处置<br>转化异常处置通常是<strong>某时段的转化率突然升高或降低</strong>，因此需要分析对应原因并给出解决方案。<br>转化异常处理目前可以分为以下几个方面：</p><ul><li>统计问题。确认各项指标的统计逻辑和数据报表是否正常。</li><li>产品异常。产品流程变更导致客户进件流程异常等。</li><li>规则策略问题。检查相应日期是否有规则调整且调整是否符合预期。</li><li>模型策略问题。检查相应日期是否有模型调整且调整是否符合预期。</li><li>数据问题。检查规则或模型使用的数据是否异常，包含三方数据和自有数据。</li><li>客群变化。在其他环节都没有问题的时候，判断是否为客群变化导致的异常。</li></ul></li><li><p>贷后逾期异常处置<br>贷后逾期异常处置的情况通常是根据<strong>某日的贷后逾期率大幅提高</strong>，因此需要分析对应原因并给出解决方案。<br>贷后逾期异常处置的分享原因分析维度和处置方案如下：</p><ul><li>统计问题。首先检查当日逾期率计算逻辑是否正常、报表数据显示是否正常、样本量是否满足统计显著性需求，以排除统计问题。</li><li>产品异常。检查客户还款或产品是否遇到其他问题。</li><li>风控策略问题。检查放款当日是否有策略调整。</li><li>催收问题。检查当日是否有催收策略调整或者催收人员管理问题。</li><li>客群或市场问题。若上述问题均未发现异常，则需要对客群进一步拆分以分析原因。</li></ul></li></ol><hr><h3 id="术语介绍"><a href="#术语介绍" class="headerlink" title="术语介绍"></a>术语介绍</h3><ol><li><p>坏账<br>坏账是指金融机构发放的贷款未能按预先约定的期限、利率收回，并且很大程度上被认定为将来也无法收回。</p></li><li><p>转化率<br>转化率是指在一个统计周期内，完成某过程的次数与参与该过程的总次数的比值。转化率主要有下列三种：</p><ul><li>机审转化率：在一个统计周期内，风控系统自动审核通过的订单与申请订单数的比例。</li><li>人审转化率：在一个统计周期内，信审人员审核通过的订单数与进入人工审核阶段的订单数的比例。</li><li>风控转化率：在一个统计周期内，放款订单数与总申请订单数的比例。</li></ul></li><li><p>有&#x2F;无监督学习<br>机器学习包含有监督学习、无监督学习和强化学习。</p><ul><li>有监督学习从有标记的训练数据中推导出预测函数。有标记的训练数据是指每个训练实例都包括输入和期望的输出。一句话概括就是：给定数据，预测标签。</li><li>无监督学习是从没有标记的训练数据中推断结论。最典型的无监督学习就是聚类分析，它可以在探索性数据分析阶段用于发现隐藏的模式或者对数据进行分组。一句话概括就是：给定数据，寻找隐藏的结构。</li><li>强化学习关注的是软件代理如何在一个环境中采取行动以便最大化某种累积的回报。一句话概括就是：给定数据，学习如何选择一系列行动，以最大化长期收益。</li></ul></li></ol><hr><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><hr><h3 id="个人备注"><a href="#个人备注" class="headerlink" title="个人备注"></a>个人备注</h3><p><strong>此博客内容均为作者学习所做笔记，侵删！</strong><br><strong>若转作其他用途，请注明来源！</strong></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h3&gt;&lt;p&gt;风控策略是指根据&lt;strong&gt;不同业务场景和客群&lt;/strong&gt;，通过&lt;strong&gt;一系列规则策略与模型策略的组合&lt;/strong&gt;，对&lt;strong&gt;客户的风险进行判断&lt;/strong&gt;，从而实现&lt;strong&gt;准入&lt;/strong&gt;、&lt;strong&gt;反欺诈&lt;/strong&gt;、&lt;strong&gt;授信&lt;/strong&gt;、&lt;strong&gt;风险定价&lt;/strong&gt;和&lt;strong&gt;催收&lt;/strong&gt;等阶段目标，最终&lt;strong&gt;达成风险控制&lt;/strong&gt;的目的。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Risk" scheme="https://blog.vgbhfive.cn/tags/Risk/"/>
    
  </entry>
  
  <entry>
    <title>ClickHouse-管理与运维</title>
    <link href="https://blog.vgbhfive.cn/ClickHouse-%E7%AE%A1%E7%90%86%E4%B8%8E%E8%BF%90%E7%BB%B4/"/>
    <id>https://blog.vgbhfive.cn/ClickHouse-%E7%AE%A1%E7%90%86%E4%B8%8E%E8%BF%90%E7%BB%B4/</id>
    <published>2022-09-12T15:35:16.000Z</published>
    <updated>2023-01-01T15:44:15.906Z</updated>
    
    <content type="html"><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>本文将对 <code>ClickHouse</code> 管理与运维相关的知识进行说明，主要包含<strong>用户</strong>、<strong>权限</strong>、<strong>熔断机制</strong>、<strong>数据备份</strong>和<strong>服务监控</strong>等知识。</p><span id="more"></span><hr><h3 id="用户配置"><a href="#用户配置" class="headerlink" title="用户配置"></a>用户配置</h3><p><code>user.xml</code> 配置文件默认位于 <code>/etc/clickhouse-server</code> 路径下，<code>ClickHouse</code> 使用他来定义用户相关的配置项，包括系统参数的设定、用户的定义、权限以及熔断机制等。</p><h4 id="用户-profile"><a href="#用户-profile" class="headerlink" title="用户 profile"></a>用户 <code>profile</code></h4><p>用户 <code>profile</code> 的作用类似于用户角色，可以预先在 <code>user.xml</code> 中为 <code>ClickHouse</code> 定义多组 <code>profile</code>，并为每组 <code>profile</code> 定义不同的配置项，以实现配置得到复用。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">yandex</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">profiles</span>&gt;</span> <span class="comment">&lt;!-- 配置 profile --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">default</span>&gt;</span> <span class="comment">&lt;!-- 用户自定义角色 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">max_memory_usage</span>&gt;</span>100000000<span class="tag">&lt;/<span class="name">max_memory_usage</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">use_uncompressed_cache</span>&gt;</span>0<span class="tag">&lt;/<span class="name">use_uncompressed_cache</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">default</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">test1</span>&gt;</span> <span class="comment">&lt;!-- 自定义名称，默认角色 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">allow_experimental_live_view</span>&gt;</span>1<span class="tag">&lt;/<span class="name">allow_experimental_live_view</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">ddistributed_product_mode</span>&gt;</span>allow<span class="tag">&lt;/<span class="name">ddistributed_product_mode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">test1</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">profiles</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">yandex</span>&gt;</span></span><br></pre></td></tr></table></figure><p>另外 <code>profile</code> 配置支持继承，实现继承的方式是在定义中引用其他的 <code>profile</code> 名称：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">normal_inherit</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">profile</span>&gt;</span>test1<span class="tag">&lt;/<span class="name">profile</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">profile</span>&gt;</span>test2<span class="tag">&lt;/<span class="name">profile</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">distributed_product_mode</span>&gt;</span>deny<span class="tag">&lt;/<span class="name">distributed_product_mode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">normal_inherit</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="配置约束"><a href="#配置约束" class="headerlink" title="配置约束"></a>配置约束</h4><p><code>constraints</code> 标签可以设置一组约束条件，以保障 <code>profile</code> 内的参数值不会被随意修改。约束条件有如下三种规则：</p><ul><li><code>Min</code>：最小值约束，在设置相应参数的时候，取值不能小于该阈值。</li><li><code>Max</code>：最大值约束，在设置相应参数的时候，取值不能大于该阈值。</li><li><code>Readonly</code>：只读约束，该参数值不允许被修改。</li></ul><p>示例如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">profiles</span>&gt;</span> <span class="comment">&lt;!-- 配置 profile --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">default</span>&gt;</span> <span class="comment">&lt;!-- 用户自定义角色 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">max_memory_usage</span>&gt;</span>100000000<span class="tag">&lt;/<span class="name">max_memory_usage</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">use_uncompressed_cache</span>&gt;</span>0<span class="tag">&lt;/<span class="name">use_uncompressed_cache</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">constraints</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">max_memory_usage</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">min</span>&gt;</span>5000000<span class="tag">&lt;/<span class="name">min</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">max</span>&gt;</span>10000000<span class="tag">&lt;/<span class="name">max</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">max_memory_usage</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">distributed_product_mode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">readonly</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">distributed_product_mode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">constraints</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">default</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">profiles</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="用户定义"><a href="#用户定义" class="headerlink" title="用户定义"></a>用户定义</h4><p>使用 <code>users</code> 标签可以配置自定义用户。如果打开 <code>user.xml</code> 配置文件，会发现已经默认配置 <code>default</code> 用户。定义一个新用户必须包含以下属性：</p><ul><li><code>username</code><br>  <code>username</code> 用于指定登录用户名，这是全局唯一属性。</li><li><code>password</code><br>  <code>password</code> 用于设置登录密码，支持明文、<code>SHA256</code> 加密、 <code>double_sha1</code> 加密三种方式，可以任选其中一种进行设置。<ul><li>明文密码：在使用明文密码时直接使用 <code>password</code> 标签定义密码。</li><li><code>SHA256</code> 加密：在使用 <code>SHA256</code> 加密算法时直接指定 <code>password_sha256_hex</code> 标签定义密码。</li><li><code>double_sha1</code> 加密：在使用 <code>double_sha1</code> 加密算法的时候，则需要通过 <code>double_sha1</code> 标签定义密码。</li></ul></li><li><code>networks</code><br>  <code>networks</code> 表示被允许登录的网络地址，用于限制用户登录的客户端地址。</li><li><code>profile</code><br>  用户所使用的 <code>profile</code> 配置，直接引用相应的名称即可。</li><li><code>quota</code><br>  用于设置该用户能够使用的资源限额，可以立即为一种熔断机制。</li></ul><p>示例如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">user_test</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">password</span>&gt;</span>123456<span class="tag">&lt;/<span class="name">password</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">networks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">ip</span>&gt;</span>::/0<span class="tag">&lt;/<span class="name">ip</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">networks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">profile</span>&gt;</span>default<span class="tag">&lt;/<span class="name">profile</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">quota</span>&gt;</span>default<span class="tag">&lt;/<span class="name">quota</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">user_test</span>&gt;</span></span><br></pre></td></tr></table></figure><hr><h3 id="权限管理"><a href="#权限管理" class="headerlink" title="权限管理"></a>权限管理</h3><p>权限管理始终是一个的话题，<code>ClickHouse</code> 分别从访问、查询和数据等角度出发，层层递进提供了一个立体的权限体系。</p><h4 id="访问权限"><a href="#访问权限" class="headerlink" title="访问权限"></a>访问权限</h4><p>访问层控制是整个权限体系的第一层防护，它又可一步细分为两类权限。</p><ol><li><p>网络访问权限<br>网络访问权限使用 <code>networks</code> 标签设置，用于限制某个用户登录的客户端地址，有 <code>IP</code> 地址、<code>host</code> 主机名称以及正则匹配三种形式，可以任选其中一种进行设置：</p><ul><li><code>IP</code> 地址：直接使用 <code>IP</code> 地址进行设置。</li><li><code>host</code> 主机名称：通过 <code>host</code> 主机名称进行设置。</li><li>正则匹配：通过表达式来匹配 <code>host</code> 名称。</li></ul></li><li><p>数据库与字典访问权限<br>在客户端连入服务之后，可以进一步限制某个用户数据库和字典的访问权限，他们分别通过 <code>allow_databases</code> 和 <code>allow_dictionaries</code> 标签进行设置。如果不进行设置，则表示无任何限制。</p></li></ol><h4 id="查询权限"><a href="#查询权限" class="headerlink" title="查询权限"></a>查询权限</h4><p>查询权限是整个权限体系中的第二层防护，它决定了一个用户能够执行的查询语句。查询权限可以分为以下四类：</p><ul><li>读权限：包括 <code>SELECT</code> 、 <code>EXISTS</code> 、 <code>SHOW</code> 、 <code>DESCRIBE</code> 查询。</li><li>写权限：包括 <code>INSERT</code> 、 <code>OPTIMIZE</code> 查询。</li><li>设置权限：包括 <code>SET</code> 查询。</li><li><code>DDL</code> 权限：包括 <code>CREATE</code> 、 <code>DROP</code> 、 <code>ALTER</code> 、 <code>RENAME</code> 、 <code>ATTACH</code> 、 <code>DETACH</code> 和 <code>TRUNCATE</code> 查询。</li></ul><p>以上四类权限通过以下两种配置标签控制：</p><ul><li><code>readonly</code>：读权限、写权限和设置权限均由此标签控制，共有三种取值：</li><li>当取值为 <code>0</code> 时，不进行任何限制。</li><li>当取值为 <code>1</code> 时，只拥有读权限。</li><li>当取值为 <code>2</code> 时，拥有读权限和设置权限。</li><li><code>allow_ddl</code>：<code>DDL</code> 权限由此标签控制，共有两种取值：</li><li>当取值为 <code>0</code> 时，不允许 <code>DDL</code> 查询。</li><li>当取值为 <code>1</code> 时，允许 <code>DDL</code> 查询。</li></ul><h4 id="数据行级权限"><a href="#数据行级权限" class="headerlink" title="数据行级权限"></a>数据行级权限</h4><p>数据权限是整个权限体系中的第三层防护，它决定了一个用户能够看到什么数据。数据权限使用 <code>databases</code> 标签定义，他是用户定义中的一项选填参数，<code>databases</code> 通过定义用户级别的查询过滤器来实现数据的行级粒度查询，规则定义如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">databases</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">database_name</span>&gt;</span> <span class="comment">&lt;!-- 数据库名称 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">table_name</span>&gt;</span> <span class="comment">&lt;!-- 表名称 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">filter</span>&gt;</span> id &lt; 10 <span class="tag">&lt;/<span class="name">filter</span>&gt;</span> <span class="comment">&lt;!-- 数据过滤条件 --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">table_name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">database_name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">databases</span>&gt;</span></span><br></pre></td></tr></table></figure><p><small>对于数据权限的使用有一点需要明确，在使用这项功能之后 <code>PREWHERE</code> 优化将不会生效。</small></p><hr><h3 id="熔断机制"><a href="#熔断机制" class="headerlink" title="熔断机制"></a>熔断机制</h3><p>熔断是限制资源被过度使用的一种自我保护机制，当使用的资源达到阈值时，那正在进行的操作都会被中断。</p><h4 id="时间周期的累计用量熔断"><a href="#时间周期的累计用量熔断" class="headerlink" title="时间周期的累计用量熔断"></a>时间周期的累计用量熔断</h4><p>这种方式下系统资源的用量是按照时间周期累积统计的，当累积量达到阈值，则直到下个计算周期开始之前，该用户无法继续进行操作。这种方式通过在 <code>user.xml</code> 中的 <code>quota</code> 标签进行配置，示例如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">quotas</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">default</span>&gt;</span> <span class="comment">&lt;!-- 自定义名称 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">internal</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">duartion</span>&gt;</span>3600<span class="tag">&lt;/<span class="name">duartion</span>&gt;</span> <span class="comment">&lt;!-- 时间周期 单位：秒 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">queries</span>&gt;</span>0<span class="tag">&lt;/<span class="name">queries</span>&gt;</span> <span class="comment">&lt;!-- 在周期内允许执行的查询次数 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">errors</span>&gt;</span>0<span class="tag">&lt;/<span class="name">errors</span>&gt;</span> <span class="comment">&lt;!-- 在周期内允许发生异常的次数 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">result_rows</span>&gt;</span>0<span class="tag">&lt;/<span class="name">result_rows</span>&gt;</span> <span class="comment">&lt;!-- 在周期内允许查询返回的结果行数 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">read_rows</span>&gt;</span>0<span class="tag">&lt;/<span class="name">read_rows</span>&gt;</span> <span class="comment">&lt;!-- 在周期内允许分布式查询节点读取的数据行数--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">execution_time</span>&gt;</span>0<span class="tag">&lt;/<span class="name">execution_time</span>&gt;</span> <span class="comment">&lt;!-- 在周期内允许执行的查询时间 --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">internal</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">default</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">quotas</span>&gt;</span></span><br></pre></td></tr></table></figure><p><small>上述配置的 <code>0</code> 表示不做限制。</small></p><h4 id="单次查询的用量熔断"><a href="#单次查询的用量熔断" class="headerlink" title="单次查询的用量熔断"></a>单次查询的用量熔断</h4><p>这种方式下系统资源的用量是按照单词查询统计的，而具体的熔断规则则是由许多不同配置项组成，这些配置项需要定义在用户 <code>profile</code> 中。</p><ol><li><p>针对普通查询的熔断配置</p><ul><li><code>max_memory_usage</code>：在单个 <code>ClickHouse</code> 服务进程中，运行一次查询限制使用的最大内存量，默认值为 <code>10GB</code>。</li><li><code>max_memory_usage_for_user</code>：以用户为单位进行统计，单个用户在运行查询时限制使用的最大内存量，默认值为 <code>0</code>，即不做限制。</li><li><code>max_memory_usage_for_all_queries</code>：所有运行的查询累加在一起所限制的最大内存量，默认值为 <code>0</code>，即不做限制。</li></ul></li><li><p>针对数据写入和聚合查询相关的熔断配置</p><ul><li><code>max_partitions_per_insert_block</code>：在单次写入时，限制创建的最大分区个数，默认值为 <code>100</code> 个。</li><li><code>max_rows_to_group_by</code>：在执行 <code>GROUP BY</code> 聚合查询时限制去重后聚合 <code>KEY</code> 的最大个数，默认值为 <code>0</code>，即不做限制。当超过阈值时，处理方式由 <code>group_by_overflow_mode</code> 参数指定。</li><li><code>group_by_overflow_mode</code> 当 <code>max_rows_to_group_by</code> 熔断规则触发时，<code>group_by_overflow_mode</code> 会提供三种处理方式：<ul><li><code>throw</code>：抛出异常，默认值。</li><li><code>break</code>：立即停止查询，并返回当前数据。</li><li><code>any</code>：仅根据当前已存在的聚合 <code>KEY</code> 继续完成聚合查询。</li></ul></li><li><code>max_bytes_before_external_group_by</code>：在执行 <code>GROUP BY</code> 聚合查询时限制使用的最大内存量，默认值为 <code>0</code>，即不做限制。当超过阈值时，聚合查询将会进一步借用本地磁盘。</li></ul></li></ol><hr><h3 id="数据备份"><a href="#数据备份" class="headerlink" title="数据备份"></a>数据备份</h3><p>前面我们学习了副本，那么还需要备份吗？当然是需要的，因为副本是不能解决误删除数据这类行为，因此 <code>ClickHouse</code> 提供如下几种方式。</p><h4 id="导出文件备份"><a href="#导出文件备份" class="headerlink" title="导出文件备份"></a>导出文件备份</h4><p>如果数据的体量较小，可以通过 <code>dump</code> 的形式将数据导出为本地文件。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clickhouse-client --query=&quot;select * from tast_backup&quot; &gt; /chbase/test_backup.csv</span><br></pre></td></tr></table></figure><p>将备份再次导入</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /chbase/test_backup.csv | clickhouse-client --query &quot;insert into test_backup format TSV&quot;</span><br></pre></td></tr></table></figure><p><small>上述 <code>dump</code> 形式的优势在于可以利用 <code>select</code> 查询并筛选数据，然后按需备份。</small></p><h4 id="通过快照备份"><a href="#通过快照备份" class="headerlink" title="通过快照备份"></a>通过快照备份</h4><p>快照表实质上就是普通的数据表，通常按照业务规定的备份频率创建。</p><h4 id="按分区备份"><a href="#按分区备份" class="headerlink" title="按分区备份"></a>按分区备份</h4><p>基于数据分区的备份，<code>ClickHouse</code> 目前提供了 <code>FREEZE</code> 和 <code>FETCH</code> 两种方式，使用方法可以参考之前的关键字。</p><hr><h3 id="服务监控"><a href="#服务监控" class="headerlink" title="服务监控"></a>服务监控</h3><p>基于原生 <code>ClickHouse</code> 进行监控，可以从<strong>系统表</strong>和<strong>查询日志</strong>两方面入手。</p><h4 id="系统表"><a href="#系统表" class="headerlink" title="系统表"></a>系统表</h4><p>在众多的 <code>SYSTEM</code> 系统表中，主要由以下三张表支撑对 <code>ClickHouse</code> 运行指标的查询，分别是 <code>metrics</code> 、 <code>events</code> 和 <code>asynchronous_metrics</code>。</p><ol><li><p><code>metrics</code><br><code>metrics</code> 表用于统计 <code>ClickHouse</code> 服务在运行时，当前正在运行的高层次的概要信息，包括正在执行的查询总次数、正在发生的合并操作总次数等。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> system.metrics limit <span class="number">5</span></span><br></pre></td></tr></table></figure></li><li><p><code>events</code><br><code>events</code> 用于统计 <code>ClickHouse</code> 服务在运行过程中已经执行过的高层次的累积概要信息，包括总的查询次数、总的 <code>SELECT</code> 查询次数等。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> event, <span class="keyword">value</span> <span class="keyword">from</span> system.events limit <span class="number">5</span></span><br></pre></td></tr></table></figure></li><li><p><code>asynchronous_metrics</code><br><code>asynchronous_metrics</code> 用于统计 <code>ClickHouse</code> 服务运行过程中，当前正在后台异步运行的高层次的概要信息，包括当前分配的内存、执行队列中的任务数量等。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> system.asynchronous_metrics limit <span class="number">5</span></span><br></pre></td></tr></table></figure></li></ol><h4 id="查询日志"><a href="#查询日志" class="headerlink" title="查询日志"></a>查询日志</h4><p>查询日志目前主要分为六种类型，分别从不同的角度记录 <code>ClickHouse</code> 的操作行为。<br>所有查询日志在默认配置下都是关闭状态，需要在 <code>config.xml</code> 配置中进行更改，在配置开启之后会自动生成相应的系统表以供查询。</p><ol><li><p><code>query_log</code> 是最常用的查询日志，记录了 <code>ClickHouse</code> 服务中所有已执行的查询记录，定义方式如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">query_log</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">databases</span>&gt;</span>system<span class="tag">&lt;/<span class="name">databases</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">table</span>&gt;</span>query_log<span class="tag">&lt;/<span class="name">table</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">partition_by</span>&gt;</span>toYYYYMM(event_date)<span class="tag">&lt;/<span class="name">partition_by</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">flush_interval_milliseconds</span>&gt;</span>7500<span class="tag">&lt;/<span class="name">flush_interval_milliseconds</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">query_log</span>&gt;</span></span><br></pre></td></tr></table></figure><p><small>如果需要单独为某个用户开启该功能，可以在 <code>user.xml</code> 的 <code>profile</code> 配置中使用 <code>&lt;log_query&gt;1&lt;/log_query&gt;</code> 配置。</small></p></li><li><p><code>query_thread_log</code> 记录所有线程的执行查询信息，定义方式如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">query_thread_log</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">databases</span>&gt;</span>system<span class="tag">&lt;/<span class="name">databases</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">table</span>&gt;</span>query_thread_log<span class="tag">&lt;/<span class="name">table</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">partition_by</span>&gt;</span>toYYYYMM(event_date)<span class="tag">&lt;/<span class="name">partition_by</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">flush_interval_milliseconds</span>&gt;</span>7500<span class="tag">&lt;/<span class="name">flush_interval_milliseconds</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">query_thread_log</span>&gt;</span></span><br></pre></td></tr></table></figure><p><small>如果需要单独为某个用户开启该功能，可以在 <code>user.xml</code> 的 <code>profile</code> 配置中使用 <code>&lt;log_query_threads&gt;1&lt;/log_query_threads&gt;</code> 配置。</small></p></li><li><p><code>part_log</code> 日志记录 <code>MergeTree</code> 系列表引擎的分区操作日志，定义方式如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">part_log</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">databases</span>&gt;</span>system<span class="tag">&lt;/<span class="name">databases</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">table</span>&gt;</span>part_log<span class="tag">&lt;/<span class="name">table</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">flush_interval_milliseconds</span>&gt;</span>7500<span class="tag">&lt;/<span class="name">flush_interval_milliseconds</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">part_log</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p><code>text_log</code> 日志记录 <code>ClickHouse</code> 运行过程中产生的一系列打印日志，包括 <code>INFO</code> 、 <code>DEBUG</code> 和 <code>Trace</code>，定义方式如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">text_log</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">databases</span>&gt;</span>system<span class="tag">&lt;/<span class="name">databases</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">table</span>&gt;</span>text_log<span class="tag">&lt;/<span class="name">table</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">flush_interval_milliseconds</span>&gt;</span>7500<span class="tag">&lt;/<span class="name">flush_interval_milliseconds</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">text_log</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p><code>metric_log</code> 日志用于将 <code>system.metrics</code> 和 <code>system.events</code> 中的数据汇聚到一起，定义方式如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">metric_log</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">databases</span>&gt;</span>system<span class="tag">&lt;/<span class="name">databases</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">table</span>&gt;</span>metric_log<span class="tag">&lt;/<span class="name">table</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">flush_interval_milliseconds</span>&gt;</span>7500<span class="tag">&lt;/<span class="name">flush_interval_milliseconds</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">collect_interval_milliseconds</span>&gt;</span>1000<span class="tag">&lt;/<span class="name">collect_interval_milliseconds</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">metric_log</span>&gt;</span></span><br></pre></td></tr></table></figure><p><small>其中 <code>collect_interval_milliseconds</code> 表示收集 <code>metrics</code> 和 <code>events</code> 数据的时间周期。</small></p></li></ol><hr><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><hr><h3 id="个人备注"><a href="#个人备注" class="headerlink" title="个人备注"></a>个人备注</h3><p><strong>此博客内容均为作者学习所做笔记，侵删！</strong><br><strong>若转作其他用途，请注明来源！</strong></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;本文将对 &lt;code&gt;ClickHouse&lt;/code&gt; 管理与运维相关的知识进行说明，主要包含&lt;strong&gt;用户&lt;/strong&gt;、&lt;strong&gt;权限&lt;/strong&gt;、&lt;strong&gt;熔断机制&lt;/strong&gt;、&lt;strong&gt;数据备份&lt;/strong&gt;和&lt;strong&gt;服务监控&lt;/strong&gt;等知识。&lt;/p&gt;</summary>
    
    
    
    
    <category term="ClickHouse" scheme="https://blog.vgbhfive.cn/tags/ClickHouse/"/>
    
  </entry>
  
  <entry>
    <title>ClickHouse-分布式</title>
    <link href="https://blog.vgbhfive.cn/ClickHouse-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    <id>https://blog.vgbhfive.cn/ClickHouse-%E5%88%86%E5%B8%83%E5%BC%8F/</id>
    <published>2022-09-10T12:18:11.000Z</published>
    <updated>2023-01-01T15:46:35.626Z</updated>
    
    <content type="html"><![CDATA[<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>随着业务线数据量的突飞猛进、服务器的意外宕机，这些都是底层基础服务会遇到的问题，因此 <code>ClickHouse</code> 就设计了<strong>集群</strong>、<strong>副本</strong>和<strong>分片</strong>这三个帮手来帮忙。</p><span id="more"></span><p>集群是副本和分片的基础，他将 <code>ClickHouse</code>. 的服务拓扑由单节点延伸为多节点，但是他又不像 <code>hadoop</code> 那样的系统，要求所有的节点都组成一个大集群。<code>ClickHouse</code> 的集群配置非常灵活，用户既可以将所有节点组成一个大集群，也可以按照业务的诉求将节点划分为多个小集群。<br>在每个小集群区域之间，他们的节点、分区和副本数量可以各不相同。从总体来看，集群定义了多个节点的拓扑关系，这些节点在后续服务中会相互合作，而执行层面的具体内容则是由副本和分片来执行。</p><p>那么如何区分副本和分片呢？<br>在数据层面上，副本之间的数据完全相同，而分片之间数据是不同的。在功能层面上，副本的作用在于防止数据丢失，增加存储数据的冗余，而分片的目的在于实现数据的水平切分。</p><hr><h3 id="副本"><a href="#副本" class="headerlink" title="副本"></a>副本</h3><p>之前有说过 <code>ReplicatedMergeTree</code> 复制表引擎，该引擎可以实现应用副本的能力，他是在 <code>MergeTree</code> 表引擎的基础上实现了分布式协同的能力。<br>在 <code>MergeTree</code> 中，一个数据分区从开始创建到全部完成，会经历两类存储区域：</p><ul><li>内存，数据首先会被写入到内存缓冲区。</li><li>本地磁盘，数据接着会被写入 <code>tmp</code> 临时目录分区，待全部完成后再将临时目录重命名为正式分区。</li></ul><p>而 <code>ReplicatedMergeTree</code> 在上述的基础上增加了 <code>ZooKeeper</code> 的部分，他会进一步在 <code>ZooKeeper</code> 内部创建一系列的监听节点，并以此实现多个实例之间的通信，并且在整个通信过程中，<code>ZooKeeper</code> 不会涉及到任何的数据传输。</p><p>那么我们总结下副本的特点：</p><ul><li>依赖 <code>ZooKeeper</code>，在执行 <code>insert</code> 和 <code>alter</code> 查询时 <code>ReplicatedMergeTree</code> 需要借助 <code>ZooKeeper</code> 的分布式协同能力，以实现多个副本之间的同步，但是在 <code>select</code> 副本时并不需要使用。</li><li>表级别的副本，副本是在表级别定义的，所以每张表的副本配置都可以按照他的实际需求进行个性化定义，包括副本的数量、副本在集群中的分布位置等。</li><li>多主架构，可以在任意一个副本上执行 <code>insert</code> 和 <code>alter</code> 查询，他们的效果都是相同的。</li><li><code>Block</code> 数据块，在执行 <code>insert</code> 命令时，会依据 <code>max_insert_block_size</code> 的大小将数据切分为若干个 <code>Block</code> 数据块，因此 <code>Block</code> 数据块是写入的基本单元，并且具有写入的唯一性和原子行。</li><li>原子性，在数据写入时，一个 <code>Block</code> 块内的数据要么全部写入成功，要么全部失败。</li><li>唯一性，在写入一个 <code>Block</code> 数据块时，会按照当前 <code>Block</code> 数据块的数据顺序、数据行和数据大小等指标计算 <code>Hash</code> 信息摘要并记录在案。如果后续遇到相同的 <code>Hash</code> 摘要则该数据块会被忽略。</li></ul><h4 id="ZooKeeper-配置方式"><a href="#ZooKeeper-配置方式" class="headerlink" title="ZooKeeper 配置方式"></a><code>ZooKeeper</code> 配置方式</h4><p>首先新建一个 <code>metrika.xml</code> 的配置文件内容如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">yandex</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">zookeeper-servers</span>&gt;</span> <span class="comment">&lt;!-- ZooKeeper 配置，名称自定义 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">node</span> <span class="attr">index</span>=<span class="string">&quot;1&quot;</span>&gt;</span> <span class="comment">&lt;!-- 节点配置，可以配置多个地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">host</span>&gt;</span>host1.vgbhfive.cn<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">port</span>&gt;</span>2181<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">node</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">zookeeper-servers</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">yandex</span>&gt;</span></span><br></pre></td></tr></table></figure><p>接着在全局配置 <code>config.xml</code> 中使用 <code>&lt;include_from&gt;</code> 标签导入刚才定义的配置：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">include_from</span>&gt;</span>/etc/clickhouse-server/cpnfig.d/metrika.xml<span class="tag">&lt;/<span class="name">include_from</span>&gt;</span></span><br></pre></td></tr></table></figure><p><small><code>incl</code> 与 <code>metrika.xml</code> 配置文件中的节点名称彼此要相互对应。</small></p><p>另外 <code>ClickHouse</code> 还在系统表中提供了一张 <code>zookeeper</code> 的代理表，通过这个表可以使用 <code>SQL</code> 查询读取远端 <code>ZooKeeper</code> 内的数据，不过查询时需要指定 <code>path</code> 条件才能查询到数据。</p><h4 id="副本定义形式"><a href="#副本定义形式" class="headerlink" title="副本定义形式"></a>副本定义形式</h4><p>首先由于增加了数据的冗余存储，所以降低了数据丢失的风险；其次由于副本采用多主架构，所以每个副本实例都可以作为数据读、写的入口，但这都增加了节点的负载。</p><p><code>ReplicatedMergeTree</code> 定义方式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ENGINE = ReplicatedMergeTree(&#x27;zk_path&#x27;, &#x27;replica_name&#x27;)</span><br></pre></td></tr></table></figure><p> 在上述配置中有 <code>zk_path</code> 和 <code>replica_name</code> 两项配置：</p><ul><li><code>zk_path</code> 用于指定在 <code>ZooKeeper</code> 中创建的数据表的路径，路径名称是自定义的，可以设置成自己希望的任何路径。<br>当然也有一些约定俗成的配置：<ul><li><code>/clickhouse/tables/</code> 是约定的路径固定前缀，表示存放数据表的根路径。</li><li><code>&#123;shard&#125;</code> 表示分片编号，通常使用数字来替代。</li><li><code>table_name</code> 表示数据表的名称，为了维护方便通常采用与物理表相同的名字。</li></ul></li><li><code>replica_name</code> 是定义副本名称，该名称是区分不同副本实例的唯一标识。</li></ul><p><small>对于 <code>zk_path</code> 而言，同一张数据表的同一个分片的不同副本，应该定义相同的路径。而对于 <code>replica_name</code> 而言，同一张数据表的同一个分片的不同副本，应该定义不同的名称。</small></p><h4 id="ReplicatedMergeTree-原理解析"><a href="#ReplicatedMergeTree-原理解析" class="headerlink" title="ReplicatedMergeTree 原理解析"></a><code>ReplicatedMergeTree</code> 原理解析</h4><p>在 <code>ReplicatedMergeTree</code> 的核心逻辑中，大量运用了 <code>ZooKeeper</code> 的能力，以实现多个 <code>ReplicatedMergeTree</code> 副本实例之间的协同，包括主副本选举、副本状态感知、操作日志分发、任务队列和 <code>BlockID</code> 去重判断等。<br>在执行 <code>INSERT</code> 数据写入、<code>MERGE</code> 分区和 <code>MUTATION</code> 操作的时候都会涉及到 <code>ZooKeeper</code> 的通信，但是在通信的过程中，并不会涉及到任何表数据的传输，在查询数据时也不会访问 <code>ZooKeeper</code>。</p><h5 id="ZooKeeper-节点结构"><a href="#ZooKeeper-节点结构" class="headerlink" title="ZooKeeper 节点结构"></a><code>ZooKeeper</code> 节点结构</h5><p><code>ReplicatedMergeTree</code> 依赖 <code>ZooKeeper</code> 的事件监听机制以实现各个副本之间的协同。因此在每个 <code>ReplicatedMergeTree</code> 表的创建过程中，会以 <code>zk_path</code> 为根路径创建一组监听节点，按照作用不同，监听节点可以大致分为一下几点：</p><ul><li>元数据<ul><li><code>/metadata</code> 保存元数据信息，包括主键、分区键、采样表达式等。</li><li><code>/columns</code> 保存列字段信息，包括列名称和数据类型。</li><li><code>/replicas</code> 保存副本名称，对应设置参数中的 <code>replica_name</code>。</li></ul></li><li>判断标识<ul><li><code>/leader_election</code> 用于主副本的选举工作，主副本会主导 <code>MERGE</code> 和 <code>MUTATION</code> 操作，这些任务都是在主副本完成之后再借助 <code>ZooKeeper</code> 将消息事件分发到其他副本。</li><li><code>/blocks</code> 记录 <code>Block</code> 数据块的 <code>Hash</code> 信息摘要，以及对应的 <code>partition_id</code>。通过 <code>Hash</code> 摘要能够判断 <code>Block</code> 数据块是否重复；通过 <code>partition_id</code> 则能找到需要同步的数据分区。</li><li><code>block_numbers</code> 按照分区的写入顺序，以相同的顺序记录 <code>partition_id</code>，各个副本在本地进行 <code>MERGE</code> 时都会依照相同的 <code>block_numbers</code> 顺序进行。</li><li><code>quorum</code> 记录 <code>quorum</code> 的数量，当至少有 <code>quorum</code> 数量的副本写入成功后，整个写入操作才算成功。<code>quorum</code> 的数量有 <code>insert_quorum</code> 参数控制，默认值为 <code>0</code>。</li></ul></li><li>操作日志<ul><li><code>/log</code> 常规操作日志，保存副本需要执行的任务指令。</li><li><code>/mutations</code> 操作日志，作用与 <code>/log</code> 日志类似，当执行 <code>ALERT DELETE</code> 或 <code>ALERT UPDATE</code> 查询时，操作指令会被添加到这个节点。</li><li><code>/replicas/&#123;replica_name&#125;/*</code> 每个副本各自的节点下的一组监听节点，用于指导副本在本地执行具体的任务指令<ul><li><code>/queue</code> 任务队列节点，用于执行具体的操作任务。</li><li><code>/log_pointer</code> <code>log</code> 日志指针节点，记录最后一次执行的 <code>log</code> 日志下标信息。</li><li><code>/mutation_pointer</code> <code>mutations</code> 日志指针节点，记录了最后一次执行的 <code>mutatutions</code> 日志名称。</li></ul></li></ul></li></ul><h5 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h5><p><code>/log</code> 和 <code>/mutations</code> 他们犹如通信路由器，是分发操作指令的信息通道，而发送指令的方式则是为这些父节点添加子节点。所有的副本实例都会监听父节点的变化，当有子节点被添加时都会被其他副本实时感知。</p><p>被添加的子节点统一被抽象为 <code>Entry</code> 对象，而具体实现则是 <code>LogEntry</code> 和 <code>MutationEntry</code> 对象承载，分别对应 <code>/log</code> 和 <code>/mutations</code> 节点：</p><ul><li><code>LogEntry</code> 用于封装 <code>/log</code> 子节点信息，核心属性如下：<ul><li><code>source replica</code> 发送这条 <code>Log</code> 指令的副本来源，对应 <code>replica_name</code>。</li><li><code>type</code> 操作指令类型，主要有 <code>get</code>、 <code>merge</code> 和 <code>mutate</code> 三种，分别对应从远程副本下载分区、合并分区和 <code>MUTATION</code> 操作。</li><li><code>block_id</code> 当前分区的 <code>BlockID</code>，对应 <code>/blocks</code> 路径下子节点的名称。</li><li><code>partition_name</code> 当前分区目录的名称。</li></ul></li><li><code>MutationEntry</code>用于封装 <code>/mutations</code> 子节点信息，核心属性如下：<ul><li><code>source replica</code> 发送这条 <code>MUTATION</code> 指令的副本来源，对应 <code>replica_name</code>。</li><li><code>commands</code> 操作指令，主要有 <code>ALERT DELETE</code> 和 <code>ALERT UPDATE</code>。</li><li><code>mutation_id</code> <code>MUTATION</code> 操作的版本号。</li><li><code>partition_id</code> 当权分区目录的 <code>ID</code>。</li></ul></li></ul><h5 id="副本协同流程"><a href="#副本协同流程" class="headerlink" title="副本协同流程"></a>副本协同流程</h5><h6 id="写入执行流程"><a href="#写入执行流程" class="headerlink" title="写入执行流程"></a>写入执行流程</h6><p>当需要在 <code>ReplicatedMergeTree</code> 中执行 <code>INSERT</code> 查询以写入数据时，即会进入 <code>INSERT</code> 核心流程，整体流程从上至下按照时间顺序进行，大致可以分为八个步骤。</p><ol><li><p>创建第一个副本实例</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> replica_sales_1 &#123;</span><br><span class="line">    id String,</span><br><span class="line">    price Float64,</span><br><span class="line">    create_time DateTime</span><br><span class="line">&#125; ENGINW <span class="operator">=</span> ReplicatedMergeTree(<span class="string">&#x27;/clickhouse/tables/01/replicated_sales_1&#x27;</span>, <span class="string">&#x27;ch5.vgbhfive.cn&#x27;</span>)</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYYYYMM(create_time)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> id</span><br></pre></td></tr></table></figure><p>在创建的过程中 <code>ReplicatedMergeTree</code> 会进行一些初始化操作：</p><ul><li>根据 <code>zk_path</code> 初始化所有的 <code>ZooKeeper</code> 节点。</li><li>在 <code>/replicas/</code> 节点下注册自己的副本实例 <code>ch5.vgbhfive.cn</code>。</li><li>启动监听任务，监听 <code>/log</code> 日志节点。</li><li>参与副本选举，选举出主副本，选举的方式是向 <code>/leader_election/</code> 插入子节点，第一个插入成功的副本就是主副本。</li></ul></li><li><p>创建第二个副本实例<br>与上述第一个创建副本实例类似，不同之处在于实例名称。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> replica_sales_1 &#123;</span><br><span class="line">    id String,</span><br><span class="line">    price Float64,</span><br><span class="line">    create_time DateTime</span><br><span class="line">&#125; ENGINW <span class="operator">=</span> ReplicatedMergeTree(<span class="string">&#x27;/clickhouse/tables/01/replicated_sales_1&#x27;</span>, <span class="string">&#x27;ch6.vgbhfive.cn&#x27;</span>)</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYYYYMM(create_time)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> id</span><br></pre></td></tr></table></figure><p>在创建过程中，第二个 <code>ReplicatedMergeTree</code> 同样会进行一些初始化操作：</p><ul><li>在 <code>/replicas/</code> 节点下注册自己的副本实例 <code>ch6.vgbhfive.cn</code>。</li><li>启动监听任务，监听 <code>/log</code> 日志节点。</li><li>参数副本选举，选举出主副本。</li></ul></li><li><p>向第一个实例中写入数据<br>现在尝试向第一个副本 <code>ch5</code> 写入数据：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO TABLE replicated_sales_1 VALUES(&#x27;A001&#x27;, 100, &#x27;2022-05-15 00:00:00&#x27;)</span><br></pre></td></tr></table></figure><p>上述命令执行完毕后，首先会在本地完成分区目录的写入：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Renaming temporary part tmp_insert_202205_1_1_0 to 202205_0_0_0</span><br></pre></td></tr></table></figure><p>接着向 <code>/blocks</code> 节点写入该数据分区的 <code>block_id</code>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Wrote block with ID &#x27;202205_xxxxx_yyyy&#x27;</span><br></pre></td></tr></table></figure><p>该 <code>block_id</code> 将作为后续去重操作的判断依据。如果此时再重复执行刚才的语句，试图写入重复数据，则会抛出异常，即副本会自动忽略 <code>block_id</code> 重复的待写入数据。<br>此外如果设置了 <code>insert_quorum</code> （默认参数为 <code>0</code>），并且 <code>insert_quorum &gt;= 2</code>，则 <code>ch5  </code> 会进一步监控已完成写入操作的副本个数，只有当写入副本个数大于或等于 <code>insert_quorum</code> 时，整个写入操作才会成功。</p></li><li><p>由第一个副本实例推送 <code>Log</code> 日志<br>在 <code>3</code> 步骤完成之后，会继续执行 <code>insert</code> 的副本向 <code>/log</code> 节点推送操作日志。日志的编号是 <code>/log/log-00000000</code>，而 <code>LogEntry</code> 的核心属性如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/log/log-00000000</span><br><span class="line">source replica: ch5.vgbhfive.cn</span><br><span class="line">block_id: 202205_xxxxx</span><br><span class="line">type: get</span><br><span class="line">partition_name: 202205_0_0_0</span><br></pre></td></tr></table></figure><p>从日志内容中可以看出，操作类型为 <code>get</code> 下载，而需要下载的分区时 <code>202205_0_0_0</code>。其余所有副本都会基于 <code>Log</code> 日志以相同的顺序执行命令。</p></li><li><p>第二个副本实例拉取 <code>Log</code> 日志<br><code>ch6</code> 副本会一直监听 <code>/log</code> 节点变化，当 <code>ch5</code> 推送日志之后，<code>ch6</code>  便会触发日志的拉取任务并更新 <code>log_pointer</code>，将其指向最新日志下标：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/replicas/ch6.vgbhfive.cn/log_pointer: 0</span><br></pre></td></tr></table></figure><p>在拉取 <code>LogEntry</code> 之后，并不会直接执行，而是将其转为任务对象放至队列：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/replicas/ch6.vgbhfive.cn/queues/</span><br><span class="line">Pulling 1 entries to queue: log-00000000 to log-00000000</span><br></pre></td></tr></table></figure><p><small>上述 <code>LogEntry</code> 放入队列是因为在复杂的情况下，会连续收到许多个 <code>LogEntry  </code> ，所以使用队列消化任务也是一种合理的设计。</small></p></li><li><p>第二个副本实例向其他副本发起下载请求<br><code>ch6</code> 基于 <code>/queue</code> 队列开始执行任务，当看到 <code>type</code> 为 <code>get</code>    时，<code>ReplicatedMergeTree</code> 会明白此时在远端的其他副本已经成功写入数据分区，而自己需要同步这些数据。<br><code>ch6</code> 上的第二个副本实例会开始选择一个远端的其他副本作为数据的下载来源。远端副本的选择算法大致是这样的：</p><ul><li>从 <code>/replicas</code> 节点拿到所有的副本节点。</li><li>遍历这些副本选取其中一个。选取的副本需要拥有最大的 <code>log_pointer</code> 下标，并且 <code>/queue</code> 子节点数量最少。<code>log_pointer</code> 下标最大，则意味该副本执行的日志最多，数据应该更加完整；而 <code>/queue</code> 最小，则意味着该副本目前的任务执行负担最小。</li></ul><p> <small>在这个实例中，算法选择的副本实例是 <code>ch5</code>。</small></p></li><li><p>第一个副本实例响应数据下载<br><code>ch5</code> 的 <code>DataPartsExchange</code> 端口服务接收到调用请求，在得知对方来意之后，根据参数做出响应，将本地分区 <code>202205_0_0_0</code> 基于 <code>DataPartsExchange</code> 的服务响应发送回 <code>ch6</code>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sending part 202205_0_0_0</span><br></pre></td></tr></table></figure></li><li><p>第二个实例下载数据并完成本地写入<br><code>ch6</code> 副本在接收到 <code>ch5</code> 的分区数据后，首先将其写入到临时目录中：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tmp_fetch_202205_0_0_0</span><br></pre></td></tr></table></figure><p>待全部数据接收完成之后，重命名该目录：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Renaming temporary part tmp_fetch_202205_0_0_0 to 202205_0_0_0</span><br></pre></td></tr></table></figure><p>至此，整个写入结束。</p></li></ol><p>在整个 <code>insert</code> 的写入过程中，<code>ZooKeeper</code> 不会进行任何实质性的数据传输。本着谁执行谁负责的原则，由写入数据的实例负责发送 <code>Log</code> 日志、通知其他实例、监控是否完成、返回下载数据。</p><h6 id="MERGE-执行流程"><a href="#MERGE-执行流程" class="headerlink" title="MERGE 执行流程"></a><code>MERGE</code> 执行流程</h6><p>当需要在 <code>ReplicatedMergeTree</code> 中触发分区合并动作时，即会进入这个部分的流程，无论 <code>MERGE</code> 操作从哪个副本发起，其合并计划都会交由主副本来制定。</p><ol><li><p>创建远程连接，尝试与主副本通信。<br>首先在 <code>ch6</code> 节点执行 <code>OPTIMIZE</code> 强制执行 <code>MERGE</code> 合并，此时 <code>ch6</code> 通过 <code>replicas</code> 找到主副本 <code>ch5</code>，并尝试建立与它的远程连接。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">optimize table replicated_sales_1</span><br><span class="line">Connection (ch5.vgbhfive.cn:9000): Connecting. Database: default. User: default</span><br></pre></td></tr></table></figure></li><li><p>主副本接收通信<br>主副本 <code>ch5</code> 接收并建立来自远端副本 <code>ch6</code> 的连接。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Connected ClickHouse Follower replica version 19.17.0, revision: 54428, database: default, user: default</span><br></pre></td></tr></table></figure></li><li><p>由主副本制定 <code>MERGE</code> 计划并推送 <code>Log</code> 日志<br>由主副本 <code>ch5   </code> 制定 <code>MERGE</code> 计划，并判断哪些分区需要被合并。在选定之后 <code>ch5</code> 将合并计划转换为 <code>Log</code> 日志对象并推送 <code>Log</code> 日志，以通知所有副本开始合并。日志的核心信息如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">type: merge</span><br><span class="line">202205_0_0_0</span><br><span class="line">202205_1_1_0</span><br><span class="line">into</span><br><span class="line">202205_0_1_1</span><br></pre></td></tr></table></figure><p>从日志内容可以看出操作类型为 <code>MERGE</code> 合并，而这次需要合并的分区目录是 <code>202205_0_0_0</code> 和 <code>202205_0_1_1</code>。与此同时主副本还会锁住执行线程，对日志的接收情况进行监听：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Waiting for queue-0000000002 to disapper from ch5.vgbhfive.cn queue</span><br></pre></td></tr></table></figure><p>其监听行为由 <code>replication_alter_partitions_sync</code> 参数控制，默认值为 <code>1</code>。</p><ul><li>参数为 <code>0</code> 时，不做任何等待。</li><li>参数为 <code>1</code> 时，只等主副本自身完成。</li><li>参数为 <code>0</code> 时，等待所有副本拉取完成。</li></ul></li><li><p>各个副本分别拉取 <code>Log</code> 日志<br><code>ch5</code> 和 <code>ch6</code> 两个副本实例将分别监听 <code>/log/log-00000002</code> 日志的推送，他们分别会拉取日志到本地，并推送到各自的 <code>/queue</code> 任务队列：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pulling 1 entries to queue : log-00000002 - log-000000002</span><br></pre></td></tr></table></figure></li><li><p>各个副本分别在本地执行 <code>MERGE</code><br><code>ch5</code> 和 <code>ch6</code> 基于各自的 <code>/queue</code> 队列开始执行任务：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Executing log entry to merge parts 202205_0_0_0, 202205_1_1_0 to 202205_0_1_1</span><br></pre></td></tr></table></figure><p>各个副本开始在本地执行 <code>MERGE</code>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Merged 2 parts: from 202205_0_0_0 to 202205_1_1_0</span><br></pre></td></tr></table></figure></li></ol><p>至此 <code>MERGE</code> 的合并过程 <code>ZooKeeper</code> 不会进行任何实质性的数据传输，所有的合并操作最终都是由各个副本在本地完成的。而无论合并动作在哪个副本被触发，最终都会交由主副本负责合并计划的制定、消息日志的推送以及日志接收情况的监控。</p><h6 id="MUTATION-执行流程"><a href="#MUTATION-执行流程" class="headerlink" title="MUTATION 执行流程"></a><code>MUTATION</code> 执行流程</h6><p>当对 <code>ReplicatedMergeTree</code> 执行 <code>ALTER DELTE</code> 或者 <code>ALTER UPDATE</code> 操作的时候，即会进入 <code>MUTATION</code> 部分的逻辑，与 <code>MERGE</code> 类似，无论 <code>MUTATION</code> 操作从哪个副本发起，首先都会由主副本进行响应。</p><ol><li>推送 <code>MUTATION</code> 日志<br>在 <code>ch6</code> 节点尝试通过 <code>DELETE</code> 来删除一行数据，执行如下命令：<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> replicated_sales_1 <span class="keyword">DELETE</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure>上述命令执行之后该副本会接着执行两个重要事项：</li></ol><ul><li>创建 <code>MUTATION ID</code>： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Created mutation with ID 000000000</span><br></pre></td></tr></table></figure></li><li>将 <code>MUTATION</code> 操作转换为 <code>MutatutionEntry</code> 日志，并推送到 <code>/mutations/00000000</code>。<code>Mutation</code> 的核心属性如下： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/mutations/000000000</span><br><span class="line">source replica: ch6.vgbhfive.cn</span><br><span class="line">mutation_id: 2</span><br><span class="line">partition_id: 202205</span><br><span class="line">commands: DELETE where id = \&#x27;1\&#x27;</span><br></pre></td></tr></table></figure></li></ul><ol start="2"><li><p>所有副本实例各自监听 <code>MUTATION</code> 日志<br><code>ch5</code> 和 <code>ch6</code> 都会监听 <code>/mutations</code> 节点，因此有新的日志子节点加入都会被实时感知：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Loading 1 mutation entries: 000000000 - 000000000</span><br></pre></td></tr></table></figure><p>当监听到有新的 <code>MUTATION</code> 日志加入时，并不是所有副本都会直接做出响应，他们首先会判断自己是否为主副本。</p></li><li><p>由主副本实例响应 <code>MUTATION</code> 日志并推送 <code>Log</code> 日志<br>只有主副本才会响应 <code>MUTATION</code> 日志，主副本会将 <code>MUTATION</code> 日志转换为 <code>LogEntry</code> 日志并推送到 <code>/log</code> 节点，以通知各个副本执行具体的操作。日志的核心信息如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/log/log-000000003</span><br><span class="line">source replica: ch5.vgbhfive.cn</span><br><span class="line">block_id:</span><br><span class="line">type: mutate</span><br><span class="line">202005_0_1_1 to 202205_0_1_1_2</span><br></pre></td></tr></table></figure></li><li><p>各个副本实例分别拉取 <code>Log</code> 日志<br><code>ch5</code> 和 <code>ch6</code> 两个副本分别监听 <code>/log/log-000000002</code> 日志的推送，他们也会分别拉取日志到本地，并推送到各自的 <code>/queue</code> 任务队列：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pulling 1 entries to queue: log-0000000002 - log-0000000002</span><br></pre></td></tr></table></figure></li><li><p>各个副本实例分别在本地执行 <code>MUTATION</code><br><code>ch5</code> 和 <code>ch6</code> 基于各自的 <code>/queue</code> 队列开始执行任务：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Executing log entry to mutate part 202205_0_1_1 to 202205_0_1_1_2</span><br></pre></td></tr></table></figure><p>各个副本开始在本地执行 <code>MUTATION</code>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Cloning part 202205_0_1_1 to tmp_clone_202205_0_1_1_2</span><br><span class="line">Renaming temporary part tmp_clone_202205_0_1_1_2 to 202205_0_1_1_2.</span><br></pre></td></tr></table></figure></li></ol><p>至此在 <code>MUTATION</code> 的整个过程中 <code>ZooKeeper</code> 同样不会进行任何实质性的数据传输。所有的 <code>MUTATION</code> 操作，最终都是由各个副本在本地完成的，而 <code>MUTATION</code> 操作是经过 <code>/mutations</code> 节点实现分发的。本着谁执行谁负责的原则，执行命令的副本负责消息推送，但是无论在哪个副本执行最终都会被交由主副本，再由主副本负责推送 <code>Log</code> 日志，以通知各个副本最终的 <code>MUTATION</code> 逻辑，同时也由主副本对日志接收的情况进行监控。</p><h6 id="ALTER-执行流程"><a href="#ALTER-执行流程" class="headerlink" title="ALTER 执行流程"></a><code>ALTER</code> 执行流程</h6><p>当对 <code>ReplicatedMergeTree</code> 执行 <code>ALTER</code> 操作的时候，即会进入 <code>ALTER</code> 部分的逻辑，与前几个类似 <code>ALTER</code> 流程会简单许多，其执行流程并不会涉及 <code>/log</code> 日志的分发。</p><ol><li><p>修改共享元数据<br>在 <code>ch6</code> 节点尝试增加一个列字段，执行语句如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> replicated_sales_1 <span class="keyword">ADD</span> <span class="keyword">COLUMN</span> id2 String</span><br></pre></td></tr></table></figure><p>执行之后，<code>ch6</code> 会修改 <code>ZooKeeper</code> 内的共享元数据节点：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/metadata, /columns</span><br><span class="line">Updated shared metadata nodes in ZooKeeper. Waiting for replicas to apply changes.</span><br></pre></td></tr></table></figure><p>数据修改之后，节点的版本号也会同时提升：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Version of metadata nodes in ZooKeeper changed. Waiting for structure write lock.</span><br></pre></td></tr></table></figure><p>与此同时，<code>ch6</code> 还会负责监听所有副本的修改完成情况：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Waiting for ch5.vgbhfive.cn to apply changes.</span><br><span class="line">Waiting for ch6.vgbhfive.cn to apply changes.</span><br></pre></td></tr></table></figure></li><li><p>监听共享元数据变更并各自执行本地修改<br><code>ch5</code> 和 <code>ch6</code> 两个副本分别监听共享元数据的变更，之后会分别对本地的元数据版本号与共享版本号进行对比。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Metadata changed in ZooKeeper. Applying changes locally.</span><br><span class="line">Applied changes to the metadata of the table.</span><br></pre></td></tr></table></figure></li><li><p>确认所有副本完成修改<br>确认所有副本均已完成修改：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ALTER finished.</span><br><span class="line">Done processing query.</span><br></pre></td></tr></table></figure></li></ol><p>至此整个 <code>ALTER</code> 流程结束。在执行过程中，<code>ZooKeeper</code> 没有参与实质性的数据传输，所有的 <code>ALTER</code> 都是各个副本在本地完成的。</p><hr><h3 id="分片"><a href="#分片" class="headerlink" title="分片"></a>分片</h3><p>通过引入数据副本可以降低数据丢失的风险，并提升查询的性能，但是仍然有一个问题没有解决，那就是数据表的容量问题，到目前为止每个副本都是保存全量的数据。</p><p><code>ClickHouse</code> 中的每个节点都可以称为一个 <code>shard</code> （分片），对于一个完整的方案来说，还需要考虑数据在写入时数据如何被均匀地被写入到各个分片中，以及在数据查询时如何路由到每个分片并组合成结果集，所以 <code>ClickHouse</code> 地数据分片需要结合 <code>Distributed</code> 表引擎一同使用。</p><p><code>Distributed</code> 表引擎自身不存储任何数据，它能够作为分布式表的一层透明代理，在集群内部自动开展数据的写入、分发、查询、路由等工作。</p><h4 id="集群的配置方式"><a href="#集群的配置方式" class="headerlink" title="集群的配置方式"></a>集群的配置方式</h4><p>在 <code>ClickHouse</code> 中集群配置用 <code>shard</code> 代表分片，用 <code>replica</code> 代表副本。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 1 分片 0 副本</span><br><span class="line"><span class="tag">&lt;<span class="name">shard</span>&gt;</span><span class="comment">&lt;!-- 分片 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">replica</span>&gt;</span><span class="comment">&lt;!-- 副本 --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">shard</span>&gt;</span></span><br><span class="line"># 1 分片 1 副本</span><br><span class="line"><span class="tag">&lt;<span class="name">shard</span>&gt;</span><span class="comment">&lt;!-- 分片 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">replica</span>&gt;</span><span class="comment">&lt;!-- 副本 --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">replica</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">shard</span>&gt;</span></span><br></pre></td></tr></table></figure><p>这样的配置貌似有点问题，其实分片更像是逻辑层面的分组，而无论是分片或时副本，承载他们的都是 <code>replica</code>，所以从某种角度来看，副本也是分片。</p><h4 id="集群分布式-DDL"><a href="#集群分布式-DDL" class="headerlink" title="集群分布式 DDL"></a>集群分布式 <code>DDL</code></h4><p>在默认情况下 <code>CREATE</code> 、 <code>DROP</code> 、 <code>RENAME</code> 、 <code>ALTER</code> 等 <code>DDL</code> 语句并不支持分布式执行，但是在加入集群配置后使用新的语法实现分布式 <code>DDL</code> 执行：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span><span class="operator">/</span><span class="keyword">DROP</span><span class="operator">/</span>RENAME<span class="operator">/</span><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> OM CLUSTER cluster_name</span><br></pre></td></tr></table></figure><p><small><code>cluster_name</code> 对应了配置文件中的集群名称，<code>ClickHouse</code> 会根据集群配置信息分别去各个节点执行 <code>DDL</code> 语句。</small></p><h5 id="数据结构-1"><a href="#数据结构-1" class="headerlink" title="数据结构"></a>数据结构</h5><p>与 <code>ReplicatedMergeTree</code> 类似，分布式 <code>DDL</code> 语句在执行的过程中也需要借助 <code>ZooKeeper</code> 的协同能力，以实现日志分发。</p><ol><li><p><code>ZooKeeper</code> 内的节点结构<br>默认情况下分布式 <code>DDL</code> 在 <code>ZooKeeper</code> 内使用的根路径为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/clickhouse/task_queue/ddl</span><br></pre></td></tr></table></figure><p><small>该地址可以在 <code>config.xml</code> 中的 <code>distributed_ddl</code> 配置指定。</small><br>当然在此节点之下还有其他的监听节点，包含 <code>/query-[seq]</code>，其内包含 <code>DDL</code> 操作日志，每执行一次分布式 <code>DDL</code> 查询，在该节点下新增一条操作日志。<code>DDL</code> 操作日志使用 <code>ZooKeeper</code> 的持久顺序型节点，每条指令的名称以 <code>query-</code> 为前缀，后面的序号递增。在该操作日志下，还有两条状态节点：</p><ul><li><code>/query-[seq]/active</code> 用于状态监控等用途，在任务的执行过程中，在该节点下会临时保存当前集群内状态为 <code>active</code> 的节点。</li><li><code>/query-[seq]/finished</code> 用于检查任务完成情况，在任务的执行过程中，每当集群内的某个 <code>host</code> 执行完毕之后，就会在该节点下写入记录。</li></ul></li><li><p><code>DDLLongEntry</code> 日志对象的数据结构<br>在 <code>/query-[seq]</code> 下记录的日志信息由 <code>DDLLogEntry</code> 承载，拥有以下几个核心属性：</p><ul><li><code>query</code> 记录 <code>DDL</code> 查询的执行语句  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">query: DROP TABLE default.test_1_local ON CLUSTER shard_2</span><br></pre></td></tr></table></figure></li><li><code>hosts</code> 记录指定集群的主机列表，集群由分布式 <code>DDL</code> 语句中的 <code>ON CLUSTER</code> 指定  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hosts: [&#x27;ch5.vgbhfive.cn:9000&#x27;, &#x27;ch6.vgbhfive.cn:9000&#x27;]</span><br></pre></td></tr></table></figure></li><li><code>initiator</code> 记录初始化 <code>host</code> 主机的名称，主机列表来源于初始化 <code>host</code> 节点上的集群  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">initiator: ch5.vgbhfive.cn</span><br></pre></td></tr></table></figure></li></ul></li><li><p>分布式 <code>DDL</code> 的核心执行流程<br><img src="https://s2.loli.net/2022/09/10/xETJYlW2Ic4dft3.png" alt="click-4-1.png"><br>整个流程从上到下按照时间顺序进行，其大致分为三个步骤：</p><ul><li>推送 <code>DDL</code> 日志，在节点执行语句，本着谁执行谁负责原则，会由这个节点创建 <code>DDLLogEntry</code> 日志并将日志推送到 <code>ZooKeeper</code> ，同时也会由这个节点负责监控任务的执行进度。</li><li>拉取日志并执行，其余节点监听到日志推送，于是拉取日志到本地。首先判断自身 <code>host</code> 是否被包含在 <code>DDLLogEntry</code> 的 <code>hosts</code> 列表中，如果包含在内则进入执行流程，执行完毕后将状态写入 <code>finished</code> 节点；如果不包含则忽略这次日子的推送。</li><li>确认执行进度，在执行 <code>DDL</code> 语句之后，客户端会阻塞等待 <code>180</code> 秒后，以期望所有 <code>host</code> 执行完毕。如果等待时间超过 <code>180</code> 秒，则进入后台线程继续等待（等待时间由 <code>distributed_ddl_task_timeout</code> 参数执行，默认 <code>180</code> 秒）。</li></ul></li></ol><h4 id="Distributed-原理解析"><a href="#Distributed-原理解析" class="headerlink" title="Distributed 原理解析"></a><code>Distributed</code> 原理解析</h4><p><code>Distributed</code> 表引擎是分布式表的代名词，它自身不存储任何数据，而是作为数据分片的透明代理，能够自动路由数据至集群中的各个节点，所以 <code>Distributed</code> 表引擎需要和其他数据表引擎一起协同工作。<br>从实体表层面来看，一张分片由两部分组成：</p><ul><li>本地表：通常以 <code>_local</code> 为后缀进行命名。本地表是承接数据的载体，可以使用非 <code>Distributed</code> 的任意表引擎，一张本地表对应了一个数据分片。</li><li>分布式表：通常以 <code>_all</code> 为后缀进行命名。分布式表是能使用 <code>Distributed</code> 表引擎，他与本地表形成一对多的映射关系，日后将通过分布式表代理操作多张本地表。</li></ul><p><small><code>Distirbuted</code> 表引擎采用读时检查，即在查询时才会抛出错误，而不会在创建表时检查。</small> </p><h5 id="定义形式"><a href="#定义形式" class="headerlink" title="定义形式"></a>定义形式</h5><p><code>Distributed</code> 表引擎的定义形式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ENGINE = Distributed(cluster, database, table [, sharding_key])</span><br></pre></td></tr></table></figure><p>其中各个参数的含义如下：</p><ul><li><code>cluster</code>：集群名称，与集群配置中的自定义名称相对应。在对分布式表执行写入和查询的过程中，他会使用集群的配置信息来找到相应的 <code>host</code> 节点。</li><li><code>dataabse</code> 和 <code>table</code>：分别对应数据库和表的名称，分布式表使用这组配置映射到本地表。</li><li><code>sharding_key</code>：分片键，选填参数。在数据写入的过程中，分布式表会依据分片键的规则，将数据分布到各个 <code>host</code> 节点的本地表。</li></ul><h5 id="查询分类"><a href="#查询分类" class="headerlink" title="查询分类"></a>查询分类</h5><p><code>Distributed</code> 表引擎的查询操作分类如下：</p><ul><li>会作用于本地表的查询，对于 <code>INSERT</code> 和 <code>SELECT</code> 查询，<code>Distributed</code> 将会以分布式的方式作用于 <code>local</code> 本地表。</li><li>只会影响 <code>Distributed</code> 自身，不会作用于本地表的查询： <code>Distributed</code> 支持部分元数据操作，包括 <code>CREATE</code> 、 <code>DROP</code> 、 <code>REANME</code> 、 <code>ALTER</code>，其中 <code>ALTER</code> 并不包括分区的操作。</li><li>不支持的查询：<code>Distributed</code> 表不支持任何 <code>MUTATION</code> 类型的操作，包括 <code>ALTER DELETE</code> 和 <code>ALTER UPDATE</code>。</li></ul><h5 id="分片规则"><a href="#分片规则" class="headerlink" title="分片规则"></a>分片规则</h5><p>分片键要求返回一个整数类型的取值，包括 <code>Int</code> 类型和 <code>UInt</code> 类型。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Distributed(cluster, database, table, userid) # 按照用户 id 的余数划分</span><br></pre></td></tr></table></figure><p><small>如果不声明分片键，那么分布式表则只会有一个分片，意味者只能映射一张本地表。当然如果分布式表只包含一个分片，那也就失去了使用的意义。</small></p><p>关于数据如何被具体的划分，需要明确以下几个概念：</p><ul><li>分片权重<br>  在集群的配置中，还有一项分片权重（<code>weight</code>）的设置：  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">shard</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">weight</span>&gt;</span>10<span class="tag">&lt;/<span class="name">weight</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">shard</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">shard</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">weight</span>&gt;</span>20<span class="tag">&lt;/<span class="name">weight</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">shard</span>&gt;</span></span><br></pre></td></tr></table></figure>  分片权重会影响数据在分片中的倾斜程度，一个分片权重值越大，那么被写入的数据就会越多。</li><li><code>slot</code>（槽）<br>  <code>slot</code> 可以理解成许多个小水槽，如果把数据比作成水的话，那么数据之水会顺着这些水槽流进每个数据分片。<code>slot</code> 的数量等于所有分片的权重之和。</li><li>选择函数<br>  选择函数用于判断一行待写入的数据应该被写入到哪个分片，那整个步骤会被分为两个步骤：<ul><li>找出 <code>slot</code> 的取值，计算公式如下：   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">slot = shard_value - sum_weight</span><br></pre></td></tr></table></figure>   其中 <code>shard_value</code> 是分片键的取值，<code>sum_weight</code> 是所有分片的权重之和。</li><li>基于 <code>slot</code> 值找到对应的数据分片</li></ul></li></ul><h5 id="分布式核心流程"><a href="#分布式核心流程" class="headerlink" title="分布式核心流程"></a>分布式核心流程</h5><h6 id="分布式写入流程"><a href="#分布式写入流程" class="headerlink" title="分布式写入流程"></a>分布式写入流程</h6><p>在向集群内的分片写入数据时，通常有两种思路：一种是借助外部计算系统，事先将数据均匀分片，再借由计算系统直接写入 <code>ClickHouse</code>集群的各个本地表。第二种则是通过 <code>Distributed</code> 表引擎代理写入分片数据的。</p><h6 id="将数据写入分片的核心流程"><a href="#将数据写入分片的核心流程" class="headerlink" title="将数据写入分片的核心流程"></a>将数据写入分片的核心流程</h6><p>在对 <code>Distributed</code> 表执行 <code>INSERT</code> 查询的时候，会进入数据写入分片的执行逻辑，可以分为五个步骤，整体流程如下：</p><ol><li><p>在第一个分片节点写入本地分片数据<br>在 <code>ch5</code> 节点对本地表 <code>test_shard_2_all</code> 执行 <code>INSERT</code> 查询，尝试写入 <code>10, 30, 200, 50</code> 四行数据。执行之后分布式表主要分做两件事情：其一，根据分片规则划分数据；第二，将属于当前分片的数据直接写入本地表 <code>test_shard_2_all</code>。</p></li><li><p>第一个分片建立远端连接，准备发送远端分片数据<br>将归至远端分片的数据以分区为单位，分别写入 <code>test_shard_2_all</code> 存储目录下的临时 <code>bin</code> 文件，数据文件的命名规则如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/database@host:port/[increase_num].bin</span><br></pre></td></tr></table></figure><p>由于在这个示例中只有一个远端分片 <code>ch6</code>，所以临时数据文件如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/test_shard_2_all/default@ch6.vgbhfive.cn:9000/1.bin</span><br></pre></td></tr></table></figure><p><code>10, 200, 50</code> 三行数据会被写入上述临时数据文件。接着会尝试与远端 <code>ch6</code> 分片建立连接：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Connection (ch6.vgbhfive.cn) : Connected to ClickHouse server</span><br></pre></td></tr></table></figure></li><li><p>第一个分片向远端分片发送数据<br>此时会有另一组监听任务负责监听 <code>/test_shard_2_all</code> 目录下的文件变化，这些任务负责将目录数据发送至远端分片：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_shard_2_all.Distributed.DirectoryMonitor:</span><br><span class="line">Started processing /test_shard_2_all/default@ch6.vgbhfive.cn:9000/1.bin</span><br></pre></td></tr></table></figure><p>其中，每份目录将会由独立的线程负责发送，数据在传输之前会被压缩。</p></li><li><p>第二个分片接收数据并写入本地<br><code>ch6</code> 分片节点确认建立与 <code>ch5</code> 的连接：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">TCPHandlerFactory: TCP Request. Address: ch5:459127</span><br><span class="line">TCPHandler: Connected ClickHouse server</span><br></pre></td></tr></table></figure><p>在接收到 <code>ch5</code> 发送的数据后，将他们写入本地表：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">executeQuery: (from ch5) INSERT INTO default.test_shard_2_local</span><br><span class="line">-- 第一个分区</span><br><span class="line">Reserving 1.00 MB on disk &#x27;default&#x27;</span><br><span class="line">Renaming temporary part tmp_insert_10_1_1_0 to 10_1_1_0.</span><br><span class="line">-- 第二个分区</span><br><span class="line">Reserving 1.00 MB on disk &#x27;default&#x27;</span><br><span class="line">Renaming temporary part tmp_insert_200_1_1_0 to 200_1_1_0.</span><br><span class="line">-- 第三个分区</span><br><span class="line">Reserving 1.00 MB on disk &#x27;default&#x27;</span><br><span class="line">Renaming temporary part tmp_insert_50_1_1_0 to 50_1_1_0.</span><br></pre></td></tr></table></figure></li><li><p>由第一个分片确认完成写入<br>最后由 <code>ch5</code> 分片确认所有的数据发送完毕：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Finished processing /test_shard_2_all/default@ch6.vgbhfive.cn:9000/1.bin</span><br></pre></td></tr></table></figure></li></ol><p>至此整个流程结束，<code>Distributed</code> 表负责所有分片的写入工作。在由 <code>Distirbuted</code> 表负责向远端分片发送数据时，有异步和同步两种写模式：如果是异步写入则在 <code>Distributed</code> 表写完本地分片之后，<code>INSERT</code> 查询就会返回成功写入的消息；如果是同步写入则在 <code>INSERT</code> 查询之后，会等待所有分片完成写入。使用何种模式由 <code>insert_distributed_sync</code> 参数控制，默认为 <code>false</code>，即异步写入；如果将其设置为 <code>true</code>，则可以进一步通过 <code>insert_distributed_timeout</code> 参数控制同步等待的超时时间。</p><h6 id="副本复制数据流程"><a href="#副本复制数据流程" class="headerlink" title="副本复制数据流程"></a>副本复制数据流程</h6><p>除了刚才的分片写入流程之外，还会触发副本数据的复制流程。数据在多个副本之间，有两种复制实现方式：一种是继续借助 <code>Distributed</code> 表引擎，由它将数据写入副本。另一种则是借助 <code>ReplicatedMergeTree</code> 表引擎实现副本数据的分发。</p><h6 id="分布式查询流程"><a href="#分布式查询流程" class="headerlink" title="分布式查询流程"></a>分布式查询流程</h6><p>与数据写入有所不同，在面向集群查询数据的时候，只能通过 <code>Distributed</code> 表引擎实现。当 <code>Distributed</code> 表接收到 <code>SELECT</code> 查询的时候，他会依次查询每个分片的数据，再合并汇总返回。</p><ol><li><p>多副本的路由规则<br>在查询数据的时候，如果集群中的一个 <code>shard</code>，拥有多个 <code>replica</code>，那么 <code>Distributed</code> 表引擎需要面临副本选择的问题。他会使用负载均衡算法从众多 <code>replica</code> 中选择一个，而具体使用何种负载均衡算法，则由 <code>load_balancing</code> 参数控制：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load_balancing = random / nearest_hostname / in_order / first_or_random</span><br></pre></td></tr></table></figure><p>有四种负载均衡算法：</p><ul><li><code>random</code></li><li><code>nearest_hostname</code></li><li><code>in_order</code></li><li><code>first_or_random</code></li></ul></li><li><p>多分片查询<br>分布式查询与分布式写入类似，同样本着谁执行谁负责的原则，他会接收 <code>SELECT</code> 查询的 <code>Distributed</code> 表并负责串联起整个过程。首先他会针对分布式表的 <code>SQL</code> 语句，按照分片数量将查询拆分为若干个本地表的子查询，然后向各个分片发起查询，然后再汇总各个分片的返回结果。</p></li></ol><hr><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><hr><h3 id="个人备注"><a href="#个人备注" class="headerlink" title="个人备注"></a>个人备注</h3><p><strong>此博客内容均为作者学习所做笔记，侵删！</strong><br><strong>若转作其他用途，请注明来源！</strong></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h3&gt;&lt;p&gt;随着业务线数据量的突飞猛进、服务器的意外宕机，这些都是底层基础服务会遇到的问题，因此 &lt;code&gt;ClickHouse&lt;/code&gt; 就设计了&lt;strong&gt;集群&lt;/strong&gt;、&lt;strong&gt;副本&lt;/strong&gt;和&lt;strong&gt;分片&lt;/strong&gt;这三个帮手来帮忙。&lt;/p&gt;</summary>
    
    
    
    
    <category term="ClickHouse" scheme="https://blog.vgbhfive.cn/tags/ClickHouse/"/>
    
  </entry>
  
  <entry>
    <title>ClickHouse-MergeTree原理</title>
    <link href="https://blog.vgbhfive.cn/ClickHouse-MergeTree%E5%8E%9F%E7%90%86/"/>
    <id>https://blog.vgbhfive.cn/ClickHouse-MergeTree%E5%8E%9F%E7%90%86/</id>
    <published>2022-07-31T05:57:06.000Z</published>
    <updated>2023-01-01T15:47:47.089Z</updated>
    
    <content type="html"><![CDATA[<h3 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h3><p>表引擎是 <code>ClickHouse</code> 设计实现的一大特色，也可以说是表引擎成就了一张表的最终<em>面貌</em>。</p><span id="more"></span><hr><h3 id="创建方式"><a href="#创建方式" class="headerlink" title="创建方式"></a>创建方式</h3><p><code>MergeTree</code> 在写入一批数据时，数据总会以片段的形式写入磁盘，且数据片段不能修改，但为了避免数据片段过多，<code>ClickHouse</code> 会在后台线程定期合并这些数据片段，属于相同分区的数据片段会被合并成一个新的片段。这种合并的特征也就是合并树名称的由来。</p><p>创建 <code>MergeTree</code> 数据表的方式与之前的方式一样，但需要将 <code>ENGINE</code> 声明为 <code>MergeTree()</code>。另外 <code>MergeTree()</code> 表引擎除了常规的配置参数之外，还有独有的配置选项。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] [db_name.]table_name (</span><br><span class="line">    name1 [type] [<span class="keyword">DEFAULT</span><span class="operator">|</span>MATERIALIZED<span class="operator">|</span>ALIAS expr],</span><br><span class="line">    name2 [type] [<span class="keyword">DEFAULT</span><span class="operator">|</span>MATERIALIZED<span class="operator">|</span>ALIAS expr]</span><br><span class="line">) ENGINE <span class="operator">=</span> MergeTree()</span><br><span class="line">[<span class="keyword">PARTITION</span> <span class="keyword">BY</span> expr]</span><br><span class="line">[<span class="keyword">ORDER</span> <span class="keyword">BY</span> expr]</span><br><span class="line">[<span class="keyword">PRIMARY</span> KEY expr]</span><br><span class="line">[SAMPLE <span class="keyword">BY</span> expr]</span><br><span class="line">[SETTING name<span class="operator">=</span><span class="keyword">value</span>, ...]</span><br></pre></td></tr></table></figure><ol><li><p><code>PARTITION BY expr</code> 分区键，用于指定表数据以何种标准进行分区。其中分区键既可以是单个列字段，也可以是通过元组的形式使用多个列字段，同时它也支持使用列表达式，如果不声明分区键则 <code>ClickHouse</code> 会自动生成一个名为 <code>all</code> 的分区。</p></li><li><p><code>ORDER BY expr</code> 排序键，用于指定在一个数据片段内，数据以何种方式标准排序。默认情况下主键与排序键相同。</p></li><li><p><code>PRIMARY KEY expr</code> 主键，声明后会依靠主键生成一级索引，用于加速表查询。默认情况下，主键与排序键相同，所以通常使用 <code>ORDER BY</code> 代为指定主键。</p></li><li><p><code>SAMPLE BY</code> 抽样表达式，用于声明数据以何种标准进行采样。</p></li><li><p><code>SETTINGS key=value</code> 设置表引擎参数。</p><ul><li><code>index_granulatrity</code> 表示索引粒度，默认值为 <code>8192</code>。</li><li><code>index_granulatrity_bytes</code> 表示索引间隔大小，即控制每一批次写入数据的题量大小，默认为 <code>10M</code>，当设置为 <code>0</code> 时表示不启动自适应功能。</li><li><code>enabled_mixed_granulatrity_parts</code> 表示是否开启自适应索引间隔的功能，默认开启。</li><li><code>merge_with_ttl_timeout</code> 数据 <code>TTL</code> 的功能。</li><li><code>storage_policy</code> 多路径存储策略。</li></ul></li></ol><hr><h3 id="存储结构"><a href="#存储结构" class="headerlink" title="存储结构"></a>存储结构</h3><p><code>MergeTree</code> 表引擎中的数据是拥有物理存储的，数据会按照分区目录的形式保存到磁盘上。<br><img src="https://s2.loli.net/2022/08/02/J7XR9l5MngsxYUh.jpg" alt="click-3-1.jpg"></p><ol><li><p><code>partition</code> 分区目录，余下的各类数据文件都是以分区目录的形式被组织存储的，属于相同分区的数据最终都会被合并到同一个分区目录，而不同分区的数据永远不会被合并。</p></li><li><p><code>checksums.txt</code> 校验文件，使用二进制格式存储。它保存了余下各类文件的 <code>size</code> 大小和 <code>size</code> 的哈希值，用于快速校验文件的完整性和正确性。</p></li><li><p><code>columns.txt</code> 列信息文件，使用明文格式存储。用于保存此数据分区下的列字段信息。</p></li><li><p><code>count.txt</code> 计数文件，使用明文格式存储。用于记录当前数据分区目录下数据的总行数。</p></li><li><p><code>primary.txt</code> 一级索引文件，使用二进制格式存储。用于存放稀疏索引，一张 <code>MergeTree</code> 表只能声明一次一级索引。通过一级索引可以在查询数据时排除主键条件范围之外的数据文件，从而有效减少数据扫描范围，加速查询速度。</p></li><li><p><code>[Column].bin</code> 数据文件，使用压缩格式存储，默认为 <code>LZ4</code> 压缩格式，用于存储某一列的数据。由于 <code>MergeTree</code> 采用列式存储，所以每一列字段都拥有独立的 <code>.bin</code> 数据文件，并以列字段名称命名。</p></li><li><p><code>[Column].mrk</code> 列字段标记文件，使用二进制格式存储。标记文件中保存 <code>.bin</code> 文件中数据的偏移量信息。标记文件与稀疏索引对齐，又与 <code>.bin</code> 文件一一对应，即 <code>MergeTree</code> 通过标记文件建立了 <code>primary.idx</code> 稀疏索引与 <code>.bin</code> 数据文件之间映射关系。即首先通过稀疏索引找到对应数据的偏移量信息，再通过偏移量从 <code>.bin</code> 文件中读取数据，由于 <code>.bin</code> 文件与 <code>.mrk</code> 标记文件一一对应，所以 <code>MergeTree</code> 中的每个列字段都会拥有与其对应的 <code>.mrk</code> 标记文件。</p></li><li><p><code>[Column].mrk2</code> 若使用了自适应大小的索引间隔，则标记文件会以 <code>.mrk2</code> 命名，工作原理和作用与 <code>.mrk</code> 标记文件相同。</p></li><li><p><code>partition.dat</code> 和 <code>minmax_[Column].idx</code> 若使用了分区键，则会生成 <code>partition.dat</code> 和 <code>minmax</code> 索引文件，均使用二进制格式存储。其中 <code>partition.dat</code> 用于保存当前分区下分区表达式最终生成的值；而 <code>minmax</code> 索引用于记录当前分区下分区字段对应原始数据的最小和最大值。 </p></li><li><p><code>skp_idx_[Column].idx</code> 和 <code>skp_idx_[Column].mrk</code> 若在建表语句中声明了二级索引，则会额外生成相应的的二级索引与标记文件，也是使用二进制存储。同时二级索引又被称为跳数索引，目前拥有 <code>minmax</code>、 <code>set</code>、 <code>ngrambf_v1</code> 和 <code>tokenbf_v1</code> 四种类型，这些索引与一级稀疏索引相同，都是为了进一步减少所需扫描的数据范围，以加速整个查询过程。</p></li></ol><hr><h3 id="数据分区"><a href="#数据分区" class="headerlink" title="数据分区"></a>数据分区</h3><p>在 <code>ClickHouse</code> 中数据分区（<code>partition</code>）和数据分区（<code>shard</code>）是完全不同的概念。数据分区是针对本地数据而言的，是对数据的一种<strong>纵向切分</strong>，<code>MergeTree</code> 并不能依靠数据分区的特性，将一张表的数据分布到多个 <code>ClickHouse</code> 节点中。而数据分片则是对数据进行<strong>横向切分</strong>。</p><h4 id="分区规则"><a href="#分区规则" class="headerlink" title="分区规则"></a>分区规则</h4><p><code>MergeTree</code> 数据分区的规则是由分区 <code>ID</code> 决定的，而具体到每个数据分区所对应的 <code>ID</code>，则是由分区键的取值决定的。<br>分区键支持使用一个或一组表达式声明，其业务语义可以是年、月、日或时等任何一种限制。针对不同取值类型，分区 <code>ID</code> 的生成逻辑目前有四种逻辑：</p><ul><li>不指定分区键，如果不使用分区键，即不使用 <code>PARTITION BY</code> 声明任何分区表达式，则分区 <code>ID</code> 默认取名为 <code>all</code>，所有的数据都会被写入到这个 <code>all</code> 分区。</li><li>使用整数，如果分区键取值属于整形，且无法转换为日期类型，则直接按照该整形的字符串形式输出，作为分区 <code>ID</code> 的取值。</li><li>使用日期类型，如果分区键取值属于日期类型，或者能转换为日期类型，则可以按照 <code>YYYYMMDD</code> 格式化后的字符串形式输出，作为分区 <code>ID</code> 的取值。</li><li>使用其他类型，如果分区键既不属于整形，也不属于日期类型，则通过 <code>128</code> 位 <code>Hash</code> 算法取其 <code>Hash</code> 值作为分区 <code>ID</code> 的取值。</li></ul><p><small>如果通过元组的形式使用多个分区字段，则分区 <code>ID</code> 依旧是按照上述规则生成，只是多个 <code>ID</code> 之间通过 <code>-</code> 符号依次连接。</small></p><h4 id="分区目录的命名规则"><a href="#分区目录的命名规则" class="headerlink" title="分区目录的命名规则"></a>分区目录的命名规则</h4><p>完整分区目录的命名公式所示：<code>PartitionID_MinBlockNum_MaxBlockNum_Level</code>。</p><ul><li><code>partitionID</code> 分区 <code>ID</code>。</li><li><code>MinBlockNum</code> 和 <code>MaxBlockNum</code> 顾名思义最小数据块编号和最大数据块编号。</li><li><code>Level</code> 合并的层级，可以理解为某个分区被合并的次数，或者为这个分区的年龄。</li></ul><h4 id="分区目录的合并过程"><a href="#分区目录的合并过程" class="headerlink" title="分区目录的合并过程"></a>分区目录的合并过程</h4><p><code>MergeTree</code> 的分区目录在某种意义上与其他数据库是不同的。<br>首先，<code>MergeTree</code> 的分区目录并不是在数据表被创建之后就存在的，而是在数据被写入过程中被 创建。即没有数据时分区目录是不存在的。<br>其次，分区目录在建立之后并不是一成不变的，在其他的数据库中，追加数据后目录自身并不会变化，只是在相同目录下添加数据文件。而 <code>MeregTree</code> 完全不同，在每一批数据写入后都会生成一批新的目录（即便是不同批次属于相同的数据，都会生成不同的分区目录）。而在这之后的某个时刻 <code>ClickHouse</code> 会通过后台任务将属于相同分区的多个目录进行合并成一个新的目录，已经存在的旧分区目录不会被立即删除，而是在这之后的某个时刻通过后台任务被删除。</p><p>属于同一个分区的多个目录在合并之后会生成一个新的目录，目录中的索引和数据文件都会被合并。新的目录名称的合并方式遵循以下规则，其中：</p><ul><li><code>MinBlockNum</code> 取同一分区内所有目录中最小的 <code>MinBlockNum</code> 值。</li><li><code>MaxBlockNum</code> 取同一分区内所有目录中最大的 <code>MaxBlockNum</code> 值。</li><li><code>Level</code> 取同一分区最大 <code>Level</code> 值并加一。</li></ul><p><img src="https://s2.loli.net/2022/08/06/zZxB9MF6G1Rjgkp.jpg" alt="neo4j-3-2.jpg"></p><p><small>分区目录在合并之后，旧分区目录并没有被删除，但旧分区目录的状态却不是激活状态，因此在查询数据时，会被自动过滤。</small></p><hr><h3 id="一级索引"><a href="#一级索引" class="headerlink" title="一级索引"></a>一级索引</h3><p><code>MergeTree</code> 的主键使用 <code>PRIMARY KEY</code> 定义，待主键定义之后 <code>MergeTree</code> 会依据 <code>index_granularity</code> 间隔为数据表生成一级索引并保存至 <code>primary.idx</code> 文件内，索引数据按照 <code>PRIMARY KEY</code> 排序。</p><h4 id="稀疏索引"><a href="#稀疏索引" class="headerlink" title="稀疏索引"></a>稀疏索引</h4><p><code>primary.idx</code> 文件内的一级索引采用稀疏索引实现。<br><img src="https://s2.loli.net/2022/08/06/YGCE16QrRgH7M2O.png" alt="neo4j-3-3.jpg"></p><p>简单来说，在稠密索引中每一行索引标记都会对应一行具体的数据记录，而在稀疏索引中每一行索引标记的是每一段数据，而不是一行。</p><p><small>稀疏索引的优势显而易见，仅需要使用少量的索引标记就能够记录大量数据的区间信息，且数据越大优势越明显。</small></p><h4 id="索引粒度"><a href="#索引粒度" class="headerlink" title="索引粒度"></a>索引粒度</h4><p>索引粒度对于 <code>MergeTree</code> 是一个非常重要的 <code>Point</code>，所以很有必要着重说明一下。索引粒度就犹如<em>标尺</em>一样会丈量整个数据的长度，并依照刻度对数据进行标注，最终将数据标记成多个间隔的小段。</p><p>数据以 <code>index_granularity</code> 粒度被标记成多个小区间，其中每个区间之间最多间隔 <code>index_granularity</code> 行数据。<code>MergeTree</code> 使用 <code>MarkRange</code> 表示一个具体的区间，并通过 <code>start</code> 和 <code>end</code> 表示具体的范围。<br><code>index_granularity</code> 的命名中包含索引，但并不仅作用于一级索引，同时也会影响数据标记 <code>.mrk</code> 和数据文件 <code>.bin</code>，因为仅借助一级索引是无法完成查询的，需要借助数据标记才能定位具体数据。</p><h4 id="索引数据的生成规则"><a href="#索引数据的生成规则" class="headerlink" title="索引数据的生成规则"></a>索引数据的生成规则</h4><p>由于是稀疏索引所以 <code>MergeTree</code> 需要间隔 <code>index_granularity</code> 行数据才会生成一条索引记录，其索引值会依据声明的主键字段获取。<br><img src="https://s2.loli.net/2022/08/07/mn78HpxLhfSUwTN.jpg" alt="neo4j-3-4.jpg"></p><p><small><code>A00A8192A16384</code> 在 <code>MergeTree</code> 对于稀疏索引的存储是非常紧凑的，索引值前后相连，按照主键字段顺序紧密的列在一起。</small></p><h4 id="索引的查询过程"><a href="#索引的查询过程" class="headerlink" title="索引的查询过程"></a>索引的查询过程</h4><p>前面说过了 <code>MarkRange</code> 是用于在 <code>ClickHouse</code> 中用于定义标记区间的对象。<code>MergeTree</code> 按照 <code>index_granularity</code> 的间隔粒度，将一段完整的数据划分为多个小的间隔数据，一个具体的数据段即一个 <code>MarkRange</code>，与索引编号一一对应，使用 <code>start</code> 和 <code>end</code> 两个属性表示其区间范围，通过 <code>start</code> 和 <code>end</code> 对应的索引编号的取值即能够得到对应的数值区间，而数值区间即此 <code>MarkRange</code> 包含的数据范围。</p><p><img src="https://s2.loli.net/2022/08/07/m7zwiE3HQfaKRrZ.jpg" alt="neo4j-3-5.jpg"><br>索引查询其本质就是两个数值区间的交集判断，其中一个区间是由基于主键的查询条件转换而来的条件区间，而另一个区间则是 <code>MarkRange</code> 对应的数值区间。具体可以分为三个步骤：</p><ul><li>生成查询条件区间。将查询条件转换为条件区间，即便是单个值的查询条件也会被转换为区间的形式。</li><li>递归交集判断。以递归的形式依次对 <code>MarkRange</code> 的数值区间与条件区间做交集判断。<br>  假设从最大的区间 <code>[+A000, +inf)</code> 开始：<ul><li>如果不存在交集，则直接通过剪枝算法优化此段 <code>MarkRange</code>。</li><li>如果存在交集，且 <code>MarkRange</code> 步长大于 <code>8 * (end - start)</code> ，则将此区间进一步拆分为八个子区间（由 <code>merge_tree_coarse_index_granularity</code> 指定，默认值为 <code>8</code>），并重复此规则继续做递归交集判断。</li><li>如果存在交集，且 <code>MarkRange</code> 不可再分解（步长小于 <code>8</code>），则记录 <code>MarkRange</code> 并返回。</li></ul></li><li>合并 <code>MarkRange</code> 区间。将最终匹配的 <code>MarkRange</code> 聚在一起，合并他们的范围。</li></ul><p><img src="https://s2.loli.net/2022/08/08/ZxSk8mAEG31JaQf.png" alt="neo4j-3-6-1.jpg"></p><hr><h3 id="二级索引"><a href="#二级索引" class="headerlink" title="二级索引"></a>二级索引</h3><p>除了一级索引以外 <code>MergeTree</code> 同样支持二级索引。二级索引又称被为跳数索引，由数据的聚合信息构建而成，根据索引类型的不同，其聚合信息的内容也不同。当然跳数索引的目的也与一级索引一样都是为了帮助查询时减少数据扫描的范围。<br>跳数索引在默认情况下是关闭的，需要设置 <code>allow_experimental_data_skipping_indices</code> 才能使用：<code>SET allow_experimental_data_skipping_indices = 1</code>。<br><small>该参数在新版本中已经被取消。</small></p><p>另外跳数索引需要在 <code>CREATE</code> 语句内定义，支持使用元组和表达式的形式声明，其完整的定义语法如下所示：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INDEX index_name expr TYPE index_type(...) GRANULARITY granularity</span><br></pre></td></tr></table></figure><p>与一级索引一样，如果在建表语句中声明跳数索引，则会额外生成相应的索引与标记文件（<code>skp_idx_[Column].idx</code> 和 <code>skp_idx_[Column].mrk</code>）。</p><h4 id="granularity-与-index-granularity-的关系"><a href="#granularity-与-index-granularity-的关系" class="headerlink" title="granularity 与 index_granularity 的关系"></a><code>granularity</code> 与 <code>index_granularity</code> 的关系</h4><p>不同的跳数索引之间除了拥有自身的参数之外，还拥有一个共同的参数就是 <code>granularity</code>。<br>对于跳数索引而言 <code>index_granularity</code> 定义数据的粒度，而 <code>granularity</code> 定义聚合信息汇总的粒度，即 <code>granularity</code> 定义一行跳数索引能够跳过多少个 <code>index_granularity</code> 区间的数据。</p><p>要解释 <code>granularity</code> 的作用，还要从跳数索引的数据生成规则说起，首先按照 <code>index_granularity</code> 粒度间隔将数据划分为 <code>n</code> 段，总共有 <code>[0, n-1]</code> 个区间，接着根据索引定义时声明的表达式，从 <code>0</code> 区间开始，依次按 <code>index_granularity</code> 粒度从数据中获取聚合信息，每次向前移动一步，聚合信息逐步累加，最后当移动 <code>granularity</code> 次区间时，则汇总并生成一行跳数索引数据。<br><img src="https://s2.loli.net/2022/08/08/MgqKXhi8ysPpxmn.png" alt="neo4j-3-7.png"></p><h4 id="跳数索引的类型"><a href="#跳数索引的类型" class="headerlink" title="跳数索引的类型"></a>跳数索引的类型</h4><p><code>MergeTree</code> 支持四种跳数索引，分别是 <code>minmax</code>、 <code>set</code>、 <code>ngrambf_v1</code> 和 <code>tokenbf_v1</code>。</p><ul><li><code>minmax</code>：记录了一段数据内的最小和最大值，其索引的作用类似分区目录的 <code>minmax</code> 索引，能够快速跳过无用的数据区间。  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INDEX a ID TYPE minmax GRANULARITY 5</span><br></pre></td></tr></table></figure></li><li><code>set</code>：直接记录了声明字段或表达式的取值（唯一值，无重复），其完整形式为 <code>set(max_rows)</code>，其中 <code>max_rows</code> 是一个阈值，表示在一个 <code>index_granularity</code> 内，索引最多记录的数据行数。  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INDEX b (length(ID) * 8) TYPE set(256) GRANULARITY 5</span><br></pre></td></tr></table></figure></li><li><code>ngrambf_v1</code>：记录的是数据短语的布隆表过滤器，只支持 <code>String</code> 和 <code>FixedString</code> 数据类型，<code>ngrambf_v1</code> 只能够提升 <code>in</code>、 <code>notIn</code>、 <code>like</code>、 <code>equals</code> 和 <code>notEquals</code> 查询的性能，其完整形式为 <code>ngrambf_v1(n, size_of_bloom_filter_in_bytes, number_of_hash_functions, random_seed)</code>。  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INDEX c (ID, Code) TYPE ngrambf_v1(3, 256, 2, 0) GRANULARITY 5</span><br></pre></td></tr></table></figure></li><li><code>tokenbf_v1</code>：是 <code>ngrambf_v1</code> 的变种，同样是一种布隆过滤器索引，<code>tokenbf_v1</code> 除了短语 <code>token</code> 的处理方法外，其他与 <code>ngrambf_v1</code> 是完全一样的，<code>tokenbf_v1</code> 会自动按照非字符的、数字的字符串分割 <code>token</code>。  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INDEX d ID TYPE tokenbf_v1(256, 2, 0) GRANULARITY 5</span><br></pre></td></tr></table></figure></li></ul><p><small>一张表支持声明多个跳数索引。</small></p><hr><h3 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h3><p>前面短暂提过在 <code>MergeTree</code> 中数据是按照列存储的，那么具体的存储细节、<code>MergeTree</code> 如何工作接下来就会说明。</p><h4 id="各列独立存储"><a href="#各列独立存储" class="headerlink" title="各列独立存储"></a>各列独立存储</h4><p>在 <code>MergeTree</code> 中，数据按列存储，而具体到每个列字段，数据也是独立存储的，每个列字段都有对应的 <code>.bin</code> 数据文件，承载着数据的物理存储。数据文件以分区目录的形式被存储，所以 <code>.bin</code> 数据文件只会保存当前分区片段内的这一部分数据。<br>按列独立存储的优势：</p><ul><li>更好地进行数据压缩（相同类型地数据放在一起，对压缩更友好）。</li><li>最小化数据扫描的范围。</li></ul><p><code>MergeTree</code> 并不是一股脑地将数据写入 <code>.bin</code> 数据文件，首先数据是经过压缩的，目前支持 <code>LZ4</code>、 <code>ZSTD</code>、 <code>Multiple</code> 和 <code>Delta</code> 几种算法，默认使用 <code>LZ4</code> 算法；其次数据会按照 <code>ORDER BY</code> 的声明排序；最后数据以压缩数据块的形式被组织写入 <code>.bin</code> 数据文件。</p><h4 id="压缩数据块"><a href="#压缩数据块" class="headerlink" title="压缩数据块"></a>压缩数据块</h4><p>一个压缩数据块由头信息和压缩数据两部分组成，头信息固定使用 <code>9</code> 位字节组成，具体由 <code>1</code> 个 <code>UInt8</code> （<code>1</code> 字节）整形和 <code>2</code> 个 <code>UInt32</code> （<code>4</code> 字节）整形组成，分别代表使用的用压缩算法类型、压缩后的数据大小和压缩前的数据大小。</p><p><code>.bin</code> 压缩文件是由多个压缩数据块组成的，而每个压缩数据块的头信息则基于 <code>CompressionMethod_CompressedSize_UncompressedSize</code> 公式生成的。<br>每个压缩数据块的体积按照其压缩前的数据字节大小被阉割控制在 <code>64KB ~ 1MB</code>，其上下限分别由 <code>min_compress_block_size</code> （默认 <code>65536</code>）和 <code>max_compress_block_size</code> （默认 <code>1048576</code>）参数指定。而一个压缩数据块的大小则是由 <code>index_granularity</code> 内数据的实际大小相关。</p><p><code>MergeTree</code> 在数据具体的写入过程中，会依照索引粒度（默认 <code>8192</code>），按批次获取数据并进行处理。如果把一批数据的未压缩大小设为 <code>size</code>，则整个写入过程遵循以下规则：</p><ul><li>单个批次数据 <code>size &lt; 64KB</code>：如果单个批次数据小于 <code>64KB</code>，则继续获取下一批次数据直到大于 <code>64KB</code>，然后生成一个数据压缩块。</li><li>单个批次数据 <code>64KB &lt;= size &lt;= 1MB</code>：如果单个批次数据大小刚好在 <code>64KB</code> 和 <code>1MB</code> 之间，则可以直接生成下一个数据压缩块。</li><li>单个批次数据 <code>size &gt; 1MB</code>：如果单个批次数据大于 <code>1MB</code>，则会截断 <code>1MB</code> 大小数据并生成一个压缩数据块，剩余数据继续依据上述规则执行。<br><img src="https://s2.loli.net/2022/08/09/X97lhzTVn6sdwWE.png" alt="neo4j-3-8.png"></li></ul><p>在 <code>.bin</code> 文件中引入压缩数据块的目的有以下两个：</p><ul><li>虽然数据被压缩后能够有效减少数据大小，降低存储空间并加属数据传输效率，但数据的压缩和解压动作，其本身也会带来额外的性能损耗。所以需要控制被压缩数据的大小，以求在性能损耗和压缩率之间寻求平衡。</li><li>在具体读取某一列数据时，首先需要将压缩数据加载到内存并解压，这样才能后续处理。通过压缩数据块，可以在步读取整个 <code>.bin</code> 文件的情况下将读取粒度降低到压缩数据块级别，从而缩小数据读取的范围。</li></ul><hr><h3 id="数据标记"><a href="#数据标记" class="headerlink" title="数据标记"></a>数据标记</h3><p>如果把 <code>MergeTree</code> 比作一本书，那么 <code>primary.idx</code> 一级索引就是这本书的目录，<code>.bin</code> 文件就是书中的内容，而 <code>.mrk</code> 文件则是一级章节目录和具体内容之间的关联。<br>主要记录以下两点重要信息：</p><ul><li>一级章节对应的页码信息。</li><li>一段文字内容在某一页中的起始位置信息。</li></ul><h4 id="数据标记的生成规则"><a href="#数据标记的生成规则" class="headerlink" title="数据标记的生成规则"></a>数据标记的生成规则</h4><p>数据标记作为衔接一级索引与数据之间的桥梁，类似于书签，且书中的每一个章节都有自己的书签。<br><img src="https://s2.loli.net/2022/08/23/dM58XwQJVgL6o1Z.png" alt="neo4j-3-9.png"></p><p>在上述中可以发现数据标记的首个特征即数据标记和索引区间是对齐的，均按照 <code>index_granularity</code> 的粒度间隔，如此一来只需简单通过索引区间的下标编号即可找到对应的数据标记。<br>为了能够与数据衔接，数据标记文件也与 <code>.bin</code> 文件一一对应，即每一个列字段 <code>[Column].bin</code> 文件都有一个与之对应的 <code>[Column].mrk</code> 数据标记文件，用于记录数据在 <code>.bin</code> 文件中的偏移量信息。<br>一行标记数据使用一个元组表示，元组内包含两个整形数值的偏移量信息，他们分别表示在此段数据区间内，在对应的 <code>.bin</code> 压缩文件中压缩数据块的起始偏移量；以及将该数据压缩块解压后，其未压缩数据的起始偏移量。</p><p>每一行标记数据都表示一个片段的数据在 <code>.bin</code> 压缩文件中的位置信息。标记数据与一级索引数据不同，并不能常驻内存，而是使用 <code>LRU</code> 缓存策略加快其取用速度。</p><h4 id="数据标记的工作方式"><a href="#数据标记的工作方式" class="headerlink" title="数据标记的工作方式"></a>数据标记的工作方式</h4><p><code>MergeTree</code> 在读取数据时必须通过标记数据的位置信息才能找到所需要的数据，整个查找过程大致可以分为<strong>读取压缩数据块</strong>和<strong>读取数据</strong>两个步骤。</p><ul><li>读取压缩数据块，在查询某一列数据时，<code>MergeTree</code> 无需一次性加载全部 <code>.bin</code> 文件，而是可以根据需要，只加载特定的压缩数据块。</li><li>读取数据，在读取解压后的数据时，<code>MergeTree</code> 并不需要一次性扫描全部解压数据，而是可以根据需要以 <code>index_granularity</code> 的粒度加载特定的一小段，而为了实现这一特性需要借助标记文件中保存的解压数据块中的偏移量。</li></ul><hr><h3 id="协同总结"><a href="#协同总结" class="headerlink" title="协同总结"></a>协同总结</h3><p>在说明上述的特性后，下面按照写入过程、查询过程以及数据标记和压缩数据块的三种对应关系的角度来说一说。</p><h4 id="写入过程"><a href="#写入过程" class="headerlink" title="写入过程"></a>写入过程</h4><p>数据写入的第一步就是生成分区目录，伴随着每一批数据的写入，都会生成一个新的分区目录。而在后续的某一时刻，属于相同分区的目录会按照规则继续合并。接下来会按照 <code>index_granularity</code> 索引粒度，会分别生成 <code>primary.idx</code> 一级索引、列字段 <code>.mrk</code> 数据标记和 <code>.bin</code> 数据压缩文件。<br>其中索引与标记都是一一对应的，而标记与数据压缩块则是根据区间数据的大小会生成多对一、一对一、一对多三种关系。</p><h4 id="查询过程"><a href="#查询过程" class="headerlink" title="查询过程"></a>查询过程</h4><p>数据查询的本质就是一个不断缩小数据范围的过程，在理想的情况下，<code>MergeTree</code> 借助分区索引、一级索引、二级索引，将数据扫描到最小，然后借助数据标记，将需要解压与计算的数据范围缩至最小。<br>当然最坏的情况就是查询语句没有匹配到任何的索引，那么在后续的数据扫描中，会扫描所有的分区目录，以及目录内索引段的最大区间，当然在此虽然不能减少数据扫描范围，不过以及可以借助数据标记，同时以多线程的方式同时读取多个压缩块以提升性能。</p><h4 id="数据标记与压缩数据块之间对应关系"><a href="#数据标记与压缩数据块之间对应关系" class="headerlink" title="数据标记与压缩数据块之间对应关系"></a>数据标记与压缩数据块之间对应关系</h4><p>由于数据压缩块的划分与一个间隔 <code>index_granularity</code> 内的数据大小有关，每个数据压缩块的体积被限制在 <code>64KB~1MB</code> 之间，同时一个间隔内的数据又只会产生一行数据标记，那么根据一个间隔内的数据的实际字节大小，数据标记和压缩数据块之间产生了不同的三种关系。</p><ul><li>多对一，即多个数据标记对应一个数据压缩块。当一个间隔内的数据未压缩大小小于 <code>64KB</code>，则会出现这种情况。</li><li>一对一，即一个数据标记对应一个数据压缩块。当一个间隔内的数据未压缩大小刚好大于等于 <code>64KB</code> 且小于 <code>1MB</code>，则会出现这种情况。</li><li>一对多，即一个数据标记对应多个数据压缩块。当一个间隔内的数据未压缩大小直接大于 <code>1MB</code>，则会出现这种情况。</li></ul><hr><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><hr><h3 id="个人备注"><a href="#个人备注" class="headerlink" title="个人备注"></a>个人备注</h3><p><strong>此博客内容均为作者学习所做笔记，侵删！</strong><br><strong>若转作其他用途，请注明来源！</strong></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;引入&quot;&gt;&lt;a href=&quot;#引入&quot; class=&quot;headerlink&quot; title=&quot;引入&quot;&gt;&lt;/a&gt;引入&lt;/h3&gt;&lt;p&gt;表引擎是 &lt;code&gt;ClickHouse&lt;/code&gt; 设计实现的一大特色，也可以说是表引擎成就了一张表的最终&lt;em&gt;面貌&lt;/em&gt;。&lt;/p&gt;</summary>
    
    
    
    
    <category term="ClickHouse" scheme="https://blog.vgbhfive.cn/tags/ClickHouse/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot集成Prometheus-自定义指标</title>
    <link href="https://blog.vgbhfive.cn/SpringBoot%E9%9B%86%E6%88%90Prometheus-%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8C%87%E6%A0%87/"/>
    <id>https://blog.vgbhfive.cn/SpringBoot%E9%9B%86%E6%88%90Prometheus-%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8C%87%E6%A0%87/</id>
    <published>2022-07-16T09:22:58.000Z</published>
    <updated>2022-08-17T13:19:43.023Z</updated>
    
    <content type="html"><![CDATA[<h3 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h3><p>这里首先说以下整体大概的思路，第一步当然是引入对应的 <code>SDK</code>，第二步则是添加配置信息、定义自定义指标，并进行注册，接下来的第三步则是指标根据具体业务的处理逻辑，那么最后一步就是在 <code>prometheus</code> 服务中增加 <code>job</code> 配置，最终在 <code>grafana</code> 中展示自定义指标。</p><span id="more"></span><hr><h3 id="实操"><a href="#实操" class="headerlink" title="实操"></a>实操</h3><h4 id="引入-SDK"><a href="#引入-SDK" class="headerlink" title="引入 SDK"></a>引入 <code>SDK</code></h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- Micrometer Prometheus registry  --&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;io.micrometer&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">&lt;!-- https://mvnrepository.com/artifact/io.micrometer/micrometer-registry-prometheus --&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;io.micrometer&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.9.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><h4 id="配置信息"><a href="#配置信息" class="headerlink" title="配置信息"></a>配置信息</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">management.endpoints.enabled-by-default=false</span><br><span class="line">management.endpoint.health.enabled=true</span><br><span class="line">management.endpoint.metrics.enabled=true</span><br><span class="line">management.endpoint.prometheus.enabled=true</span><br><span class="line">management.endpoints.web.exposure.include=health,prometheus,metrics</span><br><span class="line">management.metrics.tags.application=$&#123;spring.application.name&#125;</span><br></pre></td></tr></table></figure><h4 id="注册自定义指标"><a href="#注册自定义指标" class="headerlink" title="注册自定义指标"></a>注册自定义指标</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">@Component</span><br><span class="line">public class ContentListener implements ApplicationListener&lt;ContextRefreshedEvent&gt; &#123;</span><br><span class="line"></span><br><span class="line">private Logger logger = LoggerFactory.getLogger(ContentListener.class);</span><br><span class="line"></span><br><span class="line">private Counter counter;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public void onApplicationEvent(ContextRefreshedEvent event) &#123;</span><br><span class="line">logger.info(&quot;start register prometheus counter&quot;);</span><br><span class="line">CollectorRegistry collectorRegistry = event.getApplicationContext().getBean(CollectorRegistry.class);</span><br><span class="line">counter = Counter.build().name(&quot;xx_counter&quot;).labelNames(&quot;label1&quot;, &quot;label2&quot;).help(&quot;xx counter help&quot;).register(collectorRegistry);</span><br><span class="line">logger.info(&quot;end register prometheus counter&quot;);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   private Counter getCounter() &#123;</span><br><span class="line">   return this.counter;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="指标业务逻辑"><a href="#指标业务逻辑" class="headerlink" title="指标业务逻辑"></a>指标业务逻辑</h4><ol><li><p>自定义指标注解</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">@Documented</span><br><span class="line">@Retention(RUNTIME)</span><br><span class="line">@Target(METHOD)</span><br><span class="line">public @interface Counter &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>注解实现</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">@Aspect</span><br><span class="line">@Component</span><br><span class="line">public class CounterAspect &#123;</span><br><span class="line"></span><br><span class="line">    private static final Logger logger = LoggerFactory.getLogger(CounterAspect.class);</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    private ContentListener contentListener;</span><br><span class="line"></span><br><span class="line">    @Pointcut(&quot;execution(* com.example.controller.*.*(..)) &amp;&amp; @annotation(com.example.annotation.Counter)&quot;)</span><br><span class="line">    private void cut() &#123; &#125;</span><br><span class="line"></span><br><span class="line">    @Around(&quot;cut()&quot;)</span><br><span class="line">    public Object advice(ProceedingJoinPoint pjp) throws Throwable &#123;</span><br><span class="line">        Object retValue = pjp.proceed();</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            // 记录结果指标</span><br><span class="line">            contentListener.getCounter().labels(&quot;label1&quot;, &quot;label2&quot;).inc();</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            logger.error(&quot;error&quot;, e);</span><br><span class="line">        &#125;</span><br><span class="line">        return retValue;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h4 id="Prometheus-Server-中增加-Job-配置"><a href="#Prometheus-Server-中增加-Job-配置" class="headerlink" title="Prometheus Server 中增加 Job 配置"></a><code>Prometheus Server</code> 中增加 <code>Job</code> 配置</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">job_name: &#x27;springboot-demo&#x27;</span><br><span class="line">  # metrics_path defaults to &#x27;/metrics&#x27;</span><br><span class="line">  # scheme defaults to &#x27;http&#x27;.</span><br><span class="line">  metrics_path: /actuator/prometheus</span><br><span class="line">  static_configs:</span><br><span class="line">    targets: [&#x27;localhost:8080&#x27;]</span><br></pre></td></tr></table></figure><p>接着重新启动 <code>prometheus</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./prometheus –config.file=prometheus.yml</span><br></pre></td></tr></table></figure><h4 id="grafana-展示自定义指标"><a href="#grafana-展示自定义指标" class="headerlink" title="grafana 展示自定义指标"></a><code>grafana</code> 展示自定义指标</h4><ol><li>检查 <code>curl http://localhost:8080/actuator/prometheus</code> 是否存在自定义指标。</li><li>在 <code>grafana</code> 中配置 <code>prometheus server</code> 数据源。</li><li>在面板中配置对应的指标和需要展示的图例。</li></ol><hr><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><hr><h3 id="个人备注"><a href="#个人备注" class="headerlink" title="个人备注"></a>个人备注</h3><p><strong>此博客内容均为作者学习所做笔记，侵删！</strong><br><strong>若转作其他用途，请注明来源！</strong></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;引入&quot;&gt;&lt;a href=&quot;#引入&quot; class=&quot;headerlink&quot; title=&quot;引入&quot;&gt;&lt;/a&gt;引入&lt;/h3&gt;&lt;p&gt;这里首先说以下整体大概的思路，第一步当然是引入对应的 &lt;code&gt;SDK&lt;/code&gt;，第二步则是添加配置信息、定义自定义指标，并进行注册，接下来的第三步则是指标根据具体业务的处理逻辑，那么最后一步就是在 &lt;code&gt;prometheus&lt;/code&gt; 服务中增加 &lt;code&gt;job&lt;/code&gt; 配置，最终在 &lt;code&gt;grafana&lt;/code&gt; 中展示自定义指标。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Java" scheme="https://blog.vgbhfive.cn/tags/Java/"/>
    
    <category term="Spring Boot" scheme="https://blog.vgbhfive.cn/tags/Spring-Boot/"/>
    
    <category term="Prometheus" scheme="https://blog.vgbhfive.cn/tags/Prometheus/"/>
    
  </entry>
  
  <entry>
    <title>ClickHouse-基础</title>
    <link href="https://blog.vgbhfive.cn/ClickHouse-%E5%9F%BA%E7%A1%80/"/>
    <id>https://blog.vgbhfive.cn/ClickHouse-%E5%9F%BA%E7%A1%80/</id>
    <published>2022-07-05T15:10:59.000Z</published>
    <updated>2023-01-01T15:49:14.746Z</updated>
    
    <content type="html"><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>大家都说 <code>MySQL</code> 和 <code>ClickHouse</code> 很像，如果你不了解 <code>ClickHouse</code>，那我觉得你是对的，但若是你了解，那你更需要往下看看。</p><span id="more"></span><h3 id="数据定义"><a href="#数据定义" class="headerlink" title="数据定义"></a>数据定义</h3><h4 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h4><p>作为一款分析性数据库，<code>ClickHouse</code> 提供了很多数据类型，这里面主要可以分为基础类型、复合类型和特殊类型。</p><h5 id="基础类型"><a href="#基础类型" class="headerlink" title="基础类型"></a>基础类型</h5><p>基础类型主要包含有数值、字符串和时间三种类型，没有 <code>Boolean</code> 类型，但是可以使用整形的 <code>0</code> 和 <code>1</code> 来代替。</p><ol><li><p>数值类型<br>数值类型分为整数、浮点数和定点数三类。</p><ul><li><code>Int</code>： <code>ClickHouse</code> 使用 <code>Int8</code>、 <code>Int16</code>、 <code>Int32</code>、 <code>Int64</code> 指代四种大小的 <code>Int</code> 类型，其末尾的数字正好表明占用字节的大小。</li><li><code>Float</code>：与整数类似，<code>ClickHouse</code> 直接使用 <code>Float32</code>、 <code>Float64</code> 代表单精度浮点数及双精度浮点数。</li><li><code>Decimal</code>：如果需要更高精度的数值运算，则需要使用定点数，<code>ClickHouse</code> 提供了 <code>Decimal32</code>、 <code>Decimal64</code>、 <code>Decimal128</code> 三种精度的定点数。可以通过两种形式声明定点：简写方式有 <code>Decimal32(S)</code>、 <code>Decimal64(S)</code>、 <code>Decimal128(S)</code> 三种；原生方式为 <code>Decimal(P, S)</code>，其中 <code>P</code> 代笔精度，决定总位数（整数部份+小数部分），<code>S</code> 代表规模，决定小数位数。</li></ul></li><li><p>字符串类型<br>字符串类型可以细分为 <code>String</code>、 <code>FixedString</code>、 <code>UUID</code> 三类。</p><ul><li><code>String</code>：字符串由 <code>String</code> 定义，长度不限。</li><li><code>FixedString</code>：定长字符串，在使用时需表明字符串的长度。</li><li><code>UUID</code>：<code>UUID</code> 是一种数据库常见的主键类型，在 <code>ClickHouse</code> 中被当作了一种数据类型，<code>UUID</code> 共有 <code>32</code> 位，格式为 <code>8-4-4-4-12</code>，如果一个 <code>UUID</code> 类型的字段在写入时没有被赋值则会被依照格式使用 <code>0</code> 填充。</li></ul></li><li><p>时间类型<br>时间类型分为 <code>DataTime</code>、 <code>DateTime64</code>、 <code>Date</code> 三类，<code>ClickHouse</code> 目前没有时间戳类型，时间类型最高精度是秒，也就是说如果需要处理毫秒、微秒等大于秒分辨率的时间，则只能借助 <code>UInt</code> 类型实现。</p><ul><li><code>DateTime</code>：包含时、分、秒信息，精确到秒，支持使用字符串形式写入。</li><li><code>DateTime64</code>：可以记录亚秒，在 <code>DateTime</code> 之上增加了精度的设置。</li><li><code>Date</code>：不包含具体的时间信息，只精确到天，同样也支持字符串形式写入。</li></ul></li></ol><h5 id="复合类型"><a href="#复合类型" class="headerlink" title="复合类型"></a>复合类型</h5><p>除了基础类型之外，<code>ClickHouse</code> 还提供了数组、元组、枚举和嵌套四类复合类型。</p><ul><li><code>Array</code>：数组有两种定义方式，常规方式为 <code>array(T)</code>，或者简写方式 <code>[T]</code>。通过上述发现在查询时并不需要主动声明数组的元素类型，因为 <code>ClickHouse</code> 的数组拥有类型推断的能力，而推断依据则是以最小存储代价为原则，即使用最小可表达的数据类型。</li><li><code>Tuple</code>：元组类型由 <code>1~n</code> 个元素组成，每个元素之间允许设置不同的数据类型，且彼此之间不要求兼容。元组同样支持类型推断，其推断仍然以最小的存储代价为原则。与数组类似元组也有两种方式定义，常规方式为 <code>tuple(T)</code>，或者简写方式 <code>(T)</code>。</li><li><code>Enum</code>：<code>ClickHouse</code> 支持枚举类型，提供了 <code>Enum8</code> 和 <code>Enum16</code> 两种枚举类型，他们除了取值范围不同之外，别无二致。枚举固定使用 <code>(String:Int) Key/Value</code> 键值对的形式定义数据，所以 <code>Enum8</code> 和 <code>Enum16</code> 分别对应 <code>(String:Int8)</code> 和 <code>(String:Int16)</code>。<br>  <small><code>Key/Value</code> 是不允许重复的，要保证唯一性。另外也不允许为 <code>Null</code>，但是 <code>Key</code> 允许是空字符串。</small></li><li><code>Nested</code>：嵌套类型，顾名思义就是一种嵌套表结构。一张表结构，可以定义任意多个嵌套类型字段，但每个字段的嵌套层级只支持一级，即嵌套表内不能继续使用嵌套类型。对于简单场景的层级关系或关联关系，使用嵌套类型也是不错的选择。</li></ul><h5 id="特殊类型"><a href="#特殊类型" class="headerlink" title="特殊类型"></a>特殊类型</h5><p><code>ClickHouse</code> 还有一类不同的数据类型，那就是特殊类型。</p><ul><li><code>Nullable</code>：准确说这并不是一种独立的数据类型，更像是一种辅助的修饰符，需要与基础数据一起搭配使用，表示某个基础数据可以是 <code>Null</code> 值。</li><li><code>Domain</code>：域名类型分为 <code>IPv4</code> 和 <code>IPv6</code> 两类，本质上就是对整形和字符串的进一步封装。但是在使用时不可当作字符串使用，因为其并不支持隐式的自动类型转换，如果需要返回 <code>IP</code> 的字符串形式，需要显式调用 <code>IPv4NumToString</code> 或 <code>IPv6NumToString</code> 函数进行转换。</li></ul><h4 id="数据表"><a href="#数据表" class="headerlink" title="数据表"></a>数据表</h4><p>之前说的都是数据类型，接下来就是 <code>DDL</code> 操作及定义数据的方法。</p><h5 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE DATABASE IF NOT EXISTS db_name [ENGINE = engine]</span><br></pre></td></tr></table></figure><p>数据库目前一共支持五种默认引擎：</p><ul><li><code>Ordinary</code>：默认引擎，大多数情况下使用的引擎，使用时无需声明。</li><li><code>Dictionary</code>：字典引擎，此类数据库会为所有数据字典创建他们的数据表。</li><li><code>Memory</code>：内存引擎，用于存放临时数据。</li><li><code>Lazy</code>： 日志引擎，只能使用 <code>Log</code> 系列的表引擎。</li><li><code>MySQL</code>：会自动拉取远端 <code>MySQL</code> 中的数据，并为他们创建 <code>MySQL</code> 表引擎的数据表。</li></ul><h5 id="数据表-1"><a href="#数据表-1" class="headerlink" title="数据表"></a>数据表</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE [IF NOT EXISTS] [db_name.]table_name (</span><br><span class="line">    name1 [type] [DEFAULT|MATERIALIZED|ALIAS expr],</span><br><span class="line">    name2 [type] [DEFAULT|MATERIALIZED|ALIAS expr]</span><br><span class="line">) ENGINE = engine</span><br></pre></td></tr></table></figure><p>上面是常见的创建表方式，下面则是通过复制其他表结构来创建表</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE [IF NOT EXISTS] [db_name1.]table_name1 AS [db_name2.]table_name2 [ENGINE = engine]</span><br></pre></td></tr></table></figure><h5 id="默认值表达式"><a href="#默认值表达式" class="headerlink" title="默认值表达式"></a>默认值表达式</h5><p>表字段支持三种默认值表达式的定义方法，分别是 <code>DEFAULT</code>、 <code>MATERIALIZED</code>、 <code>ALIAS</code>，无论使用哪种形式，表字段一旦被定义了默认值，便不再强制要求定义数据类型，因为 <code>ClickHouse</code> 会根据默认值进行类型推断。若是对表字段定义了数据类型和默认值表达式，则以明确定义的数据类型为主。</p><p>默认值表达式的三种定义方法之间也存在着不同之处：</p><ul><li>在数据写入时，只有 <code>DEFAULT</code> 类型的字段可以出现在 <code>INSERT</code> 语句中，而 <code>MATERIALIZED</code> 和 <code>ALIAS</code> 不能被显式赋值，只能通过计算取值。</li><li>在数据查询时，只有 <code>DEFAULT</code> 类型的字段可以出现在 <code>SELECT</code> 语句中，而 <code>MATERIALIZED</code> 和 <code>ALIAS</code> 不能出现在返回结果集中。</li><li>在数据存储时，只有 <code>DEFAULT</code> 和 <code>MATERIALIZED</code> 类型的字段才支持持久化，而 <code>ALIAS</code> 类型的字段不能被持久化，它的取值依赖于计算。</li></ul><h5 id="临时表"><a href="#临时表" class="headerlink" title="临时表"></a>临时表</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CREATE TEMPORARY TABLE [IF NOT EXISTS] [db_name.]table_name (</span><br><span class="line">    name1 [type] [DEFAULT|MATERIALIZED|ALIAS expr],</span><br><span class="line">    name2 [type] [DEFAULT|MATERIALIZED|ALIAS expr]</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>相比普通表而言，临时表由以下两点特殊之处：</p><ul><li>临时表的生命周期与会话绑定，所以他仅支持 <code>Memory</code> 表引擎，如果会话结束，数据表就会被销毁。</li><li>临时表不属于任何数据库，所以在建表语句中，没有数据库参数和表引擎参数。</li></ul><p><small>临时表的优先级大于普通表，当两张表名称相同时，会优先读取临时表的数据。</small></p><h5 id="分区表"><a href="#分区表" class="headerlink" title="分区表"></a>分区表</h5><p>数据分区（<code>partition</code>）和数据分片（<code>shard</code>）是完全不同的两个概念，数据分区是针对本地数据而言的，是数据的一种纵向切分，而数据分片是数据的横向切分。但是目前只有合并树（<code>MergeTree</code>）家族系列的引擎支持数据分区。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE [IF NOT EXISTS] [db_name.]table_name (</span><br><span class="line">    ID String,</span><br><span class="line">    Time Date</span><br><span class="line">) ENGINE = MergeTree()</span><br><span class="line">PARTITION BY toYYYYMM(Time)</span><br><span class="line">ORDER BY ID</span><br></pre></td></tr></table></figure><h5 id="视图"><a href="#视图" class="headerlink" title="视图"></a>视图</h5><p><code>ClickHouse</code> 拥有普通和物化两种视图，其中物化视图拥有独立的存储，而普通视图只是一层简单的查询代理。<br>普通视图不会存储任何数据，只是一层简单的 <code>SELECT</code> 查询映射，起着简化查询、明晰语义的作用，对查询性能不会有影响。而物化视图支持表引擎，数据保存形式由他的表引擎决定，物化视图创建好之后，如果源表被写入数据，那么物化视图也会同步更新。<br><code>POPULATE</code> 修饰符决定了物化视图的初始策略，若使用 <code>POPULATE</code> 则在创建视图时会将源表的数据一并导入，反之不使用 <code>POPULATE</code> 则物化视图初始是没有数据的，只会在同步之后写入源表的数据。另外物化视图不支持删除数据，源表中的数据被删除，物化视图中的数据不会被删除。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 创建普通视图的语法</span><br><span class="line">CREATE VIEW [IF NOT EXISTS] [db_name.]view_name AS SELECT ...</span><br><span class="line"># 创建物化视图的语法</span><br><span class="line">CREATE [MATERIALIZED] VIEW [IF NOT EXISTS] [db.]table_name [TO[db.]name] [ENGINE = engine] [POPULATE] AS SELECT ...</span><br></pre></td></tr></table></figure><h4 id="数据表操作"><a href="#数据表操作" class="headerlink" title="数据表操作"></a>数据表操作</h4><h5 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h5><ol><li><p>追加新字段</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE tb_name ADD COLUMN [IF NOT EXISTS] name [type] [default_expr] [AFTER name_after]</span><br></pre></td></tr></table></figure></li><li><p>修改数据类型</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE tb_name MODIFY COLUMN [IF EXISTS] name [type] [default_expr]</span><br></pre></td></tr></table></figure></li><li><p>修改备注</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE tb_name COMMENT COLUMN [IF EXISTS] name &#x27;some comment&#x27;</span><br></pre></td></tr></table></figure></li><li><p>删除已有字段</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE tb_name DROP COLUMN [IF EXISTS] name</span><br></pre></td></tr></table></figure></li><li><p>移动数据表</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RENAME TABLE [db_name1.]tb_name1 TO [db_name2.]tb_name2</span><br></pre></td></tr></table></figure><p>其原理与 <code>Linux</code> 系统中的 <code>mv</code> 命令异曲同工。</p></li><li><p>清空数据表</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TRUNCATE TABLE [IF EXISTS] [db_name.]tb_name</span><br></pre></td></tr></table></figure></li><li><p>查询分区信息<br><code>ClickHouse</code> 内置了许多 <code>system</code> 系统表，用于查询自身的状态信息，其中的 <code>parts</code> 系统表专门用于查询数据表的分区信息。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT partition_id, name, table, database FROM system.parts WHERE table = &#x27;partition_v2&#x27;</span><br></pre></td></tr></table></figure></li><li><p>删除指定分区</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE tb_name DROP PARTITION partition_expr</span><br></pre></td></tr></table></figure></li><li><p>复制分区数据<br><code>ClickHouse</code> 支持将 <code>A</code> 表的分区数据复制到 <code>B</code> 区，可以用于快速数据写入、多表间数据同步和备份等场景。当然此项特性支持是有前提的：</p></li></ol><ul><li>两张表需要拥有相同的分区键。</li><li>他们的表结构完全相同。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE B REPLACE PARTITION partition_expr FROM A</span><br></pre></td></tr></table></figure></li></ul><ol start="10"><li><p>重置分区数据<br>如果数据表的某一列数据有误，需要将其重置为初始值，如果声明了默认值表达式，则以表达式为准，否则以数据类型的默认值为准。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE tb_name CLEAR COLUMN column_name IN PARTITION partition_expr</span><br></pre></td></tr></table></figure></li><li><p>卸载装载分区<br>表分区可以通过 <code>DETACH</code> 语句卸载，分区被卸载后他的物理数据会被转移到当前数据表目录的 <code>detached</code> 子目录下，而装载分区则是反向操作，可以将 <code>detached</code> 子目录下的某个分区重新装载回去。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 卸载分区语法</span><br><span class="line">ALTER TABLE tb_name DETACH PARTITION partition_expr</span><br><span class="line"># 装载分区语法</span><br><span class="line">ALTER TABLE tb_name ATTACH PARTITION partition_expr</span><br></pre></td></tr></table></figure></li><li><p>备份还原分区<br>分区在被备份之后，会被统一保存到 <code>ClickHouse</code> 根路径 <code>/shadow/N</code> 子目录下，其中 <code>N</code> 是一个自增长的整数，它的含义是备份的次数，具体次数由 <code>shadow</code> 子目录下的 <code>increment.txt</code> 文件记录。而分区备份实质上是对原始目录文件进行硬链接，所以不会有额外的存储空间。整个备份目录会一直向上追溯到 <code>data</code> 根路径的整个链路。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/data/[database]/[table]/[partition_folder]</span><br></pre></td></tr></table></figure><p><code>FETCH</code> 的工作原理与 <code>ReplicatedMergeTree</code> 同步数据的原理类似，<code>FETCH</code> 通过指定的 <code>zk_path</code> 找到 <code>ReplicatedMergeTree</code> 的所有副本实例，然后从中选择一个最合适的副本，并下载相应的分区数据。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 备份分区语法</span><br><span class="line">ALTER TABLE tb_name FREEZE PARTITION partition_expr</span><br><span class="line"># 还原分区语法</span><br><span class="line">ALTER TABLE tb_name FETCH PARTITION partition_expr FROM zk_path</span><br></pre></td></tr></table></figure><p><small><code>FETCH</code> 只支持 <code>ReplicatedMergeTree</code> 系列的表引擎。</small></p></li></ol><h5 id="分布式的-DDL-操作"><a href="#分布式的-DDL-操作" class="headerlink" title="分布式的 DDL 操作"></a>分布式的 <code>DDL</code> 操作</h5><p><code>ClickHouse</code> 支持集群模式，一个集群拥有一个到多个节点。<code>CREATE</code>、 <code>ALTER</code>、 <code>DROP</code>、 <code>RENAME</code>、 <code>TRUNCATE</code> 这些 <code>DDL</code> 语句，都支持分布式执行。这意味着在集群中任意一个节点上执行 <code>DDL</code> 语句，那么集群中的每个节点都会以相同的顺序执行相同的语句。<br>将一条普通的 <code>DDL</code> 语句转化为分布式执行十分简单，只需要加上 <code>ON CLUSTER cluster_name</code> 声明即可。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE partition_v3 ON CLUSTER ch_cluster(</span><br><span class="line">    ID String,</span><br><span class="line">    Time Date</span><br><span class="line">) ENGINE = MergeTree()</span><br><span class="line">PARTITION BY toYYYYMM(Time)</span><br><span class="line">ORDRE BY ID</span><br></pre></td></tr></table></figure><h5 id="数据操作"><a href="#数据操作" class="headerlink" title="数据操作"></a>数据操作</h5><ol><li><p>写入<br><code>INSERT</code> 语句支持三种语法范式，三种范式各有不同，可以根据写入的需求灵活变化。</p><ul><li>使用 <code>VALUES</code> 格式的常规用法： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO [db.]tb_name [(c1, c2, c3)] VALUES (v11, v12, v13), (v21, v22, v23)</span><br></pre></td></tr></table></figure></li><li>使用指定格式语法： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO [db.]tb_name [(c1, c2, c3)] FORMAT format_name data_set</span><br></pre></td></tr></table></figure></li><li>使用 <code>SELECT</code> 子句形式语法： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO [db.]tb_name [(c1, c2, c3)] SELECT ...</span><br></pre></td></tr></table></figure></li></ul></li><li><p>修改和删除<br><code>ClickHouse</code> 提供 <code>DELETE</code> 和 <code>UPDATE</code> 的能力，这类操作被称为 <code>Mutation</code> 查询，可以看作是 <code>ALTER</code> 语句的变种，虽然能实现同样的功能，但是与通常意义上的 <code>DELETE</code> 和 <code>UPDATE</code> 不一样：</p><ul><li><code>Mutation</code> 语句其实是<strong>很重</strong>的操作，更适用于批量数据的修改和删除。</li><li>不支持事务，一旦语句被提交，就会立刻对数据产生影响且无法回滚。</li><li><code>Mutation</code> 语句的执行是一个异步的后台过程，语句提交之后会立即返回。但是立即返回并不代表具体逻辑已经执行完毕，具体执行进度需要通过 <code>system.mutations</code> 系统表查询。</li></ul></li></ol><p> <code>DELETE</code> 和 <code>UPDATE</code> 语句语法如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE [db_name.]tb_name DELETE WHERE filter_expr</span><br><span class="line">ALTER TABLE [db_name.]tb_name UPDATE column1 = expr1, ... WHERE filter_expr</span><br></pre></td></tr></table></figure><hr><h3 id="数据查询"><a href="#数据查询" class="headerlink" title="数据查询"></a>数据查询</h3><h4 id="WITH-子句"><a href="#WITH-子句" class="headerlink" title="WITH 子句"></a><code>WITH</code> 子句</h4><p><code>ClickHouse</code> 支持 <code>CTE</code> （<code>Common Table Expression</code>，公共表表达式）以增强查询语句的表达。</p><ol><li><p>定义变量<br>可以定义变量，这些变量能够在后续的查询子句中被直接访问。</p></li><li><p>调用函数<br>可以访问 <code>SELECT</code> 子句中的列字段，并调用函数做进一步的加工处理。</p></li><li><p>定义子查询<br>可以定义子查询。<br><small>在 <code>WITH</code> 中使用子查询时有一些需要特别注意，该查询语句只能返回同一行数据，如果结果集的数据大于一行则会抛出异常。</small></p></li><li><p>在子查询中重复使用 <code>WITH</code><br>在子查询中可以嵌套使用 <code>WITH</code> 子句。</p></li></ol><h4 id="FROM-子句"><a href="#FROM-子句" class="headerlink" title="FROM 子句"></a><code>FROM</code> 子句</h4><p><code>FROM</code> 子句表示从何处读取数据。</p><ol><li><p>从数据表中读取数据。</p></li><li><p>从子查询中取数。</p></li><li><p>从表函数中取数。</p></li></ol><p><small><code>FROM</code> 关键字可以省略，此时会从虚拟表中取数。在 <code>ClickHouse</code> 中，并没有数据库中常见的 <code>DUAL</code> 虚拟表，取而代之的就是 <code>system.one</code>。</small></p><h4 id="SAMPLE-子句"><a href="#SAMPLE-子句" class="headerlink" title="SAMPLE 子句"></a><code>SAMPLE</code> 子句</h4><p><code>SAMPLE</code> 子句能够实现数据采样的功能，使查询仅返回采样数据而不是全部数据，从而减少查询负载。<br><small><code>SAMPLE</code> 子句的采样设计是一种幂等设计，也就是说在数据不发生变化的情况下，使用相同的采样规则总是返回相同的数据。</small><br><small><code>SAMPLE</code> 子句只能用于 <code>MergeTree</code> 系列引擎的数据表，并且要求在 <code>CREATE TABLE</code> 时声明 <code>SAMPLE BY</code> 抽样表达式。</small></p><ol><li><p><code>SAMPLE factor</code><br><code>SAMPLE factor</code> 表示按因子系数采样，其中 <code>factor</code> 表示采样因子，它的取值支持 <code>0~1</code> 之间的小数。如果 <code>factor</code> 设置为 <code>0</code> 或者 <code>1</code>，则效果等同于不进行数据采样。</p></li><li><p><code>SAMPLE rows</code><br><code>SAMPLE rows</code> 表示按样本数量采样，其中 <code>rows</code> 表示至少采样多少行数据，它的取值必须是大于 <code>1</code> 的整数。如果 <code>rows</code> 的取值大于表内数据的总行数，则效果等于 <code>rows=1</code>（即不使用采样）。</p></li><li><p><code>SAMPLE factor OFFSET n</code><br><code>SAMPLE factor OFFSET n</code> 表示按因子系数和偏移量采样，其中 <code>factor</code> 表示采样因子，<code>n</code> 表示偏移多少数据后才开始采样，他们两个的取值都是 <code>0~1</code> 之间的小数。</p></li></ol><h4 id="ARRAY-JOIN-子句"><a href="#ARRAY-JOIN-子句" class="headerlink" title="ARRAY JOIN 子句"></a><code>ARRAY JOIN</code> 子句</h4><p><code>ARRAY JOIN</code> 子句允许在数据表内部，与数组或嵌套类型的字段进行 <code>JOIN</code> 操作，从而将一行数据展开为多行。<br><small>在一条 <code>SELECT</code> 语句中，只能存在一个 <code>ARRAY JOIN</code>（使用子查询除外）。目前仅支持 <code>INNER</code> 和 <code>LEFT</code> 两种策略。 </small></p><ol><li><p><code>INNER ARRAY JOIN</code><br><code>ARRAY JOIN</code> 在默认情况下使用的是 <code>INNER JOIN</code> 策略。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> title, <span class="keyword">value</span> <span class="keyword">FROM</span> query_v1 <span class="keyword">ARRAY</span> <span class="keyword">JOIN</span> <span class="keyword">value</span></span><br><span class="line"># food <span class="number">1</span></span><br><span class="line"># food <span class="number">2</span></span><br></pre></td></tr></table></figure></li><li><p><code>LEFT ARRAY JOIN</code><br><code>ARRAY JOIN</code> 子句支持 <code>LEFT</code> 连接策略。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> title, <span class="keyword">value</span>, v <span class="keyword">FROM</span> query_v1 <span class="keyword">LEFT</span> <span class="keyword">ARRAY</span> <span class="keyword">JOIN</span> <span class="keyword">value</span> <span class="keyword">AS</span> v</span><br><span class="line"># food [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>] <span class="number">1</span></span><br><span class="line"># food [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>] <span class="number">2</span></span><br></pre></td></tr></table></figure></li></ol><h4 id="JOIN-子句"><a href="#JOIN-子句" class="headerlink" title="JOIN 子句"></a><code>JOIN</code> 子句</h4><p><code>JOIN</code> 子句可以对左右两张表的数据进行连接，这是最常用的查询子句之一。它的语法包含连接精度和连接类型两部分。连接精度可以分为 <code>ALL</code>、 <code>ANY</code> 和 <code>ASOF</code> 三种，而连接类型也可以分为外连接（外集合）、内连接（交集）和交叉连接（并集）三种。<br><small>在进行多表连接时，会转化为两两连接的形式。</small></p><h5 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h5><ul><li>优化 <code>JOIN</code> 性能，首先应<strong>遵循左大右小的原则</strong>。</li><li><code>JOIN</code> 查询目前没有缓存的支持。</li><li>如果是在大量维度属性补全的查询场景中，建议使用字典代替 <code>JOIN</code> 查询。</li><li>连接查询的空值是由默认值填充的，连接查询的空值策略是通过 <code>join_use_nulls</code> 参数指定的，默认是 <code>0</code>。</li></ul><h4 id="WHERE-和-PREWHERE-子句"><a href="#WHERE-和-PREWHERE-子句" class="headerlink" title="WHERE 和 PREWHERE 子句"></a><code>WHERE</code> 和 <code>PREWHERE</code> 子句</h4><p><code>WHERE</code> 子句基于条件表达式来实现数据过滤。另外还提供了全新的 <code>PREWHERE</code> 子句，<code>PREWHERE</code> 目前只能作用于 <code>MergeTree</code> 系列的表引擎，可以看作是 <code>WHERE</code> 的一种优化，其作用与 <code>WHERE</code> 相同，均用来过滤数据，不过 <code>PREWHERE</code> 只会读取指定的列字段数据，用于数据过滤的条件判断，待数据过滤之后再补齐 <code>SELECT</code> 声明的列字段以补全其余属性。</p><h4 id="GROUP-BY-子句"><a href="#GROUP-BY-子句" class="headerlink" title="GROUP BY 子句"></a><code>GROUP BY</code> 子句</h4><p><code>GROUP BY</code> 又称聚合查询，在 <code>GROUP BY</code> 后声明的表达式，通常被称为聚合键或者 <code>Key</code>，数据会按照聚合键进行聚合。</p><ol><li><p><code>WITH ROLLUP</code><br><code>ROLLUP</code> 能够按照聚合键从右向左上卷数据，基于聚合函数依次生成分组小计和总计。</p></li><li><p><code>WITH CUBE</code><br><code>CUBE</code> 会像立方体模型一样，基于聚合键之间所有的组合生成小计信息。如果聚合键的个数为 <code>n</code>，则最终小计组合的个数为 <code>2^n</code>。</p></li><li><p><code>WITH TOTALS</code><br>使用 <code>TOTALS</code> 修饰符后，会基于聚合函数对所有数据进行总计。</p></li></ol><h4 id="HAVING-子句"><a href="#HAVING-子句" class="headerlink" title="HAVING 子句"></a><code>HAVING</code> 子句</h4><p><code>HAVING</code> 子句需要与 <code>GROUP BY</code> 子句同时出现，不能单独使用。它能够在聚合计算之后实现二次过滤数据。<br><small>执行优先级： <code>WHERE &gt; GROUP BY &gt; HAVING</code></small></p><h4 id="ORDER-BY-子句"><a href="#ORDER-BY-子句" class="headerlink" title="ORDER BY 子句"></a><code>ORDER BY</code> 子句</h4><p><code>ORDER BY</code> 子句通过声明排序键来指定查询数据返回时的顺序。可以使用多个排序键，每个排序键后需紧跟 <code>ASC</code> 或者 <code>DESC</code>来确定排列顺序，默认 <code>ASC</code>。<br><small>对于 <code>NULL</code> 值的排序，目前拥有 <code>NULLS LAST</code> 和 <code>NULLS FIRST</code> 两种排序方式，含义跟其修饰符有关。另外就是 <code>NaN</code>，总是紧跟在 <code>NULL</code> 身边。</small></p><h4 id="LIMIT-BY-子句"><a href="#LIMIT-BY-子句" class="headerlink" title="LIMIT BY 子句"></a><code>LIMIT BY</code> 子句</h4><p><code>LIMIT BY</code> 子句和常见的 <code>LIMIT</code> 所有不同，它运行于 <code>ORDER BY</code> 之后和 <code>LIMIT</code> 之前，能够按照指定分组，最多返回前 <code>n</code> 行数据（如果数据少于 <code>n</code> 行，则按照实际数量返回），常用于 <code>TOP N</code> 的查询场景。另外也支持跳过 <code>OFFSET</code> 偏移量获取数据。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LIMIT n <span class="keyword">BY</span> express</span><br></pre></td></tr></table></figure><h4 id="LIMIT-子句"><a href="#LIMIT-子句" class="headerlink" title="LIMIT 子句"></a><code>LIMIT</code> 子句</h4><p><code>LIMIT</code> 子句用于返回指定的前 <code>n</code> 行数据，常用于分页场景。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LIMIT n</span><br><span class="line">LIMIT n <span class="keyword">OFFSET</span> m</span><br><span class="line">LIMIT m, n</span><br></pre></td></tr></table></figure><h4 id="SELECT-子句"><a href="#SELECT-子句" class="headerlink" title="SELECT 子句"></a><code>SELECT</code> 子句</h4><p><code>SELECT</code> 子句决定了一次查询语句最终返回哪些字段或者表达式。</p><h4 id="DISTINCT-子句"><a href="#DISTINCT-子句" class="headerlink" title="DISTINCT 子句"></a><code>DISTINCT</code> 子句</h4><p><code>DISTINCT</code> 子句能够去除重复数据，使用场景广泛。</p><h4 id="UNION-ALL-子句"><a href="#UNION-ALL-子句" class="headerlink" title="UNION ALL 子句"></a><code>UNION ALL</code> 子句</h4><p><code>UNIUN ALL</code> 子句能够联合左右两边的两组子查询，将结果一并返回。在一次查询中可以声明多个 <code>UNION ALL</code> 以便联合多组查询，但 <code>UNION ALL</code> 不能直接使用其他子句，这些子句只能在其联合的子查询中使用。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a1, b1 <span class="keyword">from</span> tabl1</span><br><span class="line"><span class="keyword">UNION</span> <span class="keyword">ALL</span></span><br><span class="line"><span class="keyword">select</span> a2, b2 <span class="keyword">from</span> table2</span><br></pre></td></tr></table></figure><p><small>上述查询中，<code>UNION ALL</code> 两侧的子查询中能够得到节点信息，首先两侧列字段数量必须相同，其次列字段的数据类型必须相同或兼容，最后列字段的名字可以不同但会以左侧的子查询为准。</small></p><h4 id="SQL-执行计划"><a href="#SQL-执行计划" class="headerlink" title="SQL 执行计划"></a><code>SQL</code> 执行计划</h4><p><code>ClickHouse</code> 目前并没有直接提供 <code>EXPLAIN</code> 查询，但是借助后台的服务日志，能变相实现该功能。</p><ul><li>通过将 <code>ClickHouse</code> 服务日志设置到 <code>DEBUG</code> 或者 <code>TRACE</code> 日志级别，可以变相实现 <code>EXPLAIN</code> 查询，以分析 <code>SQL</code> 的执行日志。</li><li>需要真正执行 <code>SQL</code> 查询，<code>CH</code> 才能打印计划日志，所以如果表的数据量很大，最好借助 <code>LIMIT</code> 子句以减少查询返回的数据量。</li><li>在日志中，分区过滤信息部分 <code>Selected xxx parts by date,</code>，其中 <code>by date</code> 部分是固定的，无论我们的分区键是什么字段，这里都不会变。这是由于在早期版本中，<code>MergeTree</code> 分区键只支持日期字段。</li><li>不要使用 <code>select *</code> 全字段查询。</li><li>尽可能利用各种索引（分区索引、一级索引、二级索引），这样可以避免全表扫描。</li></ul><hr><h3 id="实用工具"><a href="#实用工具" class="headerlink" title="实用工具"></a>实用工具</h3><h4 id="clickhouse-local"><a href="#clickhouse-local" class="headerlink" title="clickhouse-local"></a><code>clickhouse-local</code></h4><p><code>clickhouse-local</code> 可以独立运行大部分 <code>SQL</code> 查询，不需要依靠任何 <code>ClickHouse</code> 的服务端程序，可以理解成是 <code>ClickHouse</code> 服务的单机版微内核，是一个轻量级的应用程序。<br><code>clickhouse-local</code> 只能够使用 <code>File</code> 表引擎，他的数据与同机运行的 <code>ClickHouse</code> 服务也是完全隔离的，相互之间并不能访问。同时是非交互式运行的，每次执行都需要指定数据来源。</p><p>核心参数如下：</p><ul><li><code>-S/--structure</code>：表结构的简写方式。</li><li><code>-N/--table</code>：表名称，默认值是 <code>table</code>。</li><li><code>-if/--input-format</code>：输入数据的格式，默认值是 <code>TSV</code>。</li><li><code>-f/--file</code>：输入数据的地址，默认值是 <code>stdin</code> 标准输入。</li><li><code>-q/--query</code>：待执行的 <code>SQL</code> 语句，多条语句之间以分号间隔。</li></ul><h4 id="clickhouse-benchmark"><a href="#clickhouse-benchmark" class="headerlink" title="clickhouse-benchmark"></a><code>clickhouse-benchmark</code></h4><p><code>clickhouse-benchmark</code> 是基准测试的小工具，可以自动运行 <code>SQL</code> 查询，并生成相应的运行指标报告。</p><p>核心参数如下：</p><ul><li><code>-i/--iterations</code>：<code>SQL</code> 查询执行的次数，默认值为 <code>0</code>。</li><li><code>-c/--concurrency</code>：同时执行查询的并发数，默认值是 <code>1</code>。</li><li><code>-r/--randomize</code>：在执行多条 <code>SQL</code> 语句的时候，按照随机顺序执行。</li><li><code>-h/--host</code>：服务端地址，默认值是 <code>localhost</code>。</li><li><code>--confidence</code>：设置对比测试中置信区间的范围，默认值是 <code>5(99.5%)</code>。取值范围有 <code>0(80%), 1(90%), 2(95%), 3(98%), 4(99%)</code> 和 <code>5(99.5%)</code>。</li></ul><h4 id="clickhouse-mysql"><a href="#clickhouse-mysql" class="headerlink" title="clickhouse-mysql"></a><code>clickhouse-mysql</code></h4><p><code>clickhouse-mysql</code> 用于将 <code>MySQL</code> 的数据或者 <code>CSV</code> 文件同步到 <code>ClickHouse</code>的工具。</p><p><small>其他信息参考另一篇博客，有更详细的说明</small></p><hr><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><hr><h3 id="个人备注"><a href="#个人备注" class="headerlink" title="个人备注"></a>个人备注</h3><p><strong>此博客内容均为作者学习所做笔记，侵删！</strong><br><strong>若转作其他用途，请注明来源！</strong></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;大家都说 &lt;code&gt;MySQL&lt;/code&gt; 和 &lt;code&gt;ClickHouse&lt;/code&gt; 很像，如果你不了解 &lt;code&gt;ClickHouse&lt;/code&gt;，那我觉得你是对的，但若是你了解，那你更需要往下看看。&lt;/p&gt;</summary>
    
    
    
    
    <category term="ClickHouse" scheme="https://blog.vgbhfive.cn/tags/ClickHouse/"/>
    
  </entry>
  
  <entry>
    <title>ClickHouse-概述</title>
    <link href="https://blog.vgbhfive.cn/ClickHouse-%E6%A6%82%E8%BF%B0/"/>
    <id>https://blog.vgbhfive.cn/ClickHouse-%E6%A6%82%E8%BF%B0/</id>
    <published>2022-06-25T11:16:55.000Z</published>
    <updated>2022-07-05T15:12:59.314Z</updated>
    
    <content type="html"><![CDATA[<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p><code>ClickHouse</code> 是一款 <code>MPP</code> 架构的列式存储数据库，拥有完备的管理功能，所以他称得上是一个 <code>DBMS</code> 数据库管理系统，而不仅仅是一个数据库。</p><p>如果你想学习的话，那就一起来吧。</p><span id="more"></span><h4 id="完备的-DBMS-功能"><a href="#完备的-DBMS-功能" class="headerlink" title="完备的 DBMS 功能"></a>完备的 <code>DBMS</code> 功能</h4><p>作为 <code>DBMS</code> 具备以下基本功能：</p><ul><li><code>DDL</code>（数据定义语言）：可以动态地创建、修改和删除数据库、表和视图，而无需重启服务。</li><li><code>DML</code>（数据操作语言）：可以动态查询、插入、修改和删除数据。</li><li>权限控制：可以按照用户粒度设置数据库或者表的操作权限，保障数据的安全性。</li><li>数据备份与恢复：提供了数据备份导出与导入机制，满足生产环境的需求。</li><li>分布式管理：提供集群模式，能够自动管理多个数据库节点。</li></ul><h4 id="列式存储与数据压缩"><a href="#列式存储与数据压缩" class="headerlink" title="列式存储与数据压缩"></a>列式存储与数据压缩</h4><p>列式存储和数据压缩对于一款高性能数据库来说是必不可少的特性。<br>按列存储相比按行存储的另一个优势就是对数据压缩的友好性。并且由于压缩的本质是按照一定步长对数据进行匹配扫描，当发现重复部分的时候就进行编码转换。而在同一列的数据中，他们会拥有相同的数据类型和现实语义，重复项的可能性自然更高。</p><h4 id="向量化执行引擎"><a href="#向量化执行引擎" class="headerlink" title="向量化执行引擎"></a>向量化执行引擎</h4><p>能用钱解决的问题，千万别花时间。这句话是虽然是一句玩笑话，但是在实际中硬件层面的优化是最直接、最高效的提升性能途径之一。当然向量化执行就是这种方式的代表，寄存器硬件层面的特性，为上层应用程序的性能带来了指数级的提升。<br>为了实现向量化执行，需要利用 <code>CPU</code> 的 <code>SIMD</code> 命令。<code>SIMD</code> 的全称是 <code>Single Instruction Multiple Data</code>，即用单条指令操作多条数据。在现代计算机概念中，通过数据并行以提高性能的一种实现方式，原理即在 <code>CPU</code> 寄存器层面实现数据的并行操作。<br><small><code>ClickHouse</code> 目前利用 <code>SSE4.2</code> 指令集实现向量化执行。</small></p><h4 id="关系模型和-SQL-查询"><a href="#关系模型和-SQL-查询" class="headerlink" title="关系模型和 SQL 查询"></a>关系模型和 <code>SQL</code> 查询</h4><p><code>ClickHouse</code> 完全使用 <code>SQL</code> 作为查询语言（支持 <code>GROUP BY, ORDER BY, JOIN, IN</code> 等大部分标准 <code>SQL</code>），这会使得它平易近人、容易理解和学习。<br>在 <code>SQL</code> 解析方面 <code>ClickHouse</code> 是大小写敏感的，这意味着 <code>SELECT a</code> 和 <code>SELECT A</code> 所代表的语义是不同的。<br><code>ClickHouse</code> 使用了关系模型，所以将构建在传统关系型数据库或者数据仓库上的系统迁移到 <code>ClickHouse</code> 的成本会降低很多，可以直接沿用之前的成果。</p><h4 id="多样化的表引擎"><a href="#多样化的表引擎" class="headerlink" title="多样化的表引擎"></a>多样化的表引擎</h4><p><code>ClickHouse</code> 共拥有合并树、内存、文件、接口和其他六大类二十多种表引擎，其中每一种表引擎都有各自的特点，用户可以根据世界业务场景的需求选择合适的表引擎使用。<br>将表引擎单独设计的好处是显而易见的，通过特定的表引擎支撑特定的场景，十分灵活，对于简单的场景，可直接使用简单的引擎降低成本，而复杂的场景也有合适的引擎。</p><h4 id="多线程与分布式"><a href="#多线程与分布式" class="headerlink" title="多线程与分布式"></a>多线程与分布式</h4><p>前面提到的向量化执行通过数据并行的方式提高性能，那么多线程处理就是通过线程级并行方式实现了性能的提升。</p><h4 id="多主结构"><a href="#多主结构" class="headerlink" title="多主结构"></a>多主结构</h4><p><code>ClickHouse</code> 采用了 <code>Multi-Master</code> 多主架构，集群中的每个节点角色对等，客户端访问任意一个节点都能得到相同的效果，这种多主的结构有许多优势，例如对等的角色使系统架构变得更加简单，不用再区分主控节点、数据节点和计算节点，集群中的所有节点功能相同。所以他天然规避了单点故障问题，非常适合多数据中心、异地多活的场景。</p><h4 id="在线查询"><a href="#在线查询" class="headerlink" title="在线查询"></a>在线查询</h4><p><code>ClickHouse</code> 完美平衡成本和性能，采用了 <code>LSM</code> 树结构，使得数据的插入量可以很大。同时由于 <code>ClickHouse</code> 的内部优化，使得在复杂查询的场景下能够做到极快响应，且无须对数据进行任何预处理加工，即真 <strong>在线</strong>。</p><h4 id="数据分片与分布式查询"><a href="#数据分片与分布式查询" class="headerlink" title="数据分片与分布式查询"></a>数据分片与分布式查询</h4><p><code>ClickHouse</code> 支持分片，而分片依赖集群，每个集群有一个到多个分片组成，而每个分片则对应了 <code>ClickHouse</code> 的一个服务节点，分片的数量上限取决于节点数量（一个分片对应一个服务节点）。<br><code>ClickHouse</code> 提供了本地表（<code>Local Table</code>）和分布式表（<code>Distributed Table</code>）的概念。一张本地表等同于一份数据的分片，而分布式表本身不存储任何数据，仅仅只是本地表的访问代理，其作用类似于分库中间件，借助分布式表，能够代理访问多个数据分片，从而实现分布式查询。<br>所以在使用单个节点的本地表（单个数据分片）即可满足业务需求的基础上，待业务增长后，再通过新增数据分片的方式分流数据，并通过分布式表实现分布式查询。</p><h4 id="不足之处"><a href="#不足之处" class="headerlink" title="不足之处"></a>不足之处</h4><p>上面说有这么多的优点，那么当然也是会有缺点的，毕竟<strong>人无完人，物无完物</strong>。</p><ul><li>不支持事务。</li><li>不擅长根据主键按行粒度进行查询（虽然支持）。</li><li>不擅长按行删除数据（虽然支持）。</li></ul><hr><h3 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h3><p><img src="https://s2.loli.net/2022/07/04/aPi25eOBNIsxcKq.png" alt="click-1-1.jpg"></p><h4 id="Column-和-Field"><a href="#Column-和-Field" class="headerlink" title="Column 和 Field"></a><code>Column</code> 和 <code>Field</code></h4><p><code>Column</code> 和 <code>Field</code> 是 <code>ClickHouse</code> 数据最基础的映射单元，作为一款百分之百的按列存储数据，内存中的一列数据库由一个 <code>Column</code> 对象表示。<code>Column</code> 对象分为接口和实现两个部分，在 <code>ICloumn</code> 接口对对象中，定义了对数据进行各种关系运算的方法。<br>在大多数场合下，<code>ClickHouse</code> 都会以整列的方式操作数据，但凡也有例外，如果需要操作单个具体的数值（也就是单列中的一行数据），则需要使用 <code>Field</code> 对象，<code>Field</code> 对象代表一个单值，与 <code>Column</code> 对象的泛化设计思路不同，<code>Field</code> 对象使用了聚合的设计模式，在 <code>Field</code> 对象内部聚合了 <code>Null</code>、<code>UInt64</code>、<code>String</code>等十三种数据结构类型及对应的处理逻辑。</p><h4 id="DataType"><a href="#DataType" class="headerlink" title="DataType"></a><code>DataType</code></h4><p>数据的序列化和反序列化工作由 <code>DataType</code> 负责。<code>IDataType</code> 接口定义了许多正反序列的方法，他们成对出现，例如 <code>serializeBinary</code> 和 <code>deserializeBinary</code> 等，覆盖常见的二进制、文本、<code>JSON</code>、<code>XML</code> 等多种格式类型。<br><code>DataType</code> 虽然负责序列化相关工作，但它并不直接负责数据的读取，而实际转由从 <code>Column</code> 或 <code>Field</code> 对象中获取数据。在 <code>DataType</code> 的实现类中，聚合了相应数据类型的 <code>Column</code> 对象和 <code>Field</code> 对象。</p><h4 id="Block-和-Block-流"><a href="#Block-和-Block-流" class="headerlink" title="Block 和 Block 流"></a><code>Block</code> 和 <code>Block</code> 流</h4><p><code>ClickHouse</code> 内部的数据操作是面向 <code>Block</code> 对象进行的，并且采用了流的形式。虽然 <code>Column</code> 和 <code>Field</code> 组成了数据的基本映射单元，但对应到实际的操作中，他们还是缺少了一些必要的信息，比如数据类型和列名称。<br><code>Block</code> 对象可以看作数据表的<strong>子集</strong>，<code>Block</code> 对象的本质是由数据对象、数据类型和列名称组成的三元组，即 <code>Column</code>、 <code>DataType</code> 和列名称字符串。其中 <code>Column</code> 提供数据的读取能力，而 <code>DataType</code> 知道如何正反序列化，所以 <code>Block</code> 在这些对象的基础上进行进一步的抽象和封装，从而简化并完成一系列的数据操作。</p><p><small>在具体的实际中，<code>Block</code> 并没有直接聚合 <code>Column</code> 和 <code>DataType</code> 对象，而是通过 <code>ColumnWithTypeAndName</code> 对象进行间接引用。</small></p><p>在有了 <code>Block</code> 对象这一层封装之后，在 <code>Block</code> 流的设计就是水到渠成的事情，流操作有两个顶层的接口，其中 <code>IBlockInputStream</code> 负责数据的读取和关系运算，<code>IBlockOutputStream</code> 负责将数据输出到下一环节。同样的 <code>Block</code> 也使用了泛化的设计，对数据的各种操作最终都会转化为之类其中一种流的实现，<code>IBlockInputStream</code> 接口定义读取数据的若干个 <code>read</code> 虚方法都会由具体的实现类来填充。当然 <code>IBlockOutputStream</code> 与之类似同样定义了若干个 <code>write</code> 虚方法，均由实现类来填充具体逻辑。</p><p><code>IBlockInputStream</code> 接口共有六十多个实现类，大致可以分为三类：</p><ul><li>处理数据定义的 <code>DDL</code> 操作。</li><li>处理关系运算的相关操作。</li><li>与表引擎相呼应，每一种表引擎都有与之对应的 <code>BlockInputStream</code> 实现。</li></ul><h4 id="Table"><a href="#Table" class="headerlink" title="Table"></a><code>Table</code></h4><p>在数据表的底层设计中并没有所谓的 <code>Table</code> 对象，直接使用 <code>IStorage</code> 接口指代数据表。其中 <code>IStorage</code> 接口定义了 <code>DDL</code>、<code>read</code>、<code>write</code> 方法，这些方法分别负责数据的定义、查询与写入。在数据查询时 <code>IStorage</code> 负责根据 <code>AST</code> 查询语句的指示要求，返回数据列的原始数据。后续对数据的进一步加工、计算和过滤，则会统一交由 <code>Interpreter</code> 解释器对象处理。<br>对 <code>Table</code> 发起的一次操作通常都会经历如此的过程，接收 <code>AST</code> 查询语句，根据 <code>AST</code> 返回指定列的数据，之后再将数据交由 <code>Interpreter</code> 做进一步处理。</p><h4 id="Parser-和-Interpreter"><a href="#Parser-和-Interpreter" class="headerlink" title="Parser 和 Interpreter"></a><code>Parser</code> 和 <code>Interpreter</code></h4><p><code>Parser</code> 和 <code>Interpreter</code> 是非常重要的两组接口，<code>Parser</code> 分析器负责创建 <code>AST</code> 对象，而 <code>Interpreter</code> 解释器则负责解释 <code>AST</code>，并进一步创建查询的执行管道。他们与 <code>IStorage</code> 一起，串联起整个查询的过程。<br><code>Parser</code> 分析器可以将一条 <code>SQL</code> 语句以递归下降的方法分解成 <code>AST</code> 语法树的形式，不同的 <code>SQL</code> 会经由不同的 <code>Parser</code> 实现类解析。<br><code>Interpreter</code> 解释器的作用就像 <code>service</code> 服务层一样，起到串联整个查询过程的作用，他会根据解释器的类型，聚合它所需要的资源。首先他会解析 <code>AST</code> 对象，然后执行 <strong>业务逻辑</strong>（如分支判断、设置参数、调用接口等），最终返回 <code>IBlock</code> 对象，以线程的形式建立起一个查询执行管道。</p><h4 id="Functions-和-Aggregate-Functions"><a href="#Functions-和-Aggregate-Functions" class="headerlink" title="Functions 和 Aggregate Functions"></a><code>Functions</code> 和 <code>Aggregate Functions</code></h4><p><code>ClickHouse</code> 主要提供了两类函数，普通函数和聚合函数。<br>其中普通函数由 <code>IFunction</code> 接口定义，拥有数十种函数实现，另外普通函数是没有状态的，函数效果作用于每行数据之上，当然在数据具体执行的过程中，并不会一行一行地运算，而是采用向量化的方式直接作用与一整列数据。<br>聚合函数由 <code>IAggregateFunction</code> 接口定义，相比无状态的普通函数，聚合函数是由状态的，另外聚合函数的状态支持序列化和反序列化，能够在分布式节点之间进行传输，以实现增量计算。</p><h4 id="Cluster-和-Replication"><a href="#Cluster-和-Replication" class="headerlink" title="Cluster 和 Replication"></a><code>Cluster</code> 和 <code>Replication</code></h4><p><code>ClickHouse</code> 的集群由分片（<code>Shard</code>）组成，而每个分片又通过副本（<code>Replica</code>）组成，这种分层的概念，在一些流行的分布式系统中十分普遍。<br>在 <code>ClickHouse</code> 中有几个与众不同的特性：</p><ul><li><code>ClickHouse</code> 的一个节点只能有一个一个分片，也就是说若要实现一分片、一副本，则至少需要部署两个服务节点。</li><li>分片只是一个逻辑概念，其物理承载还是由副本承担的。</li></ul><hr><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><p><a href="https://clickhouse.com/docs/zh/development/architecture">ClickHouse 架构概述</a></p><hr><h3 id="个人备注"><a href="#个人备注" class="headerlink" title="个人备注"></a>个人备注</h3><p><strong>此博客内容均为作者学习所做笔记，侵删！</strong><br><strong>若转作其他用途，请注明来源！</strong></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h3&gt;&lt;p&gt;&lt;code&gt;ClickHouse&lt;/code&gt; 是一款 &lt;code&gt;MPP&lt;/code&gt; 架构的列式存储数据库，拥有完备的管理功能，所以他称得上是一个 &lt;code&gt;DBMS&lt;/code&gt; 数据库管理系统，而不仅仅是一个数据库。&lt;/p&gt;
&lt;p&gt;如果你想学习的话，那就一起来吧。&lt;/p&gt;</summary>
    
    
    
    
    <category term="ClickHouse" scheme="https://blog.vgbhfive.cn/tags/ClickHouse/"/>
    
  </entry>
  
  <entry>
    <title>Import and replicate data from MySQL to Clickhouse</title>
    <link href="https://blog.vgbhfive.cn/Import-and-replicate-data-from-MySQL-to-Clickhouse/"/>
    <id>https://blog.vgbhfive.cn/Import-and-replicate-data-from-MySQL-to-Clickhouse/</id>
    <published>2022-06-12T04:22:05.000Z</published>
    <updated>2022-11-03T15:56:17.935Z</updated>
    
    <content type="html"><![CDATA[<h3 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h3><p>本次将数据从 <code>MySQL</code> 备份到 <code>ClickHouse</code> 采用的是 <a href="https://github.com/MinervaDB/MinervaDB-ClickHouse-MySQL-Data-Reader">MinervaDB ClickHouse MySQL Data Reader</a> ，该项目基础版本来自于 <code>Alitinity/clickhouse-mysql-data-reader</code>。</p><span id="more"></span><hr><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip3 install mysqlclient</span><br><span class="line">pip3 install mysql-replication</span><br><span class="line">pip3 install clickhouse-driver</span><br></pre></td></tr></table></figure><p><small>这里必须使用 pip3，并且最少需要 Python 3.4 版本。</small></p><p>下面我们直接拉取主版本分支，保证使用的是最新版本。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/Altinity/clickhouse-mysql-data-reader</span><br><span class="line">pip3 install -e clickhouse-mysql-data-reader/</span><br></pre></td></tr></table></figure><hr><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>使用 <code>root</code> 用户登录 <code>MySQL</code> 创建 <code>clickhouse-mysql-data-reader</code> 访问数据所需要的用户和权限。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; CREATE USER &#x27;clickhousereader&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;MDB@2019&#x27;;</span><br><span class="line">Query OK, 0 rows affected (0.02 sec)</span><br><span class="line">mysql&gt; CREATE USER &#x27;clickhousereader&#x27;@&#x27;127.0.0.1&#x27; IDENTIFIED BY &#x27;MDB@2019&#x27;;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line">mysql&gt; CREATE USER &#x27;clickhousereader&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;MDB@2019&#x27;;</span><br><span class="line">Query OK, 0 rows affected (0.02 sec)</span><br><span class="line">mysql&gt; GRANT SELECT, REPLICATION CLIENT, REPLICATION SLAVE ON *.* TO &#x27;clickhousereader&#x27;@&#x27;%&#x27;;</span><br><span class="line">Query OK, 0 rows affected (0.01 sec)</span><br><span class="line">mysql&gt; GRANT SELECT, REPLICATION CLIENT, REPLICATION SLAVE ON *.* TO &#x27;clickhousereader&#x27;@&#x27;127.0.0.1&#x27;;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line">mysql&gt; GRANT SELECT, REPLICATION CLIENT, REPLICATION SLAVE ON *.* TO &#x27;clickhousereader&#x27;@&#x27;localhost&#x27;;</span><br><span class="line">Query OK, 0 rows affected, 1 warning (0.01 sec)</span><br></pre></td></tr></table></figure><p><code>my.cnf</code>（前提需要开启 <code>bin log</code>）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line"># mandatory</span><br><span class="line">server-id = 200</span><br><span class="line">log_bin = /var/lib/mysql/bin.log</span><br><span class="line">binlog-format = row # very important if you want to receive write, update and delete row</span><br><span class="line">events</span><br><span class="line"># optional</span><br><span class="line">expire_logs_days = 30</span><br><span class="line">max_binlog_size = 900M</span><br><span class="line"># setup listen address</span><br><span class="line">bind-address = 0.0.0.0</span><br></pre></td></tr></table></figure><p>在完成上面的配置之后，我们就可以将数据导入到 <code>ClickHouse</code> 中。<br><small>这里建议使用从库导入数据，另外不建议再修改表结构避免数据损坏。</small></p><hr><h3 id="优点和限制"><a href="#优点和限制" class="headerlink" title="优点和限制"></a>优点和限制</h3><ul><li>仅支持 <code>Insert</code> 事务。</li><li>不支持 <code>Delete</code> 和 <code>Update</code>。</li><li>不支持 <code>DDL</code>，<code>MySQL</code> 源端任何不兼容的修改都会破坏同步数据的流畅。</li></ul><hr><h3 id="运行同步"><a href="#运行同步" class="headerlink" title="运行同步"></a>运行同步</h3><p>在完成上面的内容之后，下面就可以将历史数据导入到 <code>ClickHouse</code> 中。下面就是运行导入的脚本：</p><p><small>建议在确定表结构的实例上进行导入，以避免可能发生数据损坏。另外建议使用 MySQL 从机作为数据源。</small></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clickhouse-mysql --src-server-id=200 --src-wait --nice-pause=1 --src-host=192.168.56.101 --src-user=clickhousereader --src-password=MDB@2019 --src-tables=wiki.pageviews --dst-host=127.0.0.1 --dst-create-table --migrate-table</span><br></pre></td></tr></table></figure><p>上面的脚本连接主机 <code>192.168.56.101</code> 上的 <code>MySQL</code>，他会迁移 <code>wiki</code> 库的 <code>pageviews</code> 表中的数据到主机 <code>127.0.0.1</code> 上的 <code>ClickHouse</code> 中，并且会自动建表和迁移数据。</p><p>剩下的就是验证同步数据前后的数量是否一致即可。</p><hr><h3 id="监听-bin-log-同步实时数据"><a href="#监听-bin-log-同步实时数据" class="headerlink" title="监听 bin log 同步实时数据"></a>监听 <code>bin log</code> 同步实时数据</h3><p>另外还可以在 <code>bin log</code> 日志文件中指定<code>clickhouse-mysql</code> 工具开始同步的位置同步数据。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clickhouse-mysql --src-server-id=200 --src-resume --src-binlog-file=<span class="string">&#x27;binlog.000713&#x27;</span> --src-binlog-position=638 --src-wait --nice-pause=1 --src-host=192.168.56.101 --src-user=clickhousereader --src-password=MDB@2019 --src-tables=wiki.pageviews --dst-host=127.0.0.1 --pump-data --csvpool</span><br></pre></td></tr></table></figure><hr><h3 id="常见异常"><a href="#常见异常" class="headerlink" title="常见异常"></a>常见异常</h3><ol><li><p>密码配置错误</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CRITICAL:Code: 516.</span><br><span class="line">DB::Exception: default: Authentication failed: password is incorrect or there is no user with such name.</span><br></pre></td></tr></table></figure><p>解决方法：<br>修改为正确的密码即可。</p></li><li><p>缺少 Python 文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MySQLdb/_mysql.c:46:20: fatal error: Python.h: No such file or directory</span><br><span class="line">#include &quot;Python.h&quot;</span><br></pre></td></tr></table></figure><p>解决方法：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install python3-devel</span><br></pre></td></tr></table></figure></li><li><p><code>gcc</code> 命令失败</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">compilation terminated.</span><br><span class="line">error: command &#x27;gcc&#x27; failed with exit status 1</span><br></pre></td></tr></table></figure><p>解决方法：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install gcc</span><br></pre></td></tr></table></figure></li><li><p><code>MySQL</code> 配置文件缺失</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">OSError: mysql_config not found</span><br></pre></td></tr></table></figure><p>解决方法：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install mysql-devel</span><br></pre></td></tr></table></figure><p>在安装过程中可能会出现密钥失效的情况，可以更新密钥：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm --import https://repo.mysql.com/RPM-GPG-KEY-mysql-2022</span><br></pre></td></tr></table></figure></li><li><p>未找到 <code>pip3</code> 命令</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install pyhton3-pip</span><br></pre></td></tr></table></figure></li></ol><hr><h3 id="参数解析"><a href="#参数解析" class="headerlink" title="参数解析"></a>参数解析</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br></pre></td><td class="code"><pre><span class="line">-h, --help              show this help message and exit</span><br><span class="line">查看帮助文档</span><br><span class="line"></span><br><span class="line">--config-file CONFIG_FILE</span><br><span class="line">                        Path to config file. Default - not specified</span><br><span class="line">配置文件路径。</span><br><span class="line"></span><br><span class="line">--log-file LOG_FILE     Path to log file. Default - not specified</span><br><span class="line">日志文件路径。</span><br><span class="line"></span><br><span class="line">--log-level LOG_LEVEL   Log Level. Default - NOTSET</span><br><span class="line">日志级别。</span><br><span class="line"></span><br><span class="line">--nice-pause NICE_PAUSE</span><br><span class="line">                        Make specified (in sec) pause between attempts to read binlog stream</span><br><span class="line">读取前后两次 binlog 之间暂停的时间（以秒为单位）。</span><br><span class="line"></span><br><span class="line">--dry                   Dry mode - do not do anything that can harm. Useful</span><br><span class="line">                        for debugging.</span><br><span class="line">空跑模式，不做任何有害的事情，用于调试。</span><br><span class="line"></span><br><span class="line">--daemon                Daemon mode - go to background.</span><br><span class="line">守护模式，转向后台运行。</span><br><span class="line"></span><br><span class="line">--pid-file PID_FILE     Pid file to be used by the app in daemon mode</span><br><span class="line">应用程序在守护模式下使用的 PID 文件。</span><br><span class="line"></span><br><span class="line">--binlog-position-file BINLOG_POSITION_FILE</span><br><span class="line">                        File to write binlog position to during bin log</span><br><span class="line">                        reading and to read position from on start</span><br><span class="line">在读取 binlog 文件期间要将 binlog 写入文件的位置和从开始读取位置的文件。</span><br><span class="line"></span><br><span class="line">--mempool               Cache data in mem.</span><br><span class="line">缓存内存中的数据</span><br><span class="line"></span><br><span class="line">--mempool-max-events-num MEMPOOL_MAX_EVENTS_NUM</span><br><span class="line">                        Max events number to pool - triggering pool flush</span><br><span class="line">缓存池中的最大事件数，会触发缓存池的刷新。</span><br><span class="line"></span><br><span class="line">--mempool-max-rows-num MEMPOOL_MAX_ROWS_NUM</span><br><span class="line">                        Max rows number to pool - triggering pool flush</span><br><span class="line">缓存池中的最大行数，会触发缓存池的刷新。</span><br><span class="line"></span><br><span class="line">--mempool-max-flush-interval MEMPOOL_MAX_FLUSH_INTERVAL</span><br><span class="line">                        Max seconds number between pool flushes</span><br><span class="line">缓存池之间刷新的最大秒数。</span><br><span class="line"></span><br><span class="line">--csvpool               Cache data in CSV pool files on disk. Requires memory</span><br><span class="line">                        pooling, thus enables --mempool even if it is not explicitly specified</span><br><span class="line">将 CSV 池的数据缓存在磁盘中。过程中需要使用内存池，即使没有明确指定也要启用 --mempool。</span><br><span class="line"></span><br><span class="line">--csvpool-file-path-prefix CSVPOOL_FILE_PATH_PREFIX</span><br><span class="line">                        File path prefix to CSV pool files</span><br><span class="line">CSV 池文件前缀路径。</span><br><span class="line"></span><br><span class="line">--csvpool-keep-files    Keep CSV pool files. Useful for debugging</span><br><span class="line">保留 CSV 池文件，用于调试。</span><br><span class="line"></span><br><span class="line">--create-table-sql-template</span><br><span class="line">                        Prepare CREATE TABLE SQL template(s).</span><br><span class="line">准备 CREATE TABLE SQL 模版。</span><br><span class="line"></span><br><span class="line">--create-table-sql      Prepare CREATE TABLE SQL statement(s).</span><br><span class="line">准备 CREATE TABLE SQL 语句。</span><br><span class="line"></span><br><span class="line">--with-create-database</span><br><span class="line">                        Prepend each CREATE TABLE SQL statement(s) with CREATEDATABASE statement</span><br><span class="line">在每一个 CREATE TABLE SQL 语句前添加 CREATE DATABASE 语句。</span><br><span class="line"></span><br><span class="line">--create-table-json-template</span><br><span class="line">                        Prepare CREATE TABLE template(s) as JSON. Useful for IPC</span><br><span class="line">准备 JSON 格式的 CREATE TABLE 模版，用于 IPC。</span><br><span class="line"></span><br><span class="line">--migrate-table         Migrate table(s). Copy existing data from MySQL</span><br><span class="line">                        table(s) with SELECT statement. Binlog is not read</span><br><span class="line">                        during this procedure - just copy data from the src</span><br><span class="line">                        table(s). IMPORTANT!. Target table has to be created</span><br><span class="line">                        in ClickHouse or it has to be created wit--dst-</span><br><span class="line">                        create-table and possibly wit--with-create-database</span><br><span class="line">                        options. Se--create-table-sql-template an--create-</span><br><span class="line">                        table-sql options for additional info.</span><br><span class="line">合并表。使用 SELECT 语句从 MySQL 表中复制数据。在此期间从 binlog 文件中读取数据，仅从源表中复制数据。目标表需要在 ClickHouse 中被创建 或者使用 --dst-create-table 参数创建表和使用过 --with-create-database 创建库。更多的信息可以参考 --create-table-sql-template 和 --create-table-sql。</span><br><span class="line"></span><br><span class="line">--pump-data             Pump data from MySQL binlog into ClickHouse. Copy rows</span><br><span class="line">                        from binlog until the end of binlog reached. When end</span><br><span class="line">                        of binlog reached, process ends. Use in combination</span><br><span class="line">                        wit--src-wait in case would like to continue and</span><br><span class="line">                        wait for new rows after end of binlog reached</span><br><span class="line">从 MYSQL 的 binlog 中抽取数据到 ClickHosue。从 binlog 中复制行，直到到达 binlog 的末尾。当到达 binlog 末尾时，运行停止。如果你想在到达 binlog 末尾时可以等待新的行到达然后重新运行，可以使用 --src-wait 参数。</span><br><span class="line"></span><br><span class="line">--install               Install service file(s)</span><br><span class="line">安装服务文件。</span><br><span class="line"></span><br><span class="line">--src-server-id SRC_SERVER_ID</span><br><span class="line">                        Set server_id to be used when reading date from MySQL</span><br><span class="line">                        src. Ex.: 1</span><br><span class="line">设置从 MySQL 源读取数据时要使用的 server_id。例如：1。</span><br><span class="line"></span><br><span class="line">--src-host SRC_HOST     Host to be used when reading from src. Ex.: 127.0.0.1</span><br><span class="line">从源读取数据需要使用的 Host。例如：127.0.0.1。</span><br><span class="line"></span><br><span class="line">--src-port SRC_PORT     Port to be used when reading from src. Ex.: 3306</span><br><span class="line">从源读取数据需要使用的 Port。例如：3306。</span><br><span class="line"></span><br><span class="line">--src-user SRC_USER     Username to be used when reading from src. Ex.: root</span><br><span class="line">从源读取数据需要使用的 Username。例如：root。</span><br><span class="line"></span><br><span class="line">--src-password SRC_PASSWORD</span><br><span class="line">                        Password to be used when reading from src. Ex.: qwerty</span><br><span class="line">从源读取数据需要使用的 Password。例如：qwerty。</span><br><span class="line"></span><br><span class="line">--src-schemas SRC_SCHEMAS</span><br><span class="line">                        Comma-separated list of databases (a.k.a schemas) to</span><br><span class="line">                        be used when reading from src. Ex.: db1,db2,db3</span><br><span class="line">从源读取数据需要使用的数据库列表（以逗号分隔），例如：db1,db2,db3。</span><br><span class="line"></span><br><span class="line">--src-tables SRC_TABLES</span><br><span class="line">                        Comma-separated list of tables to be used when reading</span><br><span class="line">                        from src. Ex.: table1,table2,table3Ex.:</span><br><span class="line">                        db1.table1,db2.table2,db3.table3</span><br><span class="line">从源读取数据需要使用的表（以逗号分隔），例如：table1,table2,table3，例如：db1.table1,db2.table2,db3.table3。</span><br><span class="line"></span><br><span class="line">--src-tables-where-clauses SRC_TABLES_WHERE_CLAUSES</span><br><span class="line">                        Comma-separated list of WHERE clauses for tables to be</span><br><span class="line">                        migrated. Ex.: db1.t1=&quot;a=1 and b=2&quot;,db2.t2=&quot;c=3 and</span><br><span class="line">                        k=4&quot;. Accepts both (comma-separated) clause (useful</span><br><span class="line">                        for short clauses) or file where clause is located</span><br><span class="line">                        (useful for long clauses)</span><br><span class="line">要迁移表的 WHERE 子句（以逗号分隔）。例如：db1.t1=&quot;a=1 and b=2&quot;,db2.t2=&quot;c=3 and k=4&quot;。</span><br><span class="line"></span><br><span class="line">--src-tables-prefixes SRC_TABLES_PREFIXES</span><br><span class="line">                        Comma-separated list of table prefixes to be used when</span><br><span class="line">                        reading from src.Useful when we need to process</span><br><span class="line">                        unknown-in-advance tables, say day-named log tables,</span><br><span class="line">                        as log_2017_12_27Ex.: mylog_,anotherlog_,extralog_3</span><br><span class="line">从源读取数据要使用的表前缀列表。在处理未知的预先表时非常有用，例如 log_2017_12_27 日期命名的日志表。例如：mylog_,anotherlog_,extralog_3。</span><br><span class="line"></span><br><span class="line">--src-wait               Wait indefinitely for new records to come.</span><br><span class="line">无限期等待新的记录出现。</span><br><span class="line"></span><br><span class="line">--src-resume            Resume reading from previous position. Previous</span><br><span class="line">                        position is read from `binlog-position-file`</span><br><span class="line">从先前位置开始读取。从 binlog-position-file 上读取先前位置。</span><br><span class="line"></span><br><span class="line">--src-binlog-file SRC_BINLOG_FILE</span><br><span class="line">                        Binlog file to be used to read from src. Related to</span><br><span class="line">                        `binlog-position-file`. Ex.: mysql-bin.000024</span><br><span class="line">从源读取数据需要使用的 binlog 文件，与 binlog-position-file 有关。例如：mysql-bin.000024。</span><br><span class="line"></span><br><span class="line">--src-binlog-position SRC_BINLOG_POSITION</span><br><span class="line">                        Binlog position to be used when reading from src.</span><br><span class="line">                        Related to `binlog-position-file`. Ex.: 5703</span><br><span class="line">从源读取数据需要使用的 binlog 位置，与 binlog-position-file 有关。例如：5703。</span><br><span class="line"></span><br><span class="line">--src-file SRC_FILE     Source file to read data from. CSV</span><br><span class="line">从中读取数据的源文件，例如：CSV。</span><br><span class="line"></span><br><span class="line">--dst-file DST_FILE     Target file to be used when writing data. CSV</span><br><span class="line">写入数据需要使用的目标文件，例如：CSV。</span><br><span class="line"></span><br><span class="line">--dst-host DST_HOST     Host to be used when writing to dst. Ex.: 127.0.0.1</span><br><span class="line">写入目标需要使用的 Host，例如：127.0.0.1。</span><br><span class="line"></span><br><span class="line">--dst-port DST_PORT     Port to be used when writing to dst. Ex.: 9000</span><br><span class="line">写入目标需要使用的 Port，例如：9000。</span><br><span class="line"></span><br><span class="line">--dst-user DST_USER     Username to be used when writing to dst. Ex: default</span><br><span class="line">写入目标需要使用的 Username，例如：default。</span><br><span class="line"></span><br><span class="line">--dst-password DST_PASSWORD</span><br><span class="line">                        Password to be used when writing to dst. Ex.: qwerty</span><br><span class="line">写入目标需要使用的 Password，例如：qwerty。</span><br><span class="line"></span><br><span class="line">--dst-schema DST_SCHEMA</span><br><span class="line">                        Database (a.k.a schema) to be used to create tables in</span><br><span class="line">                        ClickHouse. It overwrites source database(s) name(s),</span><br><span class="line">                        so tables in ClickHouse would be located in</span><br><span class="line">                        differently named db than in MySQL. Ex.: db1</span><br><span class="line">在 ClickHouse 中被用于创建表的 Database，他会覆盖源数据库的名称，因此跟 MYSQL 相比在 ClickHouse 本地可以用不同的名称，例如：db1。</span><br><span class="line"></span><br><span class="line">--dst-distribute        Whether to add distribute table</span><br><span class="line">是否添加分发表。</span><br><span class="line"></span><br><span class="line">--dst-cluster DST_CLUSTER</span><br><span class="line">                        Cluster to be used when writing to dst. Ex.: cluster1</span><br><span class="line">写入目标需要使用的 Cluster，例如：cluster1。</span><br><span class="line"></span><br><span class="line">--dst-table DST_TABLE</span><br><span class="line">                        Table to be used when writing to dst. Ex.: table1</span><br><span class="line">写入目标需要使用的 table，例如：table1。</span><br><span class="line"></span><br><span class="line">--dst-table-prefix DST_TABLE_PREFIX</span><br><span class="line">                        Prefix to be used when creating dst table. Ex.:copy_table_</span><br><span class="line">当创建目标表时需要使用的前缀，例如：copy_yable_。</span><br><span class="line"></span><br><span class="line">--dst-create-table      Prepare and run CREATE TABLE SQL statement(s).</span><br><span class="line">准备和运行 CREATE TABLE SQL 语句。</span><br><span class="line"></span><br><span class="line">--column-default-value [COLUMN_DEFAULT_VALUE [COLUMN_DEFAULT_VALUE ...]]</span><br><span class="line">                        Set of key=value pairs for columns default values.</span><br><span class="line">                        Ex.: date_1=2000-01-01 timestamp_1=2002-01-01 01:02:03</span><br><span class="line">设置列默认值的 key=value 对，例如：date_1=2000-01-01，timestamp_1=2002-01-01 01:02:03。</span><br><span class="line"></span><br><span class="line">--column-skip [COLUMN_SKIP [COLUMN_SKIP ...]]</span><br><span class="line">                        Set of column names to skip. Ex.: column1 column2</span><br><span class="line">设置跳过的列名称，例如：column1，column2。</span><br><span class="line"></span><br><span class="line">--ch-converter-file CH_CONVERTER_FILE</span><br><span class="line">                        Filename where to search for CH converter class</span><br><span class="line">搜索 CH 转换器类的文件名。</span><br><span class="line"></span><br><span class="line">--ch-converter-class CH_CONVERTER_CLASS</span><br><span class="line">                        Converter class name i--ch-converter-file file</span><br><span class="line">--ch-converter-file 文件中的转换器类名。</span><br></pre></td></tr></table></figure><hr><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><p><a href="https://minervadb.com/wp-content/uploads/2019/10/How-to-import-and-replicate-data-from-MySQL-to-ClickHouse.pdf">MySQL-to-ClickHouse</a></p><hr><h3 id="个人备注"><a href="#个人备注" class="headerlink" title="个人备注"></a>个人备注</h3><p><strong>此博客内容均为作者学习所做笔记，侵删！</strong><br><strong>若转作其他用途，请注明来源！</strong></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;引入&quot;&gt;&lt;a href=&quot;#引入&quot; class=&quot;headerlink&quot; title=&quot;引入&quot;&gt;&lt;/a&gt;引入&lt;/h3&gt;&lt;p&gt;本次将数据从 &lt;code&gt;MySQL&lt;/code&gt; 备份到 &lt;code&gt;ClickHouse&lt;/code&gt; 采用的是 &lt;a href=&quot;https://github.com/MinervaDB/MinervaDB-ClickHouse-MySQL-Data-Reader&quot;&gt;MinervaDB ClickHouse MySQL Data Reader&lt;/a&gt; ，该项目基础版本来自于 &lt;code&gt;Alitinity/clickhouse-mysql-data-reader&lt;/code&gt;。&lt;/p&gt;</summary>
    
    
    
    
    <category term="MySQL" scheme="https://blog.vgbhfive.cn/tags/MySQL/"/>
    
    <category term="ClickHouse" scheme="https://blog.vgbhfive.cn/tags/ClickHouse/"/>
    
  </entry>
  
  <entry>
    <title>特征工程入门</title>
    <link href="https://blog.vgbhfive.cn/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E5%85%A5%E9%97%A8/"/>
    <id>https://blog.vgbhfive.cn/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E5%85%A5%E9%97%A8/</id>
    <published>2022-05-21T16:17:39.000Z</published>
    <updated>2023-01-01T15:52:55.969Z</updated>
    
    <content type="html"><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>特征工程将数据转换为能更好地表示潜在问题的特征，从而提高机器学习性能。<br>特征工程具体包含内容如下：</p><ul><li>转换数据的过程。处理的数据经常是表格形式的，此时数据会被组织成行（观察值）和列（属性）。</li><li>特征。特征是对机器学习过程有意义的数据属性，我们需要经常查看表格，确定哪些列是特征，哪些列只是普通的属性。</li><li>更好地表示潜在问题。转换数据的目的在于更好地表达更大的问题。</li><li>提高机器学习性能。特征工程的最终目的在于获取更好的数据，以便学习算法从中挖掘模式，取得更好的效果。</li></ul><span id="more"></span><p>评估特征工程的步骤：</p><ul><li>在应用任何特征工程之前，得到机器学习模型的基准性能。</li><li>应用一种或多种特征工程。</li><li>对于每种特征工程，获取一个性能指标，并与基准性能进行对比。</li><li>如果性能的增量（变化）大于某个阈值（一般由我们定义），则任务这种特征工程是有益的，并在机器学习流水线上应用。</li><li>性能的改变一般以百分比计算（如果基准性能从 <code>40%</code> 的准确率提升到 <code>76%</code> 的准确率，那么改变就是 <code>90%</code>）。</li></ul><p><small>本篇文章的重点在于<strong>理解和转换特征</strong>。</small></p><h4 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h4><p>当你看到这里时，我想你是真的想要学习特征工程，但这也需要一些前提，希望你都具有：</p><ul><li>熟悉 <code>Python</code> 的基础语法。</li><li>理解风控模型相关的知识。</li><li>挑战已有认知的能力。</li></ul><p><small>前提声明，本文章的大部分内容为作者学习《特征工程入门与实践》一书中的学习笔记，如果需要可以自行购买学习，并且本文不包含原书任何代码内容，见谅。</small></p><hr><h3 id="特征理解"><a href="#特征理解" class="headerlink" title="特征理解"></a>特征理解</h3><p>前面我们了解了要做的事情，那么接下来就是开始干一些真实的事情：理解和处理数据。</p><h4 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h4><p>结构化（有组织）数据可以分为观察值和特征的数据，一般以表格的形式组织（行是观察值，列是特征）。<br>非结构化（无组织）数据作为自由流动的实体，不遵循标准组织结构的数据。</p><p>结构化和非结构化数据的区别：</p><ul><li>以原始文本格式存储的数据。</li><li>科学仪器报告的气象数据是高度结构化的，因为存在表格的行列结构。</li></ul><h4 id="数据分类"><a href="#数据分类" class="headerlink" title="数据分类"></a>数据分类</h4><p>定量数据本质上是数值，应该是衡量某样东西的数量。<br>定性数据本质上是类别，应该是描述某样东西的性质。</p><p><small>但是有时候数据可以同时是定量和定性的。</small></p><h4 id="数据等级"><a href="#数据等级" class="headerlink" title="数据等级"></a>数据等级</h4><p>数据的四个等级分别是：</p><ul><li>定类等级（<code>nominal level</code>）</li><li>定序等级（<code>ordinal level</code>）</li><li>定距等级（<code>interval level</code>）</li><li>定比等级（<code>ratio level</code>）</li></ul><p>每个等级都有不同的控制和数学操作等级，了解数据的等级十分重要，因为它决定了可以执行的可视化类型和操作。</p><ol><li><p>定类等级<br>定类等级是数据的第一个等级，其结构最弱，这个等级的数据只按名称分类。这些数据都是定性的。<br>对于每个等级都会介绍可执行和不可执行的数学操作，而在这个等级上，不能执行任何定量数学操作。</p></li><li><p>定序等级<br>定序等级在继承了定类等级的所有属性，而且还提供了重要的附加属性：</p></li></ol><ul><li>定序等级的数据可以自然排序。</li><li>排序则意味者列中的某些数据比其他数据更好或更大。<br>和定类等级一样，定序等级的天然数据属性仍然是类别，即使用数来表示类别也是如此。</li></ul><ol start="3"><li><p>定距等级<br>在定距等级数值数据不仅可以像定序等级的数据一样排序，而且值之间的差异也有意义，这就意味着在定距等级不仅可以对值进行排序和比较，还可以进行加减运算。</p></li><li><p>定比等级<br>在定比等级我们可以进行最大程度的控制和数学计算能力，和定距等级一样，定比等级的数据也是定量数据，不仅继承了定距等级的加减运算，而且也有了一个绝对零点的概念，可以进行乘除运算。</p><p> 理解数据的不同等级对于特征工程是非常重要的，当需要构建新特征或修复旧特征时，必须确定办法去处理每一列。因此当你拿到一个数据集时，可以按照以下的流程处理：</p><ul><li>数据是否有组织？数据是否以表格形式存在？是否有不同的列？还是以非结构化的文本形式存在？</li><li>每列的数据是定量的还是定性的？单元格里的数代表是数值还是字符串？</li><li>每列处于哪个等级？是定类、定序、定距、还是定比？</li><li>可以使用哪些图表？条形图、饼图、茎叶图、箱线图、直方图、还是其他图形？</li></ul></li></ol><hr><h3 id="特征增强"><a href="#特征增强" class="headerlink" title="特征增强"></a>特征增强</h3><p>到达这里我们在前面已经说了在实际应用中评估和理解出现的不同的数据类型。<br>下面我们进一步的修改数据集，具体来说就是开始清洗和增强数据，前者是指调整已存在的行和列，而后者则是指在数据集中删除和添加新的列，当然这些所有的目的都是为了优化机器学习的效果。</p><h4 id="缺失值"><a href="#缺失值" class="headerlink" title="缺失值"></a>缺失值</h4><p>特征增强的第一种方法就是识别数据的缺失值，这样可以让我们更好的明白如何使用真实的数据，因为在实际种总会有各种原因导致数据的确实。</p><ol><li><p>探索性数据分析<br>首先进行探索性数据分析（<code>EDA</code>）来识别缺失的值，可以使用 <code>Numpy</code> 和 <code>Pandas</code> 来存储数据并进行一些简单的计算，还可以使用可视化工具来观察数据的分布情况。</p></li><li><p>处理缺失值<br>缺失值会引起很多问题，最重要的是大部分学习算法不能处理缺失值。目前两个最主要的处理方法：</p><ul><li>删除缺少值的行。</li><li>填充缺失值。<br>  填充指的是利用现有知识&#x2F;数据来确定缺失的数量值并填充的行为。</li></ul></li></ol><h4 id="归一化-x2F-标准化"><a href="#归一化-x2F-标准化" class="headerlink" title="归一化&#x2F;标准化"></a>归一化&#x2F;标准化</h4><p>数据尺度的不同导致数据的集合差别很大，因此归一化操作旨在将行与列对齐转化为一致的规则，最常用的方式就是将所有定量列转化为同一个静态范围内的值。而标准化通过确保所有行和列在机器学习中得到平等对待，让数据的处理保持一致。<br>常用的三种数据归一化方法：</p><ol><li><p><code>Z</code> 分数标准化<br><code>Z</code> 分数标准化是最常用的标准化技术，他利用了统计学内最简单的 <code>z</code> 分数思想。<code>z</code> 分数标准化的输出会被重新缩放，使均值为 <code>0</code>、标准差为 <code>1</code>，通过缩放特征、统一化均值和方差，可以让 <code>KNN</code> 这种模型达到最优化，而不会出现倾向于较大比例的特征。公式很简单，对于每列，用这个公式替换单元格：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">z = (x - μ) / σ</span><br></pre></td></tr></table></figure><p>在这个公式中 <code>z</code> 是新的值（<code>z</code> 分数）；<code>x</code> 是单元格原来的值；<code>μ</code> 是该列的均值；<code>σ</code> 是列的标准差。<br><small><code>z</code> 表示该值到均值的距离，如果它最初低于该列的均值，则 <code>z</code> 分数就是负数。</small></p></li><li><p><code>min-max</code> 标准化<br><code>min-max</code> 标准化与 <code>Z</code> 分数标准化类似，因为他也是一个公式替换列中的每个值。此处的公式为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">m = (X - Xmin) / (Xmax - Xmin)</span><br></pre></td></tr></table></figure><p>在这个公式中 <code>m</code> 是新的值；<code>X</code> 是单元格原来的值；<code>Xmax</code> 是该列的最大值；<code>Xmin</code> 是该列的最小值。</p></li><li><p>行归一化<br>行归一化不是计算每列的统计值，而是会保证每行有单位范数，意味着每行的向量长度相同。如果每行数据都在一个 <code>n</code> 维空间内，那么每行都有一个向量范数，也就是每行都是空间内的一个向量：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = (x1, x2, ..., xn)</span><br></pre></td></tr></table></figure><p>那么范数的计算方法为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">||x|| = (x1^2 + x2^2 + ... + xn^2) ^ (1/2)</span><br></pre></td></tr></table></figure></li></ol><p>很多算法会受尺度的影响，下面就是一些流行的学习算法：<br>     - <code>KNN</code> - 依赖欧几里得距离。<br>     - <code>K</code> 均值距类 - 依赖欧几里得距离。<br>     - 逻辑回归、支持向量机、神经网络 - 使用梯度下降来学习权重。<br>     - 主成分分析 - 特征向量将偏向较大的列。</p><p>特征增强的意义在于识别有问题的区域，并确定哪种修复方法最有效，当然也可以删除数据，但是我们应该考虑如何用最好的方法解决问题，而不是删除了事。</p><hr><h3 id="特征构建"><a href="#特征构建" class="headerlink" title="特征构建"></a>特征构建</h3><p>之前研究的特征都是定量的，那么接下来我们研究分类数据，主要的目的就是利用现有的特征构建全新的特征，让模型从中学习。</p><h4 id="编码分类变量"><a href="#编码分类变量" class="headerlink" title="编码分类变量"></a>编码分类变量</h4><p>将分类数据转化为数值数据。</p><ol><li><p>定类等级编码<br>主要方法就是将分类数据转换为<strong>虚拟变量</strong>，这样有两种选择：</p><ul><li>使用 <code>Pandas</code> 自动找到分类变量进行编码。</li><li>创建自定义虚拟变量编码器，在流水线中工作。</li></ul><p> 虚拟变量的取值是 <code>1</code> 或 <code>0</code>，代表某个类别的有无，虚拟变量代表定性数据的代理，或者说是数值的替代。<br> 当使用虚拟变量时，需要小心虚拟变量陷阱。虚拟陷阱是指自变量有多重共线性或高度相关，简单来说就是这些变量能依据彼此来预测，当存在多个自变量共线性时，就会陷入虚拟变量陷阱。通常为了避免虚拟变量陷阱我们会忽略一个常量或者虚拟类型。</p></li><li><p>定序等级编码<br>将字符串转换为数值数据，在定序等级中由于数据的顺序有含义，使用虚拟变量是没有意义的，为了保持顺序，我们使用<strong>标签编码器</strong>。<br>标签编码器是指顺序数据的每个标签都会有一个相关数据。</p><p> 另外如果数值数据是连续的，那么就可以将其转化为分类变量是有意义的。<code>Pandas</code> 中有一个函数 <code>cut</code>，可以将数据进行分箱，也可以成为分桶，其意义是将会创建数据的范围。</p></li><li><p>扩展数值特征<br>有很多种办法从数字特征中创建扩展特征。<br>在处理数值数据、创建很多特征时，一个关键的方法就是使用 <code>scikit-learn</code> 的 <code>polynomial-Features</code> 类，这个类会创建新的列，他们是原有列的乘积，用于捕获特征交互。<br>更具体来说就是这个类会生成一个新的特征矩阵，里面是原始数据各个特征的多项式组合，阶数小于或等于指定的阶数。</p></li></ol><h4 id="文本的特征构建"><a href="#文本的特征构建" class="headerlink" title="文本的特征构建"></a>文本的特征构建</h4><p>之前一直处理分类数据和分值数据，虽然分类数据是字符串但是里面的文本仅仅是个类别，下面我们将进行更长的文本数据，这种文本数据比单个类别的文本更复杂的多，因为长文本包含一系列类别，或称为<strong>词项</strong>。</p><p><code>scikit-learn</code> 有一个 <code>feature_extraction</code> 模块，顾名思义是能以机器学习算法支持的方法提取数据的特征，包括文本数据，这个模块同时也包含了处理文本时需要的一些方法。<br><small>将文本数据称为语料库，尤其是指文本内容或文档的集合。</small><br>将语料库转换为数值表示（向量化）的常见方法就是<strong>词袋</strong>，其基本思想是通过单词的出现来描述文档，完全忽略单词在文档中的位置。在他最简单的形式中，用一个袋子来表示文本，不考虑语法和词序，并将这个袋子视为一个集合，其中重复度最高的单词最为重要。<br>词袋的三个步骤是：</p><ul><li>分词。分词过程就是用空白、标点将单词分开，将其变为词项，每个可能出现的词项都有一个整数 <code>ID</code>。</li><li>计数。简单地计算文档中词项的出现次数。</li><li>归一化。将词项在大多数文档中的重要性按逆序排列。</li></ul><p>下面是常用的几种向量化方法：</p><ul><li><code>CountVectorizer</code>，将文本数据转换为其向量表示的最常用方法，和虚拟变量类似 <code>CountVectorizer</code> 将文本列转换为矩阵，其中的列就是词项，单元值是每个文档中每个词项的出现次数。这个矩阵叫做<strong>文档-词矩阵</strong>，因为每行代表一个文档，每列代表一个词。<br>  <small>在实际使用中，还可以使用<strong>词干提取</strong>，可以将词汇中的词干提取出来，也就是把单词转换为其词根，从而缩小词汇量。</small></li><li><code>TF-IDF</code> 向量化器，由两部分组成，表示词频的 <code>TF</code> 部分，以及表示<strong>逆文档频率</strong> 的 <code>IDF</code> 部分。<code>TF-IDF</code> 是一个用于信息检索和聚类的词加权方法。<ul><li><code>TF</code> 词频，衡量词在文档中出现的频率。由于文档的长度不同，词在短文本中出现的频率可能比长文本中小得多，因此一般会对词频进行归一化，用其除以文档长度或文档的总词数。</li><li><code>IDF</code> 逆文档频率，衡量词的重要性。在计算词频时，认为所有的单词同等重要，但是一些词（例如 <code>of</code> 、 <code>is</code> 等）有可能出现多次，但这些词并不重要，因此我们需要减少常见词的权重，加大稀有词的权重。</li></ul></li></ul><p>在这里你已经了解到了在分类数据和分值数据中填充缺失值，针对分类数据进行编码，数值数据和文本数据的特征构建，那么接下来就是选择合适的特征。</p><hr><h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><p>特征选择是从原始数据中选择对于预测流水线而言最好的特征的过程，更正式的说就是给定 <code>n</code> 个特征，我们搜索其中的 <code>k (k &lt; n)</code> 个特征来改善机器学习的效果，总而言之就是 <strong>特征选择尝试剔除数据中的噪声</strong>。<br>特征选择的方法可以分为两大类：基于统计的特征选择和基于模型得到特征选择。基于统计的特征选择很大程度上依赖于机器学习模型之外的统计测试，以便在流水线的训练阶段选择特征。而基于模型的特征选择则依赖于一个预处理步骤，需要训练一个辅助的机器学习模型，并利用其预测能力来选择特征。其实这两种类型都是试图从原始特征中选择一个子集，减少数据大小，只留下预测能力最高的特征。<br>当然这其中也会存在问题，那么需要解决的问题就是：</p><ul><li>找到 <code>k</code> 特征子集的办法。</li><li>在机器学习中对 <em>更好</em> 的定义。</li></ul><p>当然对上述目标更好的说明就是我们要实现更好的预测性能，而且仅使用简单的指标进行测量。再更加具体的就是：</p><ul><li>模型拟合&#x2F;训练所需的时间。</li><li>拟合后的模型预测新实例的时间。</li><li>需要持久化（永久保存）的数据大小。</li></ul><p>特征选择算法可以智能地从数据中提取最重要的信号并忽略噪声，达到以下两种结果：</p><ul><li>提升模型性能，在删除冗余数据之后，基于噪声和不相关数据做出错误决策的情况会减少，而且模型可以在重要的特征上练习，提高预测性能。</li><li>减少训练时间和预测时间，因为拟合的数据更少，所以模型一般在拟合和训练上有速度提升，让流水线的整体速度更快。</li></ul><ol><li><p>基于统计的特征选择<br>通过统计数据，可以快速、简便地解释定量和定性数据。下面使用两种概念：</p><ul><li>皮尔逊相关系数。</li><li>假设检验。</li></ul><p> <small>这两种方法都是单变量方法，仅仅是为了提高机器学习性能而每次选择单一特征以创建更好的数据集这种是最简便的。</small></p><p> 皮尔逊相关系数会测量列之间的线性关系，该系数在 <code>1 ~ -1</code> 之间变化，其中 <code>0</code> 代表没有线性关系，<code>1</code> 或者 <code>-1</code> 表示相关性关系最强。</p><p> 假设检验是一种统计学方法，可以对单个特征进行复杂的统计检验，在特征选择中使用假设检验可以尝试从数据集中选择最佳特征，但是这里更依赖传统的依赖于形式化的统计方法，并通过所谓的 <code>P</code> 值进行检验。<code>p</code> 值是介于 <code>0</code> 和 <code>1</code> 的小数，代表在假设检验下，给定数据偶然出现的概率，简而言之，<code>p</code> 值越低，拒绝零假设的概率越大。当然假设的原则是 <strong>特征与响应变量没有关系（零假设）为真还是为假</strong>。<br> 作为一种统计检验，假设检验用于在给定数据样本时确定可否在整个数据集上应用某种条件，假设检验的结果会告诉我们是否应该相信或拒绝假设（并选择另一个假设）。基于样本数据，假设检验会确定是否应拒绝零假设，通常会采用 <code>p</code> 值来得出结论。</p></li><li><p>基于模型的特征选择<br>本次使用的两类模型是基于树模型和线性模型，这两类模型都有特征排列的功能，在对特征划分子集时很有用。</p><ul><li>基于树模型，在拟合决策树时，决策树会从根节点开始，在每个节点处贪婪地选择最优分割，优化节点纯净度指标。默认情况下 <code>scikit-learn</code> 每步都会优化 <strong>基尼系数</strong>，每次分割时，模型会记录每个分割对整体优化目标的帮助，因此在树形结构中，这些指标对特征重要性有作用。</li><li>基于线性模型，在拟合后线性回归、逻辑回归、支持向量机（<code>SVM</code>）等线性模型会将一个系数放在特征的斜率（重要性）前面。<br>  在线性模型中，正则化是一种对模型世家额外约束的方法，目的在于防止过拟合，并改进数据泛化能力。其中正则化通过对需要优化的<strong>损失函数</strong>添加额外的条件来完成，意味着在拟合时正则化的线性模型有可能严重减少甚至损失特征。</li></ul><p> 前面说了选择特征的方法，分为基于统计学和基于机器学习模型的二次输出。下面是一些经验可以在判断特征选择时参考：</p><ul><li>如果特征是分类的，那么从 <code>SelectKBest</code> 开始，用卡方或基于树得到选择器。</li><li>如果特征基本是定量的，用线性模型和基于相关性的选择器一般效果更好。</li><li>如果是二元分类问题，考虑使用 <code>SelectFromModel</code> 和 <code>SVC</code>，因为 <code>SVC</code> 会查找优化二元分类任务的系数。</li><li>在手动选择前，收缩性数据分析会很有益处的，同时不要低估领域知识的重要性。</li></ul></li></ol><hr><h3 id="特征转换"><a href="#特征转换" class="headerlink" title="特征转换"></a>特征转换</h3><p>在前面总共经历了数据探索性分析、特征理解、特征增强、特征构建和特征选择，下面有一套新的转换数据的方法称为<strong>特征转换</strong>。<br>特征转换实际上是一种矩阵算法，会在结构上改变数据，产生本质上全新的<strong>数据矩阵</strong>。其基本思想是，数据集的原始特征是数据点的描述符&#x2F;特点，也应该能创造一组新的特征，用更少的列来解释数据点，并且效果不变，或者效果更好。</p><p>前面提到的使用更少的列来描述数据，这跟特征选择的概念有类似之处，但是他们的方法却有很大的不同。<br>特征选择仅限于从原始列中选择特征，而特征转换则是将原始列组合起来，从而创建可以更好描述数据的特征。特征转换使用原始数据集的隐藏结构创建新的列，生成一个全新的数据集，结构与之前不同。特征转换可以使用每个列中的一点点特征创建<strong>超级列</strong>，所以不需要创建很多新特征就可以捕获所有潜在的特征交互。<br>特征转换算法可以选择最佳的列，将其与其中的几个列进行组合，从而构建新的特征。一般常用的方法有以下两种：</p><ul><li>主成分分析（<code>PCA</code>）</li><li>线性判别分析（<code>LDA</code>）</li></ul><ol><li><p>主成分分析<br>主成分分析是将有多个相关特征的数据投影到相关特征较少的坐标系上。这些新的、不相关的特征（之前称为超级列）叫主成分。主成分能替代原始特征空间的坐标系，需要的特征少、捕捉的变化多。<br><code>PCA</code> 的目标在于识别数据集中的模式和潜在结构，以创建新的特征，而非使用原始特征。主成分会产生新的特征，最大化数据的<strong>方差</strong>，这样每个特征都能解释数据的形状，主成分按可以解释的方差来排序，第一个主成分最能解释数据的方差，第二个其次，最终我们希望尽可能使用多的成分来优化机器学习任务，无论是监督学习还是无监督学习。<br><code>PCA</code> 本身是<strong>无监督任务</strong>，意思是 <code>PCA</code> 不使用响应列进行投影&#x2F;转换。</p><p> <code>PCA</code> 利用了协方差矩阵得到<strong>特征值分解</strong>。这个过程可以分为四步：</p><ul><li>创建数据集的协方差矩阵。</li><li>计算协方差矩阵的特征值。</li><li>保留前 <code>k</code> 个特征值（按特征值降序排列）。</li><li>用保留的特征向量转换新的数据点。</li></ul><p> <small><code>PCA</code> 也可以用在相关矩阵上，如果特征的尺度类似，那么可以使用相关矩阵。尺度不同时，应使用协方差矩阵。一般建议在缩放数据上使用协方差矩阵。</small></p></li><li><p>线性判别分析<br>线性判别分析（<code>LDA</code>）是特征变换算法，也是有监督分类器。<code>LDA</code> 一般用于分类流水线的预处理步骤，和 <code>PCA</code> 一样 <code>LDA</code> 的目标在于提取一个新的坐标系，将原始数据集投影到一个<strong>低维空间</strong>中；但是和 <code>PCA</code> 的区别在于 <code>LDA</code> 不会专注于数据的方差，而是优化低维空间，以获得最佳的类别可分性。综上所述的意思就是新的坐标系在为分类模型查找决策边界时更有用，非常适合用于构建分类流水线。</p><p> <small><code>LDA</code> 极为有用的原因在于基于类别可分性的分类有助于避免机器学习流水线的过拟合，也叫防止维度诅咒。<code>LDA</code> 也会降低计算成本。</small></p><p> <code>LDA</code> 与 <code>PCA</code> 一样可以作为降维工具使用，但并不会计算整体数据的协方差矩阵的特征值，而是计算类内和类间散布矩阵的特征值和特征向量。<code>LDA</code> 可以分为五个步骤：</p><ul><li>计算每个类别的均值向量。</li><li>计算类内和类间的散步矩阵。</li><li>计算 <code>Sw^-1 * Sb</code> 的特征值和特征向量。</li><li>降序排列特征值，保留前 <code>k</code> 个特征向量。</li><li>使用前几个特征向量将数据投影到新空间。</li></ul><p> <code>PCA</code> 和 <code>LDA</code> 都是特征转换工具，用于找出最优的新特征，<code>LDA</code> 特别为类别分离进行了优化，而 <code>PCA</code> 是无监督的，尝试用更少的特征表达方差。<br> <code>PCA</code> 和 <code>LDA</code> 都是很强大的工具，但也有局限性，这两个工具都是线性转换，所以只能创建线性的边界，表达数值型数据。他们也是静态转换，无论输入什么，<code>LDA</code> 和 <code>PCA</code> 的输出都是可预期的，而且是数学的。如果数据不适合 <code>PCA</code> 和 <code>LDA</code>（数据有非线性特征），那么无论我们怎么进行网格搜索，这些算法都不会有帮助。</p></li></ol><hr><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>当你看到了这里，我想你肯定觉得一头雾水，在这里我还是建议你来看看这本书《特征工程入门与实践》，当你看完这本书再来看这篇文章，那你一定会受益良多。</p><hr><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><hr><h3 id="个人备注"><a href="#个人备注" class="headerlink" title="个人备注"></a>个人备注</h3><p><strong>此博客内容均为作者学习《特征工程入门与实践》所做笔记，侵删！</strong><br><strong>若转作其他用途，请注明来源！</strong></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;特征工程将数据转换为能更好地表示潜在问题的特征，从而提高机器学习性能。&lt;br&gt;特征工程具体包含内容如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;转换数据的过程。处理的数据经常是表格形式的，此时数据会被组织成行（观察值）和列（属性）。&lt;/li&gt;
&lt;li&gt;特征。特征是对机器学习过程有意义的数据属性，我们需要经常查看表格，确定哪些列是特征，哪些列只是普通的属性。&lt;/li&gt;
&lt;li&gt;更好地表示潜在问题。转换数据的目的在于更好地表达更大的问题。&lt;/li&gt;
&lt;li&gt;提高机器学习性能。特征工程的最终目的在于获取更好的数据，以便学习算法从中挖掘模式，取得更好的效果。&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    
    <category term="Feature" scheme="https://blog.vgbhfive.cn/tags/Feature/"/>
    
  </entry>
  
  <entry>
    <title>Neo4j系列博客-高级应用</title>
    <link href="https://blog.vgbhfive.cn/Neo4j%E7%B3%BB%E5%88%97%E5%8D%9A%E5%AE%A2-%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8/"/>
    <id>https://blog.vgbhfive.cn/Neo4j%E7%B3%BB%E5%88%97%E5%8D%9A%E5%AE%A2-%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8/</id>
    <published>2022-04-29T14:14:23.000Z</published>
    <updated>2023-01-01T15:53:46.137Z</updated>
    
    <content type="html"><![CDATA[<h3 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h3><p>在之前的学习中，大致明白了 <code>Neo4j</code> 的基本操作、程序开发、数据库管理等操作，对于一些基本的操作已经足够，而现在则是通过一些高级的使用来探索其他功能的启发。</p><span id="more"></span><hr><h3 id="高级索引"><a href="#高级索引" class="headerlink" title="高级索引"></a>高级索引</h3><p>主要介绍空间索引和中文全文索引两个部分。</p><h4 id="空间索引"><a href="#空间索引" class="headerlink" title="空间索引"></a>空间索引</h4><p>空间索引的程序库是 <code>Neo4j Spatial</code>，他的主要作用是对数据进行<strong>空间</strong>操作，开发人员可以向已经具有位置信息的数据添加<strong>空间索引</strong>，并且对数据进行空间计算操作。另外 <code>Neo4j Spatial</code> 提供了数据导入 <code>GeoTools</code> （<code>Java</code> 编写的开源 <code>GIS</code> 工具包），从而启用 <code>GeoTools</code> 的应用程序，比如 <code>GeoServer</code> （共享空间地理数据的开源服务器）和 <code>uDig</code> （开源地理桌面数据访问、编辑、呈现框架）。</p><p><code>Neo4j Spatial</code> 的主要功能包括：</p><ul><li>可以将 <code>RESI Shapefile (SHP)</code> 和 <code>Open Street Map (OSM)</code> 文件导入 <code>Neo4j</code> 的应用程序。</li><li>支持常见的几何图形：点、线、多边形等。</li><li>用于快速搜索几何形状的 <code>RTree</code> 结构。</li><li>支持搜索期间的拓扑操作（包含、属于、相交、覆盖等）。</li><li>只要提供从图形映射到几何形状的适配器，就可以对任何图形进行空间操作，而不负责其数据的存储方式。</li><li>能够使用预配置的过滤器将单个图层或数据拆分成多个之图层或视图。</li></ul><h5 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h5><p>使用 <code>Neo4j Spatial</code> 最简单的方法就是获取 <code>neo4j-spatial-*.**-neo4j-*.*.*-server-plugin</code>，然后将其复制到 <code>plugin</code> 目录下，重新启动 <code>Neo4j</code> 服务即可使用。<br>使用 <code>Cypher</code> 查询一样调用 <code>Neo4j</code> 空间过程，为节点添加空间索引，并且执行多个空间点的距离、交叉查询等操作。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">// 创建 geom 的点图层</span><br><span class="line">CALL spatial.addPointLayer(&#x27;geom&#x27;)</span><br><span class="line">CALL spatial.layers()</span><br><span class="line">// 建立经度为 15.2 ，维度为 60.1 的空间点</span><br><span class="line">CREATE (n:Node &#123;latitude: 60.1, longitude: 15.2&#125;) WITH n</span><br><span class="line">// 将创建的点加入到 geom 的点图层中</span><br><span class="line">CALL spatial.addNode(&#x27;geom&#x27;, n) YIELD node RETURN node</span><br><span class="line">// 查询精度在 60.0 到 60.1 之间，纬度在 15.0 到 15.3 之间的空间点</span><br><span class="line">CALL spatial.bbox(&#x27;geom&#x27;, &#123;lon: 15.0, lat: 60.0&#125;. &#123;lon: 15.3, lat: 60.1&#125;)</span><br></pre></td></tr></table></figure><h5 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h5><p><code>Neo4j</code> 空间索引是 <code>RTree</code> 索引，它是以扩展的方式开发的，允许在必要的时候添加其他索引。空间索引可以在数据生成的过程中添加，也可以为现有的空间数据添加索引，并且实际上可以导致不同的图结构。<br>需要在数据生产的过程中添加索引，最简单的方法就是创建合适的数据图层，最常用的两种：</p><ul><li><code>SimplePointLayer</code>：一个可编辑的数据图层，仅允许向数据库添加点数据。</li><li><code>Editablelayer(Impl)</code>：默认的可编辑图层实现，可以处理任何简单的集合类型。存储格式为 <code>WKB</code>，专门用于几何地理的二进制格式。</li></ul><p><small>定义几何图形的集合叫图层，其中包含可用于查询的索引，如果在图层中添加和修改图形，则这个图层就是可编辑图层。</small></p><h5 id="空间索引查询类型"><a href="#空间索引查询类型" class="headerlink" title="空间索引查询类型"></a>空间索引查询类型</h5><p><code>RTree</code> 索引可以实现的查询方式有：</p><ul><li>包含（<code>Contian</code>）。</li><li>覆盖（<code>Cover</code>）。</li><li>被覆盖（<code>Covered By</code>）。</li><li>交叉（<code>Cross</code>）。</li><li>不相交（<code>Disjoint</code>）。</li><li>相交（<code>Intersect</code>）。</li><li>交叠（<code>Oberlap</code>）。</li><li>接触（<code>Touch</code>）。</li><li>包含（<code>Within</code>）。</li><li>在一定距离内（<code>With Distance</code>）。</li></ul><h5 id="Java-构建-Neo4j-空间索引"><a href="#Java-构建-Neo4j-空间索引" class="headerlink" title="Java 构建 Neo4j 空间索引"></a><code>Java</code> 构建 <code>Neo4j</code> 空间索引</h5><p><code>Neo4j</code> 自带一个用于导入 <code>ESRI Shapefile</code> 数据的程序，<code>ShapeFileImporter</code> 将为每个导入的 <code>Shapefile</code> 创建一个新的图层，并将每个几何图形作为 <code>WKB</code> 存储在单个节点的单个属性中。</p><ol><li><p>导入 <code>shape</code> 文件<br>下面的代码将 <code>roads.shp</code> 导入到 <code>layer_roads</code> 图层中。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">File</span> <span class="variable">storeDir</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">File</span>(dbPath);</span><br><span class="line"><span class="type">GraphDatabaseService</span> <span class="variable">database</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">GraphDatabaseFactory</span>().newEmbeddedDatabase(storeDir);</span><br><span class="line"><span class="keyword">try</span> (<span class="type">Transaction</span> <span class="variable">tx</span> <span class="operator">=</span> database.beginTx()) &#123;</span><br><span class="line"><span class="type">ShapefileImporter</span> <span class="variable">importer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ShapefileImporter</span>(database);</span><br><span class="line">importer.importFile(<span class="string">&quot;roads.shp&quot;</span>, <span class="string">&quot;layer_roads&quot;</span>);</span><br><span class="line">tx.success();</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">database.shutdown();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用 <code>Neo4j Spatial</code> 过程调用，可以达到同样的效果</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CALL spatial.addWKTLayer(&#x27;layer_roads&#x27;, &#x27;geometry&#x27;)</span><br><span class="line">CALL spatial.importShapefileToLayer(&#x27;layer_roads&#x27;, &#x27;roads.shp&#x27;)</span><br></pre></td></tr></table></figure></li><li><p>导入开放街道地图文件（<code>OSM</code>）<br>导入 <code>OSM</code> 文件要比 <code>SHP</code> 文件复杂很多，因为导入 <code>OSM</code> 文件需要分两个过程进行，而第一个过程需要批处理导入。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">File</span> <span class="variable">dir</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">File</span>(dbPath);</span><br><span class="line"><span class="comment">// 设置图层名称</span></span><br><span class="line"><span class="type">OSMImporter</span> <span class="variable">importer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">OSMImporter</span>(<span class="string">&quot;OSM&quot;</span>);</span><br><span class="line"><span class="comment">// 批量导入配置</span></span><br><span class="line">Map&lt;String, String&gt; config = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;String, String&gt;();</span><br><span class="line">config.put(<span class="string">&quot;neostore.nodestore.db.mapped_memory&quot;</span>, <span class="string">&quot;90M&quot;</span>);</span><br><span class="line">config.put(<span class="string">&quot;dump_configuration&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line">config.put(<span class="string">&quot;use_memory_mapped_buffers&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line"><span class="type">BatchInserter</span> <span class="variable">batchInserter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BatchInserterImpl</span>(dir, config);</span><br><span class="line">importer.importFile(batchInserter, <span class="string">&quot;map.osm&quot;</span>, <span class="literal">false</span>);</span><br><span class="line">BatchInserter.shutdown();</span><br><span class="line"><span class="type">GraphDatabaseService</span> <span class="variable">db</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">GraphDatabaseFactory</span>().newEmbeddedDatabase(dir);</span><br><span class="line">importer.reIndex(db, <span class="number">10000</span>);</span><br><span class="line">db.shutdown();</span><br></pre></td></tr></table></figure></li></ol><h5 id="常见的-Cypher-查询"><a href="#常见的-Cypher-查询" class="headerlink" title="常见的 Cypher 查询"></a>常见的 <code>Cypher</code> 查询</h5><ol><li><p><code>WithinDistance</code> 查询<br><code>WithinDistance</code> 查询是空间查询中最常用的一种方式，使用的是球面距离，计算采用 <code>OrthodromicDistance</code> 算法。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start n = node:geom(&#x27;WithinDistance:[21.331937, 120.638154, 0.1]&#x27;) return n limit 10</span><br></pre></td></tr></table></figure></li><li><p><code>WithinWKTGeometry</code> 查询<br>查询由点 <code>(120.678966, 31.300864)</code> 与点 <code>(120.978966, 31.330864)</code> 构成的 <code>Ploygon</code> 多边形范围内的点</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start n = node.geoindex(&#x27;WithinWKTGeometry:PLOYGON ((120.678966, 31.300864, 120.978966, 31.330864, 120.978966, 31.300864, 120.678966, 31.300868))&#x27;) return n limit 10</span><br></pre></td></tr></table></figure></li><li><p><code>bbox</code> 矩形查询<br>查询由点 <code>(120.678966, 31.300864)</code> 与点 <code>(120.978966, 31.330864)</code> 构成的 <code>BBox</code> 矩形范围内的点</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start n = node.geom(&#x27;bbox:[120.678966, 120.978966, 31.300864, 31.330864]&#x27;) return n limit 10</span><br></pre></td></tr></table></figure></li></ol><h4 id="中文全文索引"><a href="#中文全文索引" class="headerlink" title="中文全文索引"></a>中文全文索引</h4><p><code>Neo4j</code> 也提供了全文索引机制，并且是基于 <code>Lucene</code> 实现的，但是在默认情况下 <code>Lucene</code> 只提供了基于英文的分词器，如果将之用于中文，则会将中文分割成单个的字，这样就破坏了中文的语义结构，而且针对特定领域的中文分词，可能还需要自定义词典。</p><h5 id="IKAnalyzer-分词器"><a href="#IKAnalyzer-分词器" class="headerlink" title="IKAnalyzer 分词器"></a><code>IKAnalyzer</code> 分词器</h5><p><code>IKAnalyzer</code> 是一个开源的、基于 <code>Java</code> 开发的轻量级中文分词工具包，但是目前官方仅支持 <code>Luence 3.0</code> 版本。 </p><h5 id="基本使用-1"><a href="#基本使用-1" class="headerlink" title="基本使用"></a>基本使用</h5><ol><li><p>自定义词典<br>词典文件：自定义词典文件后缀名为 <code>.dic</code> 的词典文件，必须使用 <code>UTF-8</code> 编码保存。<br>词典配置： <code>IKAnalyzer.cfg.xml</code> 必须在 <code>src</code> 目录下。词典文件可以放置在任意位置，但是在配置文件中必须配置正确。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span> ?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCUTYPE <span class="keyword">properties</span> <span class="keyword">SYSTEM</span> <span class="string">&quot;http://java.sun.com/dtd/properties.dtd&quot;</span> &gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">commnet</span>&gt;</span>IK Analyzer 扩展配置<span class="tag">&lt;/<span class="name">commnet</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">entry</span> <span class="attr">key</span>=<span class="string">&quot;ext_dict&quot;</span>&gt;</span>ext.dic;<span class="tag">&lt;/<span class="name">entry</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">entry</span> <span class="attr">key</span>=<span class="string">&quot;ext_stopwords&quot;</span>&gt;</span>stopwords.dic;<span class="tag">&lt;/<span class="name">entry</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>嵌入式模式下的中文全文索引<br>指定 <code>IKAnalyzer</code> 作为 <code>Luence</code> 分词的 <code>Analyzer</code>，并对一个 <code>Label</code> 下的所有 <code>Node</code> 指定属性新建全文索引。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> (<span class="type">Transaction</span> <span class="variable">tx</span> <span class="operator">=</span> database.beginTx()) &#123;</span><br><span class="line">    Map&lt;String, String&gt; config = <span class="keyword">new</span> <span class="title class_">stringMap</span>(IndexManager.PROVIDER, <span class="string">&quot;luence&quot;</span>, <span class="string">&quot;type&quot;</span>, <span class="string">&quot;fulltext&quot;</span>, <span class="string">&quot;analyzer&quot;</span>, IKAnalyzer.class.getName());</span><br><span class="line">    IndexManager index= database.index();</span><br><span class="line">    Index&lt;Node&gt; newFullTextIndex = index.forNodes(<span class="string">&quot;FullTextIndex&quot;</span>, config);</span><br><span class="line">    ResourceIterator&lt;Node&gt; nodes = database.findNodes(DynamicLabel.label(LabelName));</span><br><span class="line">    <span class="keyword">while</span> (nodes.hasNext()) &#123;</span><br><span class="line">        <span class="type">Node</span> <span class="variable">node</span> <span class="operator">=</span> nodes.next();</span><br><span class="line">        <span class="type">Object</span> <span class="variable">text</span> <span class="operator">=</span> node.getProperty(<span class="string">&quot;text&quot;</span>, <span class="literal">null</span>);</span><br><span class="line">        newFullTextIndex.add(node, <span class="string">&quot;text&quot;</span>, text);</span><br><span class="line">    &#125;</span><br><span class="line">    tx.success();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><hr><h3 id="Docker-部署-Neo4j"><a href="#Docker-部署-Neo4j" class="headerlink" title="Docker 部署 Neo4j"></a><code>Docker</code> 部署 <code>Neo4j</code></h3><h4 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h4><p>默认情况下 <code>Neo4j</code> 的镜像开放了三个用于远程访问的端口：</p><ul><li><code>7474</code> 用于 <code>HTTP</code> 协议。</li><li><code>7473</code> 用于 <code>HTTPS</code> 协议。</li><li><code>7687</code> 用于 <code>BOLT</code> 协议。</li></ul><p>此外还指定了两个位置用于存放数据文件和日志文件：</p><ul><li><code>/data</code> 用于数据库在容器的外部持久化。</li><li><code>/logs</code> 用于允许访问 <code>Neo4j</code> 的日志文件。</li></ul><p>在 <code>Docker</code> 中运行 <code>Neo4j</code>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --publish=7474:7474 --publish=7687:7687 --volume=$HOME/neo4j/data:/data --volume=$HOME/neo4j/logs:/logs neo4j:3.1</span><br></pre></td></tr></table></figure><p><small>可通过 <code>-env NEO$J_AUTH=neo4j/&lt;password&gt;</code> 指令设置容器的登录密码。</small></p><h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><p>有三种方式可以修改 <code>Neo4j</code> 容器的配置：</p><ul><li>设置环境变量。</li><li>指定 <code>/conf</code> 存储位置。</li><li>构建新的镜像。</li></ul><ol><li><p>环境变量</p><ul><li><code>NEO4J_AUTH</code>：控制身份验证。</li><li><code>NEO4J_dbms_memory_pagecache_size</code>：本地内存缓存的大小。</li><li><code>NEO4J_dbms_memory_heap_maxSize</code>：堆大小。</li><li><code>NEO4J_dbms_txLog_rotation_retentionPolicy</code>：保留逻辑日志的大小。</li><li><code>NEO4J_dbms_allowFormatMigration</code>：是否启用升级。</li><li><code>NEO4J_dbms_mode</code>：数据库模式。</li><li><code>NEO4J_causalClustering_expectedCoreClusterSize</code>：启动时的集群初始大小。</li><li><code>NEO4J_causalClustering_initialDiscoveryMembers</code>：集群核心成员的初始网络地址&#x2F;端口号。</li><li><code>NEO4J_causalClustering_discoveryAdvertisedAddress</code>：成员发现地址&#x2F;端口号。</li><li><code>NEO4J_causalClustering_transactionAdvertisedAddress</code>：广播事务处理地址&#x2F;端口号。</li><li><code>NEO4J_causalClustering_raftAdvertisedAddress</code>：广播集群通信地址&#x2F;端口号。</li><li><code>NEO4J_ha_serverId</code>：服务器的唯一标识。</li><li><code>NEO4J_ha_host_corrdination</code>：<code>HA</code> 模式下集群协调通信的地址。</li><li><code>NEO4J_ha_host_data</code>：<code>HA</code> 模式下用于数据传输的地址。</li><li><code>NEO4J_ha_initialHosts</code>：集群的其他成员的地址&#x2F;端口列表。</li></ul></li><li><p><code>/conf</code> 配置文件配置<br><code>/conf</code> 中的配置都会覆盖镜像中的配置文件，包括已经生效的、为容器提供环境变量。如果要修改文件中的一个值则必须保证其他部分都是正确的。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --detach --publish=7474:7474 --publish=7687:7687 --volume=$HOME/neo4j/data:/data --volume=$HOME/neo4j/logs:/logs --volume=$HOME/neo4j/conf:/conf neo4j:3.1</span><br></pre></td></tr></table></figure></li><li><p>因果集群<br>每个容器必须有一个与其他容器通信的网路路由，核心服务器必须要设置 <code>NEO4J_causalClustering_initialDiscoveryMembers</code> 和 <code>NEO4J_causalClustering_scpectedCoreClusterSize</code>，而只读副本则只需要设置 <code>NEO4J_causalClustering_initialDiscoveryMembers</code>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">docker network create --driver=bridge cluster</span><br><span class="line">docker run --name=core1 --detach --network=cluster --publish=7474:7474 --publish=7687:7687 --env=NEO4J_dbms_mode=CORE --env=NEO4J_causalClustering_scpectedCoreClusterSize=3 \</span><br><span class="line">    --env=NEO4J_causalClustering_initialDiscoveryMembers=core1:5000,core2:5000.core3:5000 neo4j:3.1-enterprise</span><br><span class="line">docker run --name=core2 --detach --network=cluster --env=NEO4J_dbms_mode=CORE --env=NEO4J_causalClustering_scpectedCoreClusterSize=3 \</span><br><span class="line">    --env=NEO4J_causalClustering_initialDiscoveryMembers=core1:5000,core2:5000.core3:5000 neo4j:3.1-enterprise</span><br><span class="line">docker run --name=core3 --detach --network=cluster --env=NEO4J_dbms_mode=CORE --env=NEO4J_causalClustering_scpectedCoreClusterSize=3 \</span><br><span class="line">    --env=NEO4J_causalClustering_initialDiscoveryMembers=core1:5000,core2:5000.core3:5000 neo4j:3.1-enterprise</span><br></pre></td></tr></table></figure></li><li><p>高可用性集群<br>运行高可用性集群则每个容器必须具有可以连接到其他容器的网络路由 <code>NEO4J_ha_host_corrdination</code> 和 <code>NEO4J_ha_host_data</code> 和 <code>NEO4J_ha_initialHosts</code>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">docker network create --driver=bridge cluster</span><br><span class="line">docker run --name=instance1 --detach --network=cluster --hostname=instance1 --publish=7474:7474 --publish=7687:7687 --volume=$HOME/neo4j/logs:/logs --env=NEO4J_dbms_mode=CORE \</span><br><span class="line">    --env=NEO4J_ha_host_corrdination=HA --env=NEO4J_ha_serverId=1 --env=NEO4J_ha_host_corrdination=insatnce1:5001 --env=NEO4J_ha_host_data=instance1:6001 \</span><br><span class="line">    --env=NEO4J_ha_initialHosts=instance1:5001,instance2:5001,instance3:5001 neo4j:3.1-enterprise</span><br><span class="line">docker run --name=instance2 --detach --network=cluster --hostname=instance2 --publish=7474:7474 --publish=7687:7687 --volume=$HOME/neo4j/logs:/logs --env=NEO4J_dbms_mode=CORE \</span><br><span class="line">    --env=NEO4J_ha_host_corrdination=HA --env=NEO4J_ha_serverId=2 --env=NEO4J_ha_host_corrdination=insatnce2:5001 --env=NEO4J_ha_host_data=instance2:6001 \</span><br><span class="line">    --env=NEO4J_ha_initialHosts=instance1:5001,instance2:5001,instance3:5001 neo4j:3.1-enterprise</span><br><span class="line">docker run --name=instance3 --detach --network=cluster --hostname=instance3 --publish=7474:7474 --publish=7687:7687 --volume=$HOME/neo4j/logs:/logs --env=NEO4J_dbms_mode=CORE \</span><br><span class="line">    --env=NEO4J_ha_host_corrdination=HA --env=NEO4J_ha_serverId=3 --env=NEO4J_ha_host_corrdination=insatnce3:5001 --env=NEO4J_ha_host_data=instance3:6001 \</span><br><span class="line">    --env=NEO4J_ha_initialHosts=instance1:5001,instance2:5001,instance3:5001 neo4j:3.1-enterprise</span><br></pre></td></tr></table></figure></li><li><p>使用 <code>Cypher-Shell</code><br><code>Cypher-Shell</code> 可以在容器内使用以下命令在本地运行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec --interactive --tty &lt;container&gt; bin/cypher-shell</span><br></pre></td></tr></table></figure></li></ol><hr><h3 id="Neo4j-与图计算"><a href="#Neo4j-与图计算" class="headerlink" title="Neo4j 与图计算"></a><code>Neo4j</code> 与图计算</h3><p><code>Apache Spark</code> 是一种集群内数据处理的解决方案，可以轻松地在多个机器上进行大规模数据处理，此外还有 <code>GraphX</code> 和 <code>GraphFrames</code> 两个框架，可以专门用于对数据进行图计算操作。<br><code>Spark</code> 可以与 <code>Neo4j</code> 搭配进行外部数据处理解决方案，处理过程如下：</p><ul><li>所需要分析的子图从 <code>Neo4j</code> 导出到 <code>Spark</code>。</li><li>利用 <code>Spark</code> 集群进行图计算。</li><li>将计算结果返回到 <code>Neo4j</code> 中。</li><li>用 <code>Cypher</code> 语言或者其他操作工具进行查询。</li></ul><h4 id="Neo4j-Spark-Connector"><a href="#Neo4j-Spark-Connector" class="headerlink" title="Neo4j-Spark-Connector"></a><code>Neo4j-Spark-Connector</code></h4><p><code>Neo4j-Spark-Connector</code> 使用二进制 <code>Bolt</code> 协议从 <code>Neo4j</code> 中导入和导出数据，同时提供了 <code>Spark-2.0</code> 的 <code>RDD</code>、<code>DataFrame</code>、<code>GraphX Graph</code> 和 <code>GraphFrames</code> 等，可以自由地选择如何使用 <code>Spark</code> 处理数据。<br>一般的分析过程如下：</p><ul><li>创建 <code>org.neo4j.spark.Neo4j(sc)</code>。</li><li>设置 <code>cypher(query, [params], nodes(query, [params]), rels(query, [params])</code> 作为直接查询或者 <code>pattern(&quot;Label&quot;, Seq(&quot;REL&quot;), &quot;Label2&quot;)</code> 或 <code>pattern((&quot;Label1&quot;, &quot;prop1&quot;), (&quot;REL&quot;, &quot;prop&quot;), (&quot;Label2&quot;, &quot;prop2&quot;))</code>。</li><li>为并行计算定义 <code>partitions(n), batch(size), rows(count)</code>。</li><li>选择返回的数据类型。<ul><li><code>loadRowRdd, loadNodeRdds, loadRelRdd, loadRdd[T]</code></li><li><code>loadDataFrame, loadDataFrame(schema)</code></li><li><code>loadGraph[VD, ED]</code></li><li><code>loadGraphFrame[VD, ED]</code></li></ul></li></ul><p>下面实现一个简单地从 <code>Neo4j</code> 中加载数据并且使用 <code>Spark</code> 分析的流程：</p><ol><li><p>在 <code>Neo4j</code> 中添加数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">UNWIND range(1, 100) as id</span><br><span class="line">CREATE (p:Person &#123;id: id&#125;) WITH collect(p) as people</span><br><span class="line">UNWIND people as p1</span><br><span class="line">UNWIND range(1, 10) as friend</span><br><span class="line">WITH p1, people[(p1.id + friend) % size(people)] as p2</span><br><span class="line">CREATE (p1)-&gt;[:KNOWS &#123;years: abs(p2.id - p1.id)&#125;]-&gt;(p2)</span><br></pre></td></tr></table></figure></li><li><p>在 <code>Spark</code> 中配置 <code>Neo4j</code> 的连接方式</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">spark.neo4j.bolt.url = bolt://&lt;host&gt;:&lt;port&gt;</span><br><span class="line">spark.neo4j.bolt.user = &lt;username&gt;</span><br><span class="line">spark.neo4j.bolt.password = &lt;password&gt;</span><br></pre></td></tr></table></figure></li><li><p>打开 <code>Spark</code> 添加 <code>jar</code> 包</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-shell --packages neo4j-contrib:neo4j-spark-connector:2.0.0-M2</span><br></pre></td></tr></table></figure><p><small>如果还需要添加其他依赖的 <code>jar</code> 包，在后面依次添加即可，用逗号分隔。</small></p></li><li><p>加载数据转换为 <code>Spark</code> 的 <code>RDD</code> 类型</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import org.neo4j.spark._</span><br><span class="line">val neo = Neo4j(sc)</span><br><span class="line">val rdd = neo.cypher(&quot;MATCH (n:Person) RETURN id(n) as id&quot;).loadRowRdd</span><br><span class="line">rdd.count // 1000</span><br><span class="line">rdd.first.schema.fieldNames // [&quot;id&quot;] </span><br><span class="line">rdd.first.schema(&quot;id&quot;) // StructField(id, LongType, true)</span><br><span class="line">neo.cypher(&quot;MATCH (n:Person) WHERE n.id &lt;= &#123;maxId&#125; RETURN n.id&quot;).param(&quot;maxId&quot;, 10).loadRowRdd.count // 10</span><br><span class="line">// 设置分区和批处理大小</span><br><span class="line">neo.nodes(&quot;MATCH (n:Person) RETURN id(n) SKIP &#123;_skip&#125; LIMIT &#123;_limit&#125;&quot;).partitions(4).batch(25).loadRowRdd.count // 100 == 4 * 25</span><br><span class="line">// 通过 pattern 加载数据</span><br><span class="line">neo.pattern(&quot;Person&quot;, Seq(&quot;KNOWS&quot;), &quot;Person&quot;).rows(80).batch(21).loadNodeRdds.count // 80</span><br><span class="line">// 通过 pattern 加载关系</span><br><span class="line">neo.pattern(&quot;Person&quot;, Seq(&quot;KNOWS&quot;), &quot;Person&quot;).partitions(12).batch(100).loadRelRdds.count // 1000</span><br></pre></td></tr></table></figure></li><li><p>加载数据转换为 <code>Spark</code> 的 <code>DataFrame</code> 类型</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import org.neo4j.spark._</span><br><span class="line">val neo = Neo4j(sc)</span><br><span class="line">neo.nodes(&quot;MATCH (n:Person) RETURN id(n) as id SKIP &#123;_skip&#125; LIMIT &#123;_limit&#125;&quot;).partitions(4).batch(25).loadDataFrame.count</span><br><span class="line">var df = neo.pattern(&quot;Person&quot;, Seq(&quot;KNOWS&quot;), &quot;Person&quot;).rows(12).batch(100).loadDataFrame // [id: gigint]</span><br></pre></td></tr></table></figure></li><li><p>加载数据转换为 <code>Spark</code> 的 <code>GraphX Graph</code> 类型</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import org.neo4j.spark._</span><br><span class="line">import org.apache.spark.graphx._</span><br><span class="line">import org.apache.spark.graphx.lib._</span><br><span class="line">val neo = Neo4j(sc)</span><br><span class="line">val graphQuery = &quot;MATCH (n:Person)-[:KNOWS]-(m:Person) RETURN id(n) as source, id(m) as target, type(r) as value SKIP &#123;_skip&#125; LIMIT &#123;_limit&#125;&quot;</span><br><span class="line">val graph: Graph[Long, String] = neo.rels(graphQuery).partitions(7).batch(200).loadGraph</span><br><span class="line">graph.vertices.count // 100</span><br><span class="line">graph.edges.count // 1000</span><br><span class="line">// 通过 pattern 加载 graph</span><br><span class="line">val graph = neo.patttern((&quot;Person&quot;, &quot;id&quot;), (&quot;KNOWS&quot;, &quot;since&quot;), (&quot;Person&quot;. &quot;id&quot;)).partitions(7).batch(200).loadGraph[Long, Long]</span><br><span class="line">val graph2 = PageRank.run(graph, 5)</span><br><span class="line">graph2.vertices.sort(_._2).take(3)</span><br></pre></td></tr></table></figure></li><li><p>加载数据转换为 <code>Spark</code> 的 <code>GraphFrames</code> 类型</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import org.neo4j.spark._</span><br><span class="line">import org.graphframes._</span><br><span class="line">val neo = Neo4j(sc)</span><br><span class="line">val graphFrame = neo.pattern((&quot;Person&quot;, &quot;id&quot;), (&quot;KNOWS&quot;, null), (&quot;Person&quot;. &quot;id&quot;)).partitions(3).rows(1000).loadGraphFrame</span><br><span class="line">graphFrame.vertices.count // 100</span><br><span class="line">graphFrame.edges.count // 1000</span><br><span class="line">val pageRankFrame = graphFrame.pageRank.maxIter(5).run()</span><br><span class="line">val ranked = pageRankFrame.vertices</span><br><span class="line">ranked.printSchema()</span><br><span class="line">val top3 = ranked.orderBy(ranked.col(&quot;pagerank&quot;).desc).take(3)</span><br></pre></td></tr></table></figure></li></ol><hr><h3 id="Neo4j-与自然语言处理"><a href="#Neo4j-与自然语言处理" class="headerlink" title="Neo4j 与自然语言处理"></a><code>Neo4j</code> 与自然语言处理</h3><p>自然语言处理技术在挖掘文本数据时使用的关键技术之一是本体的挖掘词关联。词关联在语言处理标记、解析、实体提取等自然语言处理任务中非常有用，<code>Neo4j</code> 由于其关联数据的能力，为自然语言处理中词关联的处理提供了一种新的解决方案。<br>在自然语言中最常见的词关联就是聚合关系和组合关系。</p><h4 id="计算聚合相关性"><a href="#计算聚合相关性" class="headerlink" title="计算聚合相关性"></a>计算聚合相关性</h4><p>计算聚合关系的基本步骤分为三步：</p><ul><li>通过一个单词的上下文表示每个单词。<br> 考虑一个简单的文档，其中包含这样的单词： <figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">My cat eats fish on Saturday.</span><br><span class="line">His dog eats turkey on Tuesday.</span><br></pre></td></tr></table></figure> 至此要分析两个词之间是否存在关联，那就需要使用一定的方法来表示给定单词的上下文。 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Right1(&quot;cat&quot;) = &#123;&quot;eats&quot;, &quot;ate&quot;, &quot;is&quot;, &quot;has&quot;, ...&#125;</span><br><span class="line">Left1(&quot;cat&quot;) = &#123;&quot;my&quot;, &quot;his&quot;, &quot;big&quot;, &quot;a&quot;, &quot;the&quot;, ...&#125;</span><br></pre></td></tr></table></figure></li><li>计算上下文相关性<br> 为了计算聚合关系的度量，可以采用相对上下文相似性的和来表示，使用 <code>Jaccard</code> 指数作为相似性的度量。 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sim(&quot;Cat&quot;, &quot;Dog&quot;) = Sim(Left1(&quot;Cat&quot;), Left1(&quot;Dog&quot;)) + Sim(Right1(&quot;Cat&quot;), Right1(&quot;Dog&quot;))</span><br></pre></td></tr></table></figure></li><li>具有上下文高度相似性的词可能具有聚合关系<br> 一旦有了这种计算相似度的方式，就可以寻找具有高相似度的词对。其中可以通过扩大上下文窗口的大小，处理停止词来调整相似性得分。</li></ul><h4 id="将文本数据建模为邻接图"><a href="#将文本数据建模为邻接图" class="headerlink" title="将文本数据建模为邻接图"></a>将文本数据建模为邻接图</h4><p>可以将文本数据建模为邻接图，其中每个单词是一个节点，两个节点之间的边表示这些单词在文本语料库中彼此相邻。<br><img src="https://s2.loli.net/2022/05/08/KowAQnDE1r4s9xP.png" alt="neo4j-9-1.jpg"></p><h4 id="挖掘单词之间的关系"><a href="#挖掘单词之间的关系" class="headerlink" title="挖掘单词之间的关系"></a>挖掘单词之间的关系</h4><p>根据插入的数据来发现单词之间的关系。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">LEFT1_QUERY = <span class="string">&#x27;MATCH (s:Word &#123;word: &#123;word&#125;&#125;) MATCH (w:Word)-[:NEXT_WORD]-&gt;(s) RETURN w.word as word&#x27;</span></span><br><span class="line">RIGHT1_QUERY = <span class="string">&#x27;MATCH (s:Word &#123;word: &#123;word&#125;&#125;) MATCH (w:Word)&lt;-[:NEXT_WORD]-(s) RETURN w.word as word&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">left1</span>(<span class="params">word</span>):</span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">&#x27;word&#x27;</span>: word.lower()</span><br><span class="line">    &#125;</span><br><span class="line">    tx = graphdb.cypher.begin()</span><br><span class="line">    tx.append(LEFT1_QUERY, params)</span><br><span class="line">    results = tx.commit()</span><br><span class="line">    words = []</span><br><span class="line">    <span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> result:</span><br><span class="line">            words.append(line.word)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">set</span>(words)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">right1</span>(<span class="params">word</span>):</span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">&#x27;word&#x27;</span>: word.lower()</span><br><span class="line">    &#125;</span><br><span class="line">    tx = graphdb.cypher.begin()</span><br><span class="line">    tx.append(RIGHT1_QUERY, params)</span><br><span class="line">    results = tx.commit()</span><br><span class="line">    words = []</span><br><span class="line">    <span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> result:</span><br><span class="line">            words.append(line.word)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">set</span>(words)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">jaccard</span>(<span class="params">a, b</span>):</span><br><span class="line">    intSize = <span class="built_in">len</span>(a.intersection(b))</span><br><span class="line">    unionSize = <span class="built_in">len</span>(a.union(b))</span><br><span class="line">    <span class="keyword">return</span> intSize / unionSize</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">paradingSimilarity</span>(<span class="params">w1, w2</span>):</span><br><span class="line">    <span class="keyword">return</span> (jeccard(left1(w1), left1(w2)) + jaccard(right1(w1), right1(w2))) / <span class="number">2.0</span></span><br></pre></td></tr></table></figure><p>通过上面的代码我们就可以计算单词之间的相似性：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">paradingSimilarity(&quot;school&quot;, &quot;university&quot;) // 0.2153846153846154</span><br></pre></td></tr></table></figure><hr><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><hr><h3 id="个人备注"><a href="#个人备注" class="headerlink" title="个人备注"></a>个人备注</h3><p><strong>此博客内容均为作者学习所做笔记，侵删！</strong><br><strong>若转作其他用途，请注明来源！</strong> </p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;引入&quot;&gt;&lt;a href=&quot;#引入&quot; class=&quot;headerlink&quot; title=&quot;引入&quot;&gt;&lt;/a&gt;引入&lt;/h3&gt;&lt;p&gt;在之前的学习中，大致明白了 &lt;code&gt;Neo4j&lt;/code&gt; 的基本操作、程序开发、数据库管理等操作，对于一些基本的操作已经足够，而现在则是通过一些高级的使用来探索其他功能的启发。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Neo4j" scheme="https://blog.vgbhfive.cn/tags/Neo4j/"/>
    
  </entry>
  
  <entry>
    <title>Neo4j系列博客-集群</title>
    <link href="https://blog.vgbhfive.cn/Neo4j%E7%B3%BB%E5%88%97%E5%8D%9A%E5%AE%A2-%E9%9B%86%E7%BE%A4/"/>
    <id>https://blog.vgbhfive.cn/Neo4j%E7%B3%BB%E5%88%97%E5%8D%9A%E5%AE%A2-%E9%9B%86%E7%BE%A4/</id>
    <published>2022-04-04T15:22:03.000Z</published>
    <updated>2023-01-01T15:54:38.250Z</updated>
    
    <content type="html"><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>集群技术是一项在较低成本下能有效提高系统整体性能、可靠性、灵活性和可扩展性，并广泛应用于生产系统的必备技术，同样 <code>Neo4j</code> 企业版也提供了集群技术，主要分为：高可用性集群（<code>High Availablity, HA</code>）和因果集群（<code>Causal Clustering</code>）。</p><span id="more"></span><hr><h3 id="因果集群"><a href="#因果集群" class="headerlink" title="因果集群"></a>因果集群</h3><p>因果集群技术基于 <code>Raft</code> 协议开发，可支持数据中心和云所需要的大规模和多拓扑环境，其中内置了由 <code>Neo4j Bolt</code> 驱动处理的负载均衡，还支持同样由 <code>Bolt</code> 驱动管理的集群可感知会话，以此帮助开发人员解决架构上的问题。<br>因果集群的安全性改进还包括：多用户、基于角色的访问控制（读取者、发布者、架构者和管理者）、查询安全事件日志、列出并终止运行中的查询以及细粒度的访问控制等特性。</p><p><code>Neo4j</code> 因果集群主要提供以下两个特点：</p><ul><li>安全性：核心服务器为事务提供处理提供容错平台，仅有一部分核心服务器正常运行时，整个系统仍然是可用的。</li><li>可扩展性：只读副本为图查询提供了一个大规模高可扩展平台，可以在分布广泛的拓扑中执行非常大的图查询工作。</li></ul><p>以上两个特点结合起来就是允许最终用户拥有完整数据库的全部功能，并在可以在发生多个硬件或网络故障的情况下也可以正常的对数据库进行读写操作。</p><h4 id="操作视图"><a href="#操作视图" class="headerlink" title="操作视图"></a>操作视图</h4><p>从操作视图的角度来看，可以认为集群主要包括两个角色，一个是核心服务器，另一个就是只读副本。<br><img src="https://s2.loli.net/2022/04/16/6rwULljeSnQvmfM.png" alt="neo4j-8-1.jpg"></p><ol><li><p>核心服务器<br>核心服务器的主要职责就是保护数据，使用 <code>Raft</code> 协议复制所有事务来实现。<code>Raft</code> 协议能确保数据在最终用户应用程序提交事务之前是安全的。然而在实际中意味者集群中的大多数（即 <code>N/2+1</code>）核心服务器接收事务，就可以安全地提交事务到最终用户应用程序。<br>但是这种安全性对写操作有延迟影响，写操作由多数核心服务器进行确认，然而随着核心服务器数量的增长，必定会影响写操作的效率。实际上，只需要少量的核心服务器就可以为特定部署提供足够的容错能力，可以使用公式 <code>M = 2F + 1</code>，其中 <code>M</code> 是允许 <code>F</code> 个核心服务器发生故障所需的核心服务器总数。<br><small>如果核心服务器集群发生故障而无法再处理写入操作时，则核心服务器将转化为只读状态，以确保整个集群的数据安全。</small></p></li><li><p>只读副本<br>只读副本的主要职责是扩展图操作（例如 <code>Cypher</code> 查询、过程处理等）的工作负载，类似于核心服务器中受数据保护的高速缓存，当并不是简单的键值高速缓存。然而事实上，只读副本是能够完成任意只读图查询和过程处理的全功能的 <code>Neo4j</code> 数据库。<br>只读副本通过事务日志以异步的方式从核心服务器上复制数据，周期性（通常在毫秒内）地轮询核心服务器，以查找自上次轮询之后处理的新事务，然后核心服务器将新事务发送到只读副本。大量的只读副本可以从相对较少的核心服务器复制数据，从而确保大量的图查询工作负载得以均衡。<br>只读副本与核心服务器不同的在于不参与集群拓扑的决策，丢失只读副本不影响集群的可用性，除了影响图查询性能吞吐的能力之外，也不会影响集群的容错能力。</p></li></ol><h4 id="应用视图"><a href="#应用视图" class="headerlink" title="应用视图"></a>应用视图</h4><p>在应用程序中，通常从图数据库中读写数据，但是根据工作负载需要考虑读取时之前的写入，以确保因果一致性。因果一致性可以保证数据很容易写入到核心服务器，并可以从只读副本中读到这些写入的数据。<br><img src="https://s2.loli.net/2022/04/17/eiEPZCoQULDwl9Y.png" alt="neo4j-8-2.jpg"><br>在实行事务时客户端可以请求书签，然后作为下一次事务的参数，使用书签功能集群就可以确保其中的服务器只处理了客户端的书签事务之后才可以处理下一个事务，这提供了一个因果链，从客户的角度来确保行为的正确性。<br>除了书签之外剩余的工作都有集群来处理，其中主要是由数据库驱动程序与集群拓扑管理器一起完成，以选择最合适的核心服务器和只读副本来提高服务的质量。</p><h4 id="创建新的因果集群"><a href="#创建新的因果集群" class="headerlink" title="创建新的因果集群"></a>创建新的因果集群</h4><p>接下来配置具有三个核心实例的集群，三个核心实例是形成一个安全的因果集群所需的最少的服务器数量，并配备三个只读副本来提供一定的横向扩展的能力。</p><ol><li><p>下载配置<br>从官网下载企业版，然后解压到对应的机器上，接着配置每台机器的配置文件，主要配置 <code>neo4j.conf</code> 。<br>在三台独立的机器上运行 <code>Neo4j</code> 时，实现一个因果集群的最基本配置就是两个网络配置和三个集群配置。</p><ul><li><code>dbms.connection.default_listen_address</code>：本机用于监听传入消息的地址或网络接口。</li><li><code>dbms.connection.default_advertised_address</code>：告知其他机器需要连接的地址。</li><li><code>dbms.mode</code>：数据库实例的运行模式。</li><li><code>causal_clustering.excepted_core_cluster_size</code>：启动时的初始集群大小。建立集群时需要在早期就实现稳定的核心服务器资格认证，以确保集群数据的安全读写操作。</li><li><code>causal_clustering.initial_discovery_members</code>：用于引导核心服务器或只读副本去初始发现核心集群成员，该值是以逗号为分隔的地址&#x2F;端口列表。</li></ul></li><li><p>启动服务器</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/neo4j start</span><br></pre></td></tr></table></figure><p>启动成功之后，从 <code>Neo4j-shell</code> 中使用 <code>call dbms.cluster.oerview()</code> 命令来显式集群的状态和每个集群成员的信息。</p></li><li><p>添加新的核心服务器<br>添加新的核心服务器与前面的配置一样，只需要配置新添加的核心服务器的 <code>neo4j.conf</code> 配置文件并修改其他已存在的集群中的核心服务器的 <code>neo4j.conf</code> 配置文件即可。一旦重新配置完成就可以重启核心服务器，新的核心服务器也会自动加入到集群中。</p></li><li><p>设置集群领导者偏好<br>因果集群中的核心服务器使用 <code>Raft</code> 协议来保证一致性和安全性。<code>Raft</code> 协议的实现细节是它使用其他领导者角色对基础日子加以排序，其他的实例作为追随者，复制领导者的状态。在具体的实现中，这意味着对数据库的写操作是由当前为领导者角色的核心服务器来排序的。<br>相关的配置参数是 <code>neo4j.conf</code> 配置文件中的 <code>causal_clustering.refuse_to_be_leader</code>，该配置项默认为 <code>false</code>，设置为 <code>true</code> 之后表示在领导者的选举中弃权。</p></li><li><p>添加只读副本<br>添加只读副本与核心服务器类似，因为只读副本不参与集群的决策，因此配置项更少，只读副本只需要知道核心服务器的地址，以便于绑定到这些地址上正常运行发现协议，一旦完成了发现过程，只读副本就会知道核心服务器的状态，并且选择一个合适的核心服务器进行数据复制。</p></li></ol><ul><li>数据库的操作模式，必须取消注释并且设置为 <code>dbms.mode = READ_REPLICA</code>。</li><li>集群中核心实例的地址 <code>causal_clustering.initial_discovery_members</code>。</li></ul><h4 id="生命周期"><a href="#生命周期" class="headerlink" title="生命周期"></a>生命周期</h4><p>因果集群的生命周期主要包括：发现协议、加入集群、核心服务器和只读副本成员资格获取以及用于轮询、捕获和备份的协议到最后的关闭集群。</p><ol><li><p>发现协议<br>发现协议是构建集群的第一步，他提供了现有核心集群服务器的一些提示，并使用这些提示初始化网络连接协议。而在这些提示中，服务器会加入到现有集群或者形成自己的集群，但是发现协议仅支持从核心服务器到核心服务器和从只读副本到核心服务器的发现过程。<br>这个提示的具象化就是 <code>neo4j.conf</code> 配置文件中的 <code>initial_discovery_members</code> 配置项，该配置项通常为点分十进制 <code>IP</code> 地址和端口，且在执行过程中当前服务器尝试与其他列出的服务器连接，一旦连接成功即可成功加入集群的拓扑结构中。同时发现服务也会持续运行在因果集群的全生命周期，用以维持可用服务器的当前状态，还可以帮助客户端通过驱动转发请求到合适的服务器。<br><small>发现协议只针对核心服务器，而不管执行发现的是只读副本还是核心服务器。</small></p></li><li><p>核心服务器成员资格<br>若此时为核心服务器执行发现协议，则一旦与核心服务器集群建立连接，就会加入到 <code>Raft</code> 协议中去。<br><code>Raft</code> 协议处理集群成员资格的方式就是通过<strong>使其成为分布式日志同步的一部分</strong>。要想加入到 <code>Raft</code> 集群则必须将集群成员资格插入到 <code>Raft</code> 日志中，然后复制到集群的其他成员目录中，一旦该目录被应用于 <code>Raft</code> 共识组（运行 <code>Raft</code> 算法的服务器）中的大部分成员，则集群成员更新自己的集群视图以添加新加入的成员。新加入的核心服务器还必须在初始化其内部 <code>Raft</code> 实例时，从其他核心服务器获取到自己的 <code>Raft</code> 日志。<br><small>当一个实例想要加入到一个集群时，取决于集群的当前状态和它本身是否有资格加入。其资格的判定在于是否与集群成员保存有相同的数据库存储（可以是过时的数据）。</small></p></li><li><p>只读副本成员资格<br>若只读副本执行发现协议，则一旦与任何核心服务器建立连接，就会将自己加入到共享白板（<code>Shared Whiteboard</code>）中。其中共享白板实时提供所有只读副本的视图，并用于最终用户应用程序的数据库驱动程序中的请求路由和集群状态的监控。<br><small>只读副本不涉及 <code>Raft</code> 协议，也不影响集群拓扑。</small></p></li><li><p><code>Raft</code> 协议实现事务<br>一旦集群建立成功，就意味着每个核心服务器都会花时间处理数据库事务。而更新操作会通过 <code>Raft</code> 协议在核心服务器之间可靠复制，更新操作以包含事务命令的 <code>Raft</code> 日志条目的形式呈现，再作用到图数据库上。<br>因果集群中仅在核心服务器之间采用了 <code>Raft</code> 协议，并对集群中的核心服务器划分为三类角色：<code>Leader</code>（领导者，只有一个）、 <code>Follower</code>（通常多个）、 <code>Candidate</code>（候选人，通常多个）。<br><a href="https://segmentfault.com/a/1190000022398199">选举流程</a><br><code>Raft</code> 协议的事务执行过程就是在某时刻 <code>Raft Leader</code> 将事务附加到其本地日志的头部，并要求其他实例执行相同的操作。当领导者看到大多数的实例都已经附加上此条目之后，就可以将这个事务安全地提交到 <code>Raft</code> 日志中，至此就可以通知客户端应用程序事务已经安全地提交。<br><small>在任何一个 <code>Raft</code> 协议实例中，只有一个领导者能够在给定的任期内驱动协议的正常运转，领导者承担强制 <code>Raft</code> 日志排序和管理日志的责任。</small><br>追随者根据领导者的日志变化来更新自身的日志，如果集群中的任何参与者怀疑领导者出现故障，那么就可以通过进入候选者状态来发起领导者候选。其中最佳领导者的最佳状态由最长运行时间、最长日志、最高提交条目来决定。</p></li><li><p>跟踪协议<br>只读副本一方面处理图查询，另一方面处理与核心服务器事务更新的一致性。而从核心服务器到只读副本的更新是通过事务发送来传递的，事务发送由只读副本频繁轮询任意一个核心服务器，得到其接收和处理的最后一个事务编号来启动，其中轮询的频率是可以设置的。<br><small><code>Neo4j</code> 事务编号是严格递增的整数值。只读副本通过自身最后处理的事务编号与核心服务器的事务编号比较来判断该事务是否在只读副本上执行过。</small><br>如果有时候核心服务器与只读副本之间的数据差异较大时，就会直接执行回滚操作并直接将数据库内容从核心服务器复制到只读副本中。</p></li><li><p>备份协议<br>参考上一节内容中的备份。</p></li><li><p>关闭只读副本<br>只读副本正常关闭时会调用发现协议从集群的共享白板视图中删除自身，这样可以确保数据库的完全关闭和集群数据的一致性。<br>非常规关机之后，只读副本可能不再具有完全一致的存储文件和事务日志，因此在后续重新启动时，只读副本会回滚这段时间的事务，以保证数据的一致性。</p></li><li><p>关闭核心服务器<br>正常关闭核心服务器需要通过 <code>Raft</code> 协议来处理，当一个核心服务器关闭时，协议会将成员资格条目附加到 <code>Raft</code> 日志上，然后其他的核心服务器重复同样的操作，一旦大多数核心服务器都提交了成员资格条目，在逻辑上该核心服务器就可以离开集群并安全关闭。<br>而非正常关闭核心服务器不会通知集群已经离开集群，此时集群中的核心服务器数量与之前记录的一致，这样在同步事务时会更加的困难，因此在收到告警时，请在必要的时候进行人工干预。</p></li></ol><h4 id="灾备恢复"><a href="#灾备恢复" class="headerlink" title="灾备恢复"></a>灾备恢复</h4><p>灾备恢复是指把少量幸存实例从只读状态转换到可读写状态的实例组成的集群。</p><ul><li>确保已经发生数据中心丢失的风险，并且可以访问正在运行的集群中幸存的成员，然后对集群中的每个实例进行以下操作。</li><li>运行命令 <code>./bin/neo4j stop</code> 停止数据库实例。</li><li>修改 <code>neo4j.conf</code> 配置文件中的 <code>causal_clustering.initial_discovery_members</code> 参数为当前可用实例的 <code>IP</code> 地址。</li><li>更改 <code>neo4j.conf</code> 配置文件中的 <code>causal+clustering.expected_core_cluster_size = 2</code>，即有两个实例幸存。</li><li>重新启动实例 <code>./bin/neo4j start</code>。</li></ul><h4 id="其他设置"><a href="#其他设置" class="headerlink" title="其他设置"></a>其他设置</h4><ol><li><p><code>causal_clustering.raft_advertised_address</code><br>该配置项为地址&#x2F;端口对，是本机 <code>Neo4j</code> 实例向集群的其他成员通知他在核心集群内监听 <code>Raft</code> 消息的位置。</p></li><li><p><code>causal_clustering.transaction_advertised_address</code><br>值为地址&#x2F;端口对，指定本机 <code>Neo4j</code> 实例在哪里监听事务传输捕获协议中的事务请求。</p></li><li><p><code>causal_clustering.discover_listen_address</code><br>发现协议所使用的地址&#x2F;端口对。</p></li><li><p><code>causal_clustering.raft_listen_address</code><br>值为地址&#x2F;端口对，指定 <code>Neo4j</code> 实例将绑定到哪个网络地址和端口用以进行集群通信。此配置必须与 <code>causal_clustering.raft_advertised_address</code> 配置相配合，因为本机也会监听自己的 <code>causal_clustering.raft_advertised_address</code> 配置。</p></li><li><p><code>causal_clustering.transaction_listen_address</code><br>值为地址&#x2F;端口对，指定 <code>Neo4j</code> 实例将绑定到哪个网络地址和端口上进行集群通信。此配置必须与 <code>causal_clustering.transaction_advertised_address</code> 配置相配合，因为本机也会监听自己的 <code>causal_clustering.transaction_advertised_address</code> 配置。</p></li></ol><hr><h3 id="高性能集群"><a href="#高性能集群" class="headerlink" title="高性能集群"></a>高性能集群</h3><p>高可用性 <code>Neo4j</code> 集群采用了主从复制结构，优点在于硬件故障时的应变能力和容错能力和扩展 <code>Neo4j</code> 读密集型数据场景的能力。<br>弹性和容错是指即使在网络或硬件发生故障时，<code>Neo4j</code> 集群仍然可以继续提供服务的能力。这就意味着集群中的一个节点坏了，服务依旧是可用的。主从结构的另外一个好处就是能够在读密集型场景下的横向扩展能力，另外还支持缓存分区，使得集群相比单实例具有更大的负载处理能力。</p><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>一个高可用性集群由一个主实例和零个或多个从实例组成，集群中所有的实例都在其本地数据库文件中保存有集群数据的完整副本。<br><img src="https://s2.loli.net/2022/04/23/PgiSaGloAExvUn6.png" alt="neo4j-8-3.jpg"><br><small>横线箭头代表协调每个实例之间的数据复制和选举管理。斜线箭头代表集群中主实例与从实例之间保持数据库最新。</small></p><ol><li><p>仲裁实例<br>仲裁实例是一个仅在仲裁模式下运行的 <code>Neo4j</code> 实例，但是它只参与集群的通信，用于在选举出现僵局时进行仲裁，并不参与集群的其他操作（也不复制集群中的数据）。</p></li><li><p>事务传播<br>在主机上的写操作与在非集群模式下的方式一样，在主机上执行成功之后，会将该事务推送到从机上，然而如果推送中间发生异常，主机也是默认推送成功。<br>但是在从机上执行写操作时，每个写操作都是首先与主机同步，此时主机和从机都会被锁定，当事务提交时，首先在主机上提交，在主机上提交成功后才会在从机上提交。同时为了保证一致性，在执行写操作时从机和主机的状态必须完全一致，从机的自动更新协议包含在与主机的通过协议中。（写操作尽量在主机上完成）</p></li><li><p>故障恢复<br>当集群中的一个实例不可用时，集群中的其他实例将会检测到此问题并将其标记为临时故障，在该实例发生故障之后如果可以重新实现和集群同步，那么会重新加入到集群中。如果一个主机发生故障，那么稍后在集群中就会进行主机选举，如果一个从机被选中，他的角色也会由从机转变为主机，之后就会向集群中的其他成员通报自己的身份。在选举过程中的几秒钟是不能进行写操作的。</p></li><li><p>分支<br>数据分支可能由以下两种方式引起：</p></li></ol><ul><li>从机落后主机很多，然后离开或重新加入集群，这类型的分支是无害的。</li><li>重新发生了主机选举，旧的主机还有一个或多个事务未推送，这类型的分支是有害的，需要采取措施处理。</li></ul><ol start="5"><li>总结<ul><li>写入事务是可以在集群中的任何实例中执行。</li><li><code>Neo4j</code> 高可用性集群是具有容错功能的。</li><li>从机的写操作将先在主机上同步。</li><li>如果主机发生故障，着自动选出新的主机。</li><li>集群会自动处理一个实例发生故障的情况，并且在它再次可用时还可以重新加入集群中。</li><li>事务具有原子性、一致性、持久性，直到最后才会传递到从机。</li><li>如果主机关闭，那么正在运行的事务将会回滚，新事务将会阻塞或者执行失败，直至主机可用为止。</li><li>读操作的负载能力会随着集群中的数据库实例增加而增加。</li></ul></li></ol><h4 id="搭建高可用性集群"><a href="#搭建高可用性集群" class="headerlink" title="搭建高可用性集群"></a>搭建高可用性集群</h4><p>搭建高可用性集群步骤如下：</p><ul><li>每台机器上安装 <code>Neo4j</code> 企业版。</li><li>若是有需要，可以配置仲裁实例。</li><li>修改每台机器上 <code>Neo4j</code> 实例的配置文件。</li><li>安装单个实例。</li><li>修改具体的参数配置 <code>dbms.mode</code>、<code>ha.server_id</code>、<code>ha.initial_hosts</code>。</li></ul><ol><li><p>重要配置项<br>在启动 <code>Neo4j</code> 集群时，每个实例按照配置项来关联其他的实例，当一个实例需要建立到其他实例的连接时，能否加入集群取决于集群的当前状态和该实例是否有这个加入，为了保证实例具有资格加入集群，因此每个实例都必须与集群的其他成员具有相同的数据库存储，或者是没有数据库存储的全新部署。<br><small>参与到集群中的实例应该配置 <code>IP</code> 地址或主机名。</small></p><ul><li><code>dbms.mode</code> 配置数据库的操作模式，需设置为 <code>dbms.mode = HA</code>。</li><li><code>ha.server_id</code> 是每个实例的集群标识符，他必须是整数，并且必须在集群中所有的实例中保持唯一，为 <code>ha.server_id = 1</code>。</li><li><code>ha.host.coordination</code> 是指实力监听集群的端口，默认端口为 <code>5001</code>。</li><li><code>ha.ininial_hosts</code> 是用逗号隔开的地址&#x2F;端口对列表，该列表指定一个实力如何与其他的实例进行通信。当实例启动时，使用这些主机地址来查找和加入集群，当集群冷启动没有集群可用时，数据库也是不可用的，直到 <code>ha.ininial_hosts</code> 中列出的地址都在线且彼此通信才可以恢复使用。</li><li><code>ha.host.data</code> 是一个地址&#x2F;端口对设置，用来指定从机监听来自主机的事务，默认配置端口为 <code>6001</code>。<code>ha.host.data</code> 必须使用与 <code>ha.host.coordination</code> 使用不同的端口。</li></ul></li><li><p>配置文件示例</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ha.server_id = 1</span><br><span class="line">ha.initial_hosts = neo4j-01.local:5001,neo4j-02.local:5001,neo4j-03.local:5001</span><br><span class="line">dbms.mode = HA</span><br><span class="line">dbms.connector.http.enabled = true</span><br><span class="line">dbms.connector.http.listen+address:7474</span><br></pre></td></tr></table></figure></li><li><p>设置仲裁实例<br>高可用性集群的典型部署就是三台机器来提供容错和读可扩展性。至此为了防止主机不可用，可以部署仲裁实例的 <code>Neo4j</code> 实例，他也会被视为集群的一员，主要作用是用于主机的选举，但不会参与到其他的操作。<br>仲裁实例的 <code>neo4j.conf</code> 配置文件与其他实例的配置基本相同，只是将 <code>dbms.mode</code> 配置的值变为 <code>ARBITER</code>，启动和停止仲裁实例的方法也与其他实例一致。</p></li></ol><h4 id="状态信息端点"><a href="#状态信息端点" class="headerlink" title="状态信息端点"></a>状态信息端点</h4><p><code>Neo4j</code> 高可用性集群常见的操作就是将所有的写入请求定向到主机上，从机只负责读取操作，这样在集群中对读操作做到负载均衡，同时支持故障转移。<br>实现这个功能最常见的方法是在集群上加入一个负载均衡器，可以选用 <code>HA Proxy</code>（一个支持高可用性、负载均衡 <code>TCP</code> 和 <code>HTTP</code> 开源应用程序代理软件），这里的负载均衡器使用 <code>HTTP</code> 端点来发现主节点和从节点。</p><ol><li>状态端点信息<br>每个高可用性集群的实例都有关于其在集群中状态的三个端点，每个端点都是可用的，具体的状态取决于负载均衡的需求和设置。三个端点分别为：<ul><li><code>/db/manage/server/ha/master</code></li><li><code>/db/manage/server/ha/slave</code></li><li><code>/db/manage/server/ha/available</code></li></ul></li></ol><p><code>master</code> 和 <code>salve</code> 可以将写入和非写入请求引导向特定的实例。<code>available</code> 端点一般情况下会将任意请求指向可用于事务处理的实例。查询端点的状态信息，执行 <code>HTTP GET</code> 操作。</p><ol start="2"><li>状态信息端点详情<br>端点如下：<ul><li><code>/db/manage/server/ha/master</code><table><thead><tr><th>实例状态</th><th>返回状态码</th><th>正文文本</th></tr></thead><tbody><tr><td><code>Master</code></td><td><code>200 OK</code></td><td><code>true</code></td></tr><tr><td><code>Slave</code></td><td><code>404 Not Found</code></td><td><code>false</code></td></tr><tr><td><code>Unknown</code></td><td><code>404 Not Found</code></td><td><code>Unknown</code></td></tr></tbody></table></li><li><code>/db/manage/server/ha/slave</code><table><thead><tr><th>实例状态</th><th>返回状态码</th><th>正文文本</th></tr></thead><tbody><tr><td><code>Master</code></td><td><code>404 Not Found</code></td><td><code>false</code></td></tr><tr><td><code>Slave</code></td><td><code>200 OK</code></td><td><code>true</code></td></tr><tr><td><code>Unknown</code></td><td><code>404 Not Found</code></td><td><code>Unknown</code></td></tr></tbody></table></li><li><code>/db/manage/server/ha/available</code><table><thead><tr><th>实例状态</th><th>返回状态码</th><th>正文文本</th></tr></thead><tbody><tr><td><code>Master</code></td><td><code>200 OK</code></td><td><code>master</code></td></tr><tr><td><code>Slave</code></td><td><code>200 OK</code></td><td><code>salve</code></td></tr><tr><td><code>Unknown</code></td><td><code>404 Not Found</code></td><td><code>Unknown</code></td></tr></tbody></table></li></ul></li></ol><p><small><code>UNKNOWN</code> 状态表示当前 <code>Neo4j</code> 实例既不是主机也不是从机。</small></p><ol start="3"><li>运行<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#&gt; curl http://localhost:7474/db/manage/server/ha/master</span><br><span class="line">true</span><br></pre></td></tr></table></figure></li></ol><h4 id="HAProxy-负载均衡"><a href="#HAProxy-负载均衡" class="headerlink" title="HAProxy 负载均衡"></a><code>HAProxy</code> 负载均衡</h4><p>在 <code>Neo4j</code> 高可用性集群架构中，集群通常由负载均衡器管理。</p><h5 id="为-Bolt-协议配置-HAProxy"><a href="#为-Bolt-协议配置-HAProxy" class="headerlink" title="为 Bolt 协议配置 HAProxy"></a>为 <code>Bolt</code> 协议配置 <code>HAProxy</code></h5><p>在 <code>Neo4j</code> 高可用性集群的部署中，<code>HAProxy</code> 将配置两个端口其中一个用于写入操作路由到主机，另一个则用于从机读操作的负载均衡。每个应用程序都有两个驱动程序实例，一个连接到主机端口用于执行写操作，而另一个连接到从机端口用于执行读操作。</p><ol><li><p>设置通信模式和空闲超时<br>如果一个服务器或者客户端空闲超过两个小时，那么该客户端或服务器就会被断开连接。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">defaults</span><br><span class="line">modetcp</span><br><span class="line">timeout connect 30s</span><br><span class="line">timeout client 2h</span><br><span class="line">timeoutserver 2h</span><br></pre></td></tr></table></figure></li><li><p>设置写操作</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">frontend neo4j-write</span><br><span class="line">bind *:7680</span><br><span class="line">default backend current-master</span><br></pre></td></tr></table></figure></li><li><p>主机后端配置</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">backend current-master</span><br><span class="line">optionhttpchk HEAD  /db/manage/server/ha/master HTTP/1.0</span><br><span class="line">server db01 10.0.1.10:7687 check port 7474</span><br><span class="line">server db02 10.0.1.11:7687 check port 7474</span><br><span class="line">server db03 10.0.1.12:7687 check port 7474</span><br></pre></td></tr></table></figure></li><li><p>设置读连接</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">frontend neo4j-read</span><br><span class="line">bind *:7681</span><br><span class="line">default backend slaves</span><br></pre></td></tr></table></figure></li><li><p>从机的后端配置</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">backend slaves</span><br><span class="line">balance roundrobin</span><br><span class="line">option  httpchk  HEAD  /db/manage/server/ha/slave HTTP/1.0</span><br><span class="line">server db01 10.0.1.10:7687 check port 7474</span><br><span class="line">server db02 10.0.1.11:7687 check port 7474</span><br><span class="line">server db03 10.0.1.12:7687 check port 7474</span><br></pre></td></tr></table></figure></li></ol><p><small>主机的后端配置与从机的后端配置相同。</small></p><p>然后将上述的所有配置放到一个文件中，就可以得到一个基本可运行的 <code>HAProxy</code> 配置文件，它采用 <code>Bolt</code> 协议为应用程序提供负载均衡功能。</p><h5 id="为-HTTP-API-配置-HAProxy"><a href="#为-HTTP-API-配置-HAProxy" class="headerlink" title="为 HTTP API 配置 HAProxy"></a>为 <code>HTTP API</code> 配置 <code>HAProxy</code></h5><p>添加以下配置文件 <code>haproxy.cfg</code>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">global</span><br><span class="line">daemon</span><br><span class="line">maxconn 256</span><br><span class="line">defaults</span><br><span class="line">mode http</span><br><span class="line">timeout connect 5000ms</span><br><span class="line">timeout client 50000ms</span><br><span class="line">timeout server 50000ms</span><br><span class="line">frontend http-in</span><br><span class="line">bind *:80</span><br><span class="line">default_backend neo4j</span><br><span class="line">backend neo4j</span><br><span class="line">option httochk GET /db/manage/server/ha/available</span><br><span class="line">server s1 10.0.1.10:7474 maxconn 32</span><br><span class="line">server s2 10.0.1.11:7474 maxconn 32</span><br><span class="line">server s3 10.0.1.12:7474 maxconn 32</span><br><span class="line">listen admin</span><br><span class="line">bind *:8080</span><br><span class="line">stats enable</span><br></pre></td></tr></table></figure><p>使用以下方式启动</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg</span><br></pre></td></tr></table></figure><p>至此就可以通过 <code>http://ip:8080/haproxy?stats</code> 来查看状态信息。默认用户名密码为 <code>admin</code>。</p><h5 id="优化读写"><a href="#优化读写" class="headerlink" title="优化读写"></a>优化读写</h5><p><code>HAProxy</code> 支持使用 <code>HTTP</code> 响应码区分集群实例是否可用的功能，因此如果在应用程序中可以区分读请求和写请求，那么就可以使用两个独立的逻辑负载均衡器，其中一个用来将所有的写请求定向到主机，而另一个则将读请求定向到从机。在 <code>HAProxy</code> 中可以通过添加多个后端服务来构建逻辑负载均衡器。<br>下面将请求定向到从机：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">global</span><br><span class="line">daemon</span><br><span class="line">maxconn 256</span><br><span class="line">defaults</span><br><span class="line">mode http</span><br><span class="line">timeout connect 5000ms</span><br><span class="line">timeout client 50000ms</span><br><span class="line">timeout server 50000ms</span><br><span class="line">frontend http-in</span><br><span class="line">bind *:80</span><br><span class="line">default_backend neo4j-slaves</span><br><span class="line">backend neo4j-slaves</span><br><span class="line">option httochk GET /db/manage/server/ha/slave</span><br><span class="line">server s1 10.0.1.10:7474 maxconn 32 check</span><br><span class="line">server s2 10.0.1.11:7474 maxconn 32 check</span><br><span class="line">server s3 10.0.1.12:7474 maxconn 32 check</span><br><span class="line">listen admin</span><br><span class="line">bind *:8080</span><br><span class="line">stats enable</span><br></pre></td></tr></table></figure><hr><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><hr><h3 id="个人备注"><a href="#个人备注" class="headerlink" title="个人备注"></a>个人备注</h3><p><strong>此博客内容均为作者学习所做笔记，侵删！</strong><br><strong>若转作其他用途，请注明来源！</strong></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;集群技术是一项在较低成本下能有效提高系统整体性能、可靠性、灵活性和可扩展性，并广泛应用于生产系统的必备技术，同样 &lt;code&gt;Neo4j&lt;/code&gt; 企业版也提供了集群技术，主要分为：高可用性集群（&lt;code&gt;High Availablity, HA&lt;/code&gt;）和因果集群（&lt;code&gt;Causal Clustering&lt;/code&gt;）。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Neo4j" scheme="https://blog.vgbhfive.cn/tags/Neo4j/"/>
    
  </entry>
  
  <entry>
    <title>MySQL-TRUNCATE函数与truncate命令</title>
    <link href="https://blog.vgbhfive.cn/MySQL-TRUNCATE%E5%87%BD%E6%95%B0%E4%B8%8Etruncate%E5%91%BD%E4%BB%A4/"/>
    <id>https://blog.vgbhfive.cn/MySQL-TRUNCATE%E5%87%BD%E6%95%B0%E4%B8%8Etruncate%E5%91%BD%E4%BB%A4/</id>
    <published>2022-03-20T03:24:19.000Z</published>
    <updated>2022-03-21T14:31:25.939Z</updated>
    
    <content type="html"><![CDATA[<h3 id="TRUNCATE-函数"><a href="#TRUNCATE-函数" class="headerlink" title="TRUNCATE 函数"></a><code>TRUNCATE</code> 函数</h3><h4 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h4><p><code>TRUNCATE(X, D)</code> 函数是 <code>MySQL</code> 自带的一个系统函数。其中 <code>X</code> 是数值，而 <code>D</code> 是保留小数的位数。其作用就是按照小数位数，进行数值截取（此处的截取是按保留位数直接进行截取，没有四舍五入）。</p><span id="more"></span><h4 id="规则"><a href="#规则" class="headerlink" title="规则"></a>规则</h4><p>规则如下：</p><ul><li>当 <code>D</code> 大于 <code>0</code>，是对数值 <code>X</code> 的小数位数进行操作。</li><li>当 <code>D</code> 等于 <code>0</code>，是将数值 <code>X</code> 的小数部分去除，只保留整数部分。</li><li>当 <code>D</code> 小于 <code>0</code>，是将数值 <code>X</code> 的小数部分去除，并将整数部分按照 <code>D</code> 指定位数，用 <code>0</code> 替换。</li></ul><h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><ol><li><p><code>X</code> 为正数</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SELECT TRUNCATE(123.4567, 3);   # 123.456</span><br><span class="line">SELECT TRUNCATE(123.4567, 2);   # 123.45</span><br><span class="line">SELECT TRUNCATE(123.4567, 1);   # 123.4</span><br><span class="line">SELECT TRUNCATE(123.4567, 0);   # 123</span><br><span class="line">SELECT TRUNCATE(123.4567, -1);  # 120</span><br><span class="line">SELECT TRUNCATE(123.4567, -2);  # 100</span><br><span class="line">SELECT TRUNCATE(123.4567, -3);  # 0</span><br></pre></td></tr></table></figure></li><li><p><code>X</code> 为负数</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SELECT TRUNCATE(-123.4567, 3);   # -123.456</span><br><span class="line">SELECT TRUNCATE(-123.4567, 2);   # -123.45</span><br><span class="line">SELECT TRUNCATE(-123.4567, 1);   # -123.4</span><br><span class="line">SELECT TRUNCATE(-123.4567, 0);   # -123</span><br><span class="line">SELECT TRUNCATE(-123.4567, -1);  # -120</span><br><span class="line">SELECT TRUNCATE(-123.4567, -2);  # -100</span><br><span class="line">SELECT TRUNCATE(-123.4567, -3);  # 0</span><br></pre></td></tr></table></figure></li><li><p>其他示例</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">// 查询数据库的所有表的容量和索引数</span><br><span class="line">SELECT </span><br><span class="line">table_schema as &#x27;数据库&#x27;,</span><br><span class="line">sum(table_rows) as &#x27;记录数&#x27;,</span><br><span class="line">sum(truncate(data_length/1024/1024, 2)) as &#x27;数据容量(MB)&#x27;,</span><br><span class="line">sum(truncate(index_length/1024/1024, 2)) as &#x27;索引容量(MB)&#x27;,</span><br><span class="line">sum(truncate(DATA_FREE/1024/1024, 2)) as &#x27;碎片占用(MB)&#x27;</span><br><span class="line">from information_schema.tables</span><br><span class="line">where table_schema=&#x27;kalacloud_test_data&#x27;</span><br><span class="line">group by table_schema and table_name=&#x27;product_demo&#x27;</span><br><span class="line">order by sum(data_length) desc, sum(index_length) desc;</span><br></pre></td></tr></table></figure></li></ol><hr><h3 id="truncate-命令"><a href="#truncate-命令" class="headerlink" title="truncate 命令"></a><code>truncate</code> 命令</h3><h4 id="说明-1"><a href="#说明-1" class="headerlink" title="说明"></a>说明</h4><p><code>truncate</code> 的作用是清空表，只能作用于表。执行 <code>truncate</code> 语句需要 <code>drop</code> 权限，从逻辑上讲，<code>truncate table</code> 类似于 <code>delete</code> 删除所有行的语句或 <code>drop table</code> 然后再 <code>create table</code> 语句的组合。<br>其中为了实现高性能，它绕过了删除数据的 <code>DML</code> 方法，因此不支持回滚。尽管 <code>truncate table</code> 与 <code>delete</code> 类似，但是他被分类为 <code>DDL</code> 语句而不是 <code>DML</code> 语句。</p><h4 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h4><ul><li><code>truncate</code> 和 <code>drop</code> 都是 <code>DDL</code> 语句，执行后无法回滚，而 <code>delete</code> 是可以回滚的。</li><li><code>truncate</code> 是直接删除原表然后再创建一个一样的表，执行速度比 <code>delete</code> 快，而 <code>delete</code> 则是一行一行的删除记录。</li><li><code>truncate</code> 不支持使用 <code>WHERE</code> 子句，只能删除全部整体，而 <code>delete</code> 支持 <code>WHERE</code> 子句，通过执行条件来删除部分数据。</li><li><code>truncate</code> 语句只能用于表，而 <code>drop</code> 和 <code>delete</code> 可以作用于视图、表等。</li><li><code>truncate</code> 会清除表中所有的行，但表结构及其约束、索引保持不变，但 <code>drop</code> 会删除表的结构及其所依赖的约束和索引。</li><li><code>truncate</code> 会重置表的自增值，<code>delete</code> 不会。</li><li><code>truncate</code> 不会激活与表有关的删除触发器，但 <code>delete</code> 可以。</li><li><code>truncate</code> 使用后会使表和索引所占的空间恢复到初始大小，<code>delete</code> 操作不会减少表或索引所占用的空间，<code>drop</code>语句则会将表所占用的空间全部释放。</li></ul><h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><p>其语法格式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TRUNCATE TABLE table_name;</span><br></pre></td></tr></table></figure><h4 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h4><ul><li>如果想删除部分数据用 <code>delete</code> 再带上 <code>WHERE</code> 子句；如果想删除表就需要使用 <code>drop</code> ；如果想保留表而将所有数据删除且和事务无关那就用 <code>truncate</code> 即可。</li><li>如果和事务有关或者想触发 <code>trigger</code> 可以用 <code>delete</code> ；如果想整理表内部的碎片可以用 <code>truncate</code> 然后再重新插入数据。</li><li><code>truncate</code> 无法通过 <code>binlog</code> 回滚。</li><li><code>truncate</code> 会清空所有数据且执行速度很快。</li><li><code>truncate</code> 不能对有外键约束引用的表使用。</li><li>执行 <code>truncate</code> 需要 <code>drop</code> 权限，不建议给账号 <code>drop</code> 权限。</li><li>执行 <code>truncate</code> 前一定要再三检查确认，最好提前备份下表数据。</li></ul><hr><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><hr><h3 id="个人备注"><a href="#个人备注" class="headerlink" title="个人备注"></a>个人备注</h3><p><strong>此博客内容均为作者学习所做笔记，侵删！</strong><br><strong>若转作其他用途，请注明来源！</strong></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;TRUNCATE-函数&quot;&gt;&lt;a href=&quot;#TRUNCATE-函数&quot; class=&quot;headerlink&quot; title=&quot;TRUNCATE 函数&quot;&gt;&lt;/a&gt;&lt;code&gt;TRUNCATE&lt;/code&gt; 函数&lt;/h3&gt;&lt;h4 id=&quot;说明&quot;&gt;&lt;a href=&quot;#说明&quot; class=&quot;headerlink&quot; title=&quot;说明&quot;&gt;&lt;/a&gt;说明&lt;/h4&gt;&lt;p&gt;&lt;code&gt;TRUNCATE(X, D)&lt;/code&gt; 函数是 &lt;code&gt;MySQL&lt;/code&gt; 自带的一个系统函数。其中 &lt;code&gt;X&lt;/code&gt; 是数值，而 &lt;code&gt;D&lt;/code&gt; 是保留小数的位数。其作用就是按照小数位数，进行数值截取（此处的截取是按保留位数直接进行截取，没有四舍五入）。&lt;/p&gt;</summary>
    
    
    
    
    <category term="MySQL" scheme="https://blog.vgbhfive.cn/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>Neo4j系列博客-程序开发-HTTP</title>
    <link href="https://blog.vgbhfive.cn/Neo4j%E7%B3%BB%E5%88%97%E5%8D%9A%E5%AE%A2-%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91-HTTP/"/>
    <id>https://blog.vgbhfive.cn/Neo4j%E7%B3%BB%E5%88%97%E5%8D%9A%E5%AE%A2-%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91-HTTP/</id>
    <published>2022-03-17T14:16:02.000Z</published>
    <updated>2022-03-30T13:31:14.234Z</updated>
    
    <content type="html"><![CDATA[<h3 id="HTTP-API"><a href="#HTTP-API" class="headerlink" title="HTTP API"></a><code>HTTP API</code></h3><p><code>Neo4j HTTP API</code> 是专门针对跨平台操作开发出来的一套与开发平台、开发语言无关的 <code>API</code>，因为可以使用任何编程语言来调用 <code>Neo4j HTTP API</code>。</p><span id="more"></span><h4 id="流"><a href="#流" class="headerlink" title="流"></a>流</h4><p>向 <code>Neo4j HTTP API</code> 发出请求后的响应可以作为 <code>JSON</code> 流传输，从而在服务器端实现更高的性能和更低的内存开销。如果要使用流式处理，我们需要每个 <code>HTTP</code> 请求添加请求头部 <code>X-Stream:true</code>。</p><h4 id="认证和授权"><a href="#认证和授权" class="headerlink" title="认证和授权"></a>认证和授权</h4><p><code>HTTP API</code> 支持身份验证和授权，因此必须使用有效用户的用户名和密码对 <code>HTTP API</code> 的请求授权。<br>当 <code>Neo4j</code> 首次安装时，可以使用默认用户 <code>neo4j</code> 和默认密码 <code>neo4j</code> 进行身份验证。在允许访问资源之前，必须更改密码。</p><h5 id="认证"><a href="#认证" class="headerlink" title="认证"></a>认证</h5><ol><li><p>缺少认证<br>如果未提供授权头，则服务器返回错误。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">GET http://localhost:7687/db/base/</span><br><span class="line">ACCEPT: application/json;charset=UTF-8</span><br><span class="line">// 返回结果</span><br><span class="line">401: Unauthorized</span><br><span class="line">Content-Type: application/json;charset=UTF-8</span><br><span class="line">WWW-Authenticate: Basic realm=&quot;Neo4j&quot;</span><br><span class="line">&#123;</span><br><span class="line">&quot;errors&quot;: [ &#123;</span><br><span class="line">&quot;code&quot;: &quot;Neo.ClientError.Security.Unauthorized&quot;,</span><br><span class="line">&quot;message&quot;: &quot;No authentication header supplied.&quot;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>通过验证访问服务器<br>通过使用 <code>HTTP</code> 基本认证向 <code>Neo4j</code> 发送用户名和密码进行认证。请求包括授权头，其值为 <code>Basic &lt;用户名密码串&gt;</code>，其中<strong>用户名密码串</strong>是 <code>base64</code> 编码的字符串，进行 <code>base64</code> 编码前的格式为<strong>用户名:密码</strong>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">GET http://localhost:7474/user/neo4j</span><br><span class="line">ACCEPT: application/json;charset=UTF-8</span><br><span class="line">Authentication: Basic bmVvNGo6c2VjcmV0</span><br><span class="line">// 返回结果</span><br><span class="line">200: OK</span><br><span class="line">Content-Type: application/json;charset=UTF-8</span><br><span class="line">&#123;</span><br><span class="line">&quot;password_change_required&quot;: false,</span><br><span class="line">&quot;password_change&quot;: &quot;http://localhost:7474/user/neo4j/password&quot;,</span><br><span class="line">&quot;username&quot;: &quot;neo4j&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>授权出错<br>如果提供的用户名或密码不正确，则服务器返回错误。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">GET http://localhost:7474/db/data/</span><br><span class="line">ACCEPT: application/json;charset=UTF-8</span><br><span class="line">Authentication: Basic bmVvNGo6c2VjcmV0</span><br><span class="line">// 返回结果</span><br><span class="line">401: Unauthorized</span><br><span class="line">Content-Type: application/json;charset=UTF-8</span><br><span class="line">WWW-Authenticate: Basic realm=&quot;Neo4j&quot;</span><br><span class="line">&#123;</span><br><span class="line">&quot;errors&quot;: [ &#123;</span><br><span class="line">&quot;code&quot;: &quot;Neo.ClientError.Security.Unauthorized&quot;,</span><br><span class="line">&quot;message&quot;: &quot;No authentication header supplied.&quot;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>修改密码<br>在某些情况下，比如第一次访问 <code>Neo4j</code> 时，用户将需要选择一个新的密码，数据库会发出需要新密码并拒绝访问的响应。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">GET http://localhost:7474/db/data/</span><br><span class="line">ACCEPT: application/json;charset=UTF-8</span><br><span class="line">Authentication: Basic bmVvNGo6c2VjcmV0</span><br><span class="line">// 返回结果</span><br><span class="line">403: Forbidden</span><br><span class="line">Content-Type: application/json;charset=UTF-8</span><br><span class="line">WWW-Authenticate: Basic realm=&quot;Neo4j&quot;</span><br><span class="line">&#123;</span><br><span class="line">&quot;password_change&quot;: &quot;http://localhost:7474/user/neo4j/password&quot;,</span><br><span class="line">&quot;errors&quot;: [ &#123;</span><br><span class="line">&quot;code&quot;: &quot;Neo.ClientError.Security.Unauthorized&quot;,</span><br><span class="line">&quot;message&quot;: &quot;No authentication header supplied.&quot;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h5 id="用户状态和密码更改"><a href="#用户状态和密码更改" class="headerlink" title="用户状态和密码更改"></a>用户状态和密码更改</h5><ol><li><p>查看用户状态<br>在首次使用默认密码登录时，用户状态将指示用户密码需要更改。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">GET http://localhost:7474/user/neo4j</span><br><span class="line">ACCEPT: application/json;charset=UTF-8</span><br><span class="line">Authentication: Basic bmVvNGo6c2VjcmV0</span><br><span class="line">// 返回结果</span><br><span class="line">200: Ok</span><br><span class="line">Content-Type: application/json;charset=UTF-8</span><br><span class="line">&#123;</span><br><span class="line">&quot;password_change_required&quot;: true,</span><br><span class="line">&quot;password_change&quot;: &quot;http://localhost:7474/user/neo4j/password&quot;,</span><br><span class="line">&quot;username&quot;: &quot;neo4j&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>修改用户密码<br>假设直到当前用户名密码，可以要求服务器更改用户密码。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">POSt http://localhost:7474/user/neo4j/password</span><br><span class="line">ACCEPT: application/json;charset=UTF-8</span><br><span class="line">Authentication: Basic bmVvNGo6c2VjcmV0</span><br><span class="line">Content-Type: application/json</span><br><span class="line">&#123;</span><br><span class="line">&quot;password&quot;: &quot;secret&quot;</span><br><span class="line">&#125;</span><br><span class="line">// 返回结果</span><br><span class="line">200: Ok</span><br></pre></td></tr></table></figure></li><li><p>禁用身份验证和授权时的访问<br>当禁用身份验证和授权时，可以在没有授权标头的情况下发送 <code>HTTP API</code> 请求。</p></li><li><p>将安全配置从一个实例复制到另一个实例<br>用户名和密码组合对每个 <code>Neo4j</code> 实例都是仅限于本地的。</p></li></ol><h4 id="请求中使用事务"><a href="#请求中使用事务" class="headerlink" title="请求中使用事务"></a>请求中使用事务</h4><p><code>Neo4j</code> 的事务 <code>HTTP API</code> 允许在事务范围内执行一系列 <code>Cypher</code> 语句。事务可以在多个不同的 <code>HTTP</code> 请求中保持打开状态，直到客户端选择提交或者回滚。每个 <code>HTTP</code> 请求包括待执行的 <code>Cypher</code> 语句列表，通常情况下可以用事务来提交 <code>Cypher</code> 语句。<br>服务器对提交的事务有时间限制。如果在超时时限内事务的请求没有回应，则服务器将会回滚此事务。可以在服务器配置中配置超时时长，方法是将 <code>dbms.transaction_timeout</code> 设置为超时前的秒数，默认超时为 <code>60</code> 秒。<br>当请求失败时，事务将回滚。通过检查事务密钥是否存在可以确定事务是否仍然处于打开状态。<br>事务不会在 <code>HA (High Availability)</code> 高可用集群的成员之间共享。因此在 <code>HA</code> 集群中使用此端点，则必须确保事务的所有请求都发送到同一个 <code>Neo4j</code> 实例才行。<br>如果不需要跨多个 <code>HTTP</code> 请求保持使用同一个事务，则可以使用单个 <code>HTTP</code> 请求来创建事务并执行语句。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">POST http://localhost:7474/db/data/transaction/commit</span><br><span class="line">ACCEPT: application/json;charset=UTF-8</span><br><span class="line">Content-Type: application/json</span><br><span class="line">&#123;</span><br><span class="line">&quot;statements&quot;: [&#123;</span><br><span class="line">&quot;statement&quot;: &quot;CREATE (n) RETURN id(n)&quot;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;</span><br><span class="line">// 返回结果</span><br><span class="line">200: Ok</span><br><span class="line">Content-Type: application/json;charset=UTF-8</span><br><span class="line">&#123;</span><br><span class="line">&quot;result&quot;: [&#123;</span><br><span class="line">&quot;columns&quot;: [&quot;id(n)&quot;],</span><br><span class="line">&quot;data&quot;: [&#123;</span><br><span class="line">&quot;row&quot;: [6],</span><br><span class="line">&quot;meta&quot;: [null]</span><br><span class="line">&#125;]</span><br><span class="line">&#125;],</span><br><span class="line">&quot;errors&quot;: []</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="执行多条语句"><a href="#执行多条语句" class="headerlink" title="执行多条语句"></a>执行多条语句</h4><p>可以在同一请求中发送多个 <code>Cypher</code> 语句，得到的响应将包含每个语句的结果。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">POST http://localhost:7474/db/data/transaction/commit</span><br><span class="line">ACCEPT: application/json;charset=UTF-8</span><br><span class="line">Content-Type: application/json</span><br><span class="line">&#123;</span><br><span class="line">&quot;statements&quot;: [&#123;</span><br><span class="line">&quot;statement&quot;: &quot;CREATE (n) RETURN id(n)&quot;</span><br><span class="line">&#125;, &#123;</span><br><span class="line">&quot;statement&quot;: &quot;CREATE (n &#123;props&#125;) RETURN n&quot;,</span><br><span class="line">&quot;parameters&quot;: &#123;</span><br><span class="line">&quot;props&quot;: &#123;</span><br><span class="line">&quot;name&quot;: &quot;My Node&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;</span><br><span class="line">// 返回结果</span><br><span class="line">200: Ok</span><br><span class="line">Content-Type: application/json;charset=UTF-8</span><br><span class="line">&#123;</span><br><span class="line">&quot;result&quot;: [&#123;</span><br><span class="line">&quot;columns&quot;: [&quot;id(n)&quot;],</span><br><span class="line">&quot;data&quot;: [&#123;</span><br><span class="line">&quot;row&quot;: [2],</span><br><span class="line">&quot;meta&quot;: [null]</span><br><span class="line">&#125;]</span><br><span class="line">&#125;, &#123;</span><br><span class="line">&quot;columns&quot;: [&quot;n&quot;],</span><br><span class="line">&quot;data&quot;: [&#123;</span><br><span class="line">&quot;row&quot;: &#123;</span><br><span class="line">&quot;name&quot;: &quot;My Node&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;meta&quot;: [&#123;</span><br><span class="line">&quot;id&quot;: 3,</span><br><span class="line">&quot;type&quot;: &quot;node&quot;,</span><br><span class="line">&quot;deleted&quot;: false</span><br><span class="line">&#125;]</span><br><span class="line">&#125;]</span><br><span class="line">&#125;],</span><br><span class="line">&quot;errors&quot;: []</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="运行一个事务"><a href="#运行一个事务" class="headerlink" title="运行一个事务"></a>运行一个事务</h4><p>可以通过将多个 <code>Cypher</code> 语句发送到事务端点来创建新事务，服务器将响应发送语句的结果，以及打开的事务的位置。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">POST http://localhost:7474/db/data/transaction</span><br><span class="line">ACCEPT: application/json;charset=UTF-8</span><br><span class="line">Content-Type: application/json</span><br><span class="line">&#123;</span><br><span class="line">&quot;statements&quot;: [&#123;</span><br><span class="line">&quot;statement&quot;: &quot;CREATE (n &#123;props&#125;) RETURN n&quot;,</span><br><span class="line">&quot;parameters&quot;: &#123;</span><br><span class="line">&quot;props&quot;: &#123;</span><br><span class="line">&quot;name&quot;: &quot;My Node&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;</span><br><span class="line">// 返回结果</span><br><span class="line">201: Created</span><br><span class="line">Content-Type: application/json;charset=UTF-8</span><br><span class="line">Location: http://localhost:7474/db/data/transaction/10</span><br><span class="line">&#123;</span><br><span class="line">&quot;commit&quot;: &quot;http://localhost:7474/db/data/transaction/10/commit&quot;</span><br><span class="line">&quot;result&quot;: [&#123;</span><br><span class="line">&quot;columns&quot;: [&quot;n&quot;],</span><br><span class="line">&quot;data&quot;: [&#123;</span><br><span class="line">&quot;row&quot;: &#123;</span><br><span class="line">&quot;name&quot;: &quot;My Node&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;meta&quot;: [&#123;</span><br><span class="line">&quot;id&quot;: 10,</span><br><span class="line">&quot;type&quot;: &quot;node&quot;,</span><br><span class="line">&quot;deleted&quot;: false</span><br><span class="line">&#125;]</span><br><span class="line">&#125;]</span><br><span class="line">&#125;],</span><br><span class="line">&quot;transaction&quot;: &#123;</span><br><span class="line">&quot;expires&quot;: &quot;Thu, 02 Feb 2017 18:46:33 +0000&quot;</span><br><span class="line">&#125;</span><br><span class="line">&quot;errors&quot;: []</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="打开的事务中执行语句"><a href="#打开的事务中执行语句" class="headerlink" title="打开的事务中执行语句"></a>打开的事务中执行语句</h4><p>如果创建了一个开放的事务，可以发送多个请求，每个请求都可以执行 <code>Cypher</code> 语句。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">POST http://localhost:7474/db/data/transaction/12</span><br><span class="line">ACCEPT: application/json;charset=UTF-8</span><br><span class="line">Content-Type: application/json</span><br><span class="line">&#123;</span><br><span class="line">&quot;statements&quot;: [&#123;</span><br><span class="line">&quot;statement&quot;: &quot;CREATE (n) RETURN n&quot;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;</span><br><span class="line">// 返回结果</span><br><span class="line">200: Ok</span><br><span class="line">Content-Type: application/json;charset=UTF-8</span><br><span class="line">&#123;</span><br><span class="line">&quot;commit&quot;: &quot;http://localhost:7474/db/data/transaction/12/commit&quot;</span><br><span class="line">&quot;result&quot;: [&#123;</span><br><span class="line">&quot;columns&quot;: [&quot;n&quot;],</span><br><span class="line">&quot;data&quot;: [&#123;</span><br><span class="line">&quot;row&quot;: &#123; &#125;,</span><br><span class="line">&quot;meta&quot;: [&#123;</span><br><span class="line">&quot;id&quot;: 11,</span><br><span class="line">&quot;type&quot;: &quot;node&quot;,</span><br><span class="line">&quot;deleted&quot;: false</span><br><span class="line">&#125;]</span><br><span class="line">&#125;]</span><br><span class="line">&#125;],</span><br><span class="line">&quot;transaction&quot;: &#123;</span><br><span class="line">&quot;expires&quot;: &quot;Thu, 02 Feb 2017 18:48:33 +0000&quot;</span><br><span class="line">&#125;</span><br><span class="line">&quot;errors&quot;: []</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="重置超时事务"><a href="#重置超时事务" class="headerlink" title="重置超时事务"></a>重置超时事务</h4><p>每个事务在一段时间无任何活动后将会自动过期，则可以通过重置事务超时来防止其过期。<br>可以通过向服务器发送执行空语句的列表来保持活动请求来重置超时。此请求将刷新重置事务过期时间，并在响应的事务部分中返回事务作为 <code>RFC 1123</code> 格式化的新时间的时间戳。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">POST http://localhost:7474/db/data/transaction/12</span><br><span class="line">ACCEPT: application/json;charset=UTF-8</span><br><span class="line">Content-Type: application/json</span><br><span class="line">&#123;</span><br><span class="line">&quot;statements&quot;: []</span><br><span class="line">&#125;</span><br><span class="line">// 返回结果</span><br><span class="line">200: Ok</span><br><span class="line">Content-Type: application/json;charset=UTF-8</span><br><span class="line">&#123;</span><br><span class="line">&quot;commit&quot;: &quot;http://localhost:7474/db/data/transaction/12/commit&quot;</span><br><span class="line">&quot;result&quot;: [],</span><br><span class="line">&quot;transaction&quot;: &#123;</span><br><span class="line">&quot;expires&quot;: &quot;Thu, 02 Feb 2017 18:49:33 +0000&quot;</span><br><span class="line">&#125;</span><br><span class="line">&quot;errors&quot;: []</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="提交事务"><a href="#提交事务" class="headerlink" title="提交事务"></a>提交事务</h4><p>如果有一个开放的事务，可以提交一个请求或者可以提交其他语句以及提交事务之前的请求。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">POST http://localhost:7474/db/data/transaction/12</span><br><span class="line">ACCEPT: application/json;charset=UTF-8</span><br><span class="line">Content-Type: application/json</span><br><span class="line">&#123;</span><br><span class="line">&quot;statements&quot;: [&#123;</span><br><span class="line">&quot;statement&quot;: &quot;CREATE (n) RETURN id(n)&quot;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;</span><br><span class="line">// 返回结果</span><br><span class="line">200: Ok</span><br><span class="line">Content-Type: application/json;charset=UTF-8</span><br><span class="line">&#123;</span><br><span class="line">&quot;commit&quot;: &quot;http://localhost:7474/db/data/transaction/12/commit&quot;</span><br><span class="line">&quot;result&quot;: [&#123;</span><br><span class="line">&quot;columns&quot;: [&quot;id(n)&quot;],</span><br><span class="line">&quot;data&quot;: [&#123;</span><br><span class="line">&quot;row&quot;: &#123;5&#125;,</span><br><span class="line">&quot;meta&quot;: [null]</span><br><span class="line">&#125;]</span><br><span class="line">&#125;],</span><br><span class="line">&quot;errors&quot;: []</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="回滚事务"><a href="#回滚事务" class="headerlink" title="回滚事务"></a>回滚事务</h4><p>如果一个打开的事务，可以发送回滚请求，服务器则回滚事务。尝试在此事务中运行的任何其他语言将立即失败。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">DELETE http://localhost:7474/db/data/transaction/12</span><br><span class="line">ACCEPT: application/json;charset=UTF-8</span><br><span class="line">// 返回结果</span><br><span class="line">200: Ok</span><br><span class="line">Content-Type: application/json;charset=UTF-8</span><br><span class="line">&#123;</span><br><span class="line">&quot;result&quot;: [],</span><br><span class="line">&quot;errors&quot;: []</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="查询统计信息"><a href="#查询统计信息" class="headerlink" title="查询统计信息"></a>查询统计信息</h4><p>通过将语句的 <code>includeStats</code> 设置为 <code>true</code>，将返回统计信息。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">POST http://localhost:7474/db/data/transaction/commit</span><br><span class="line">ACCEPT: application/json;charset=UTF-8</span><br><span class="line">Content-Type: application/json</span><br><span class="line">&#123;</span><br><span class="line">&quot;statements&quot;: [&#123;</span><br><span class="line">&quot;statement&quot;: &quot;CREATE (n) RETURN id(n)&quot;,</span><br><span class="line">&quot;includeStats&quot;: true</span><br><span class="line">&#125;]</span><br><span class="line">&#125;</span><br><span class="line">// 返回结果</span><br><span class="line">200: Ok</span><br><span class="line">Content-Type: application/json;charset=UTF-8</span><br><span class="line">&#123;</span><br><span class="line">&quot;result&quot;: [&#123;</span><br><span class="line">&quot;columns&quot;: [&quot;id(n)&quot;],</span><br><span class="line">&quot;data&quot;: [&#123;</span><br><span class="line">&quot;row&quot;: &#123;4&#125;,</span><br><span class="line">&quot;meta&quot;: [null]</span><br><span class="line">&#125;],</span><br><span class="line">&quot;stats&quot;: &#123;</span><br><span class="line">&quot;contains_updates&quot;: true,</span><br><span class="line">&quot;nodes_created&quot;: 1,</span><br><span class="line">&quot;nodes_deleted&quot;: 0,</span><br><span class="line">&quot;properties_set&quot;: 0,</span><br><span class="line">&quot;relationships_created&quot;: 0,</span><br><span class="line">&quot;relationships_deleted&quot;: 0,</span><br><span class="line">&quot;labels_added&quot;: 0,</span><br><span class="line">&quot;labels_removed&quot;: 0,</span><br><span class="line">&quot;indexes_added&quot;: 0,</span><br><span class="line">&quot;indexes+removed&quot;: 0,</span><br><span class="line">&quot;constraints_added&quot;: 0,</span><br><span class="line">&quot;constraints_removed&quot;: 0</span><br><span class="line">&#125;</span><br><span class="line">&#125;],</span><br><span class="line">&quot;errors&quot;: []</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="图格式返回结果"><a href="#图格式返回结果" class="headerlink" title="图格式返回结果"></a>图格式返回结果</h4><p>当查询返回节点和关系的图结构时，可以指定<strong>图</strong>结果数据格式。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">POST http://localhost:7474/db/data/transaction/commit</span><br><span class="line">ACCEPT: application/json;charset=UTF-8</span><br><span class="line">Content-Type: application/json</span><br><span class="line">&#123;</span><br><span class="line">&quot;statements&quot;: [&#123;</span><br><span class="line">&quot;statement&quot;: &quot;CREATE (n &#123;&quot;name&quot;: &quot;node&quot;&#125;) RETURN id(n)&quot;,</span><br><span class="line">&quot;resultDataContents&quot;: [&quot;row&quot;, &quot;graph&quot;]</span><br><span class="line">&#125;]</span><br><span class="line">&#125;</span><br><span class="line">// 返回结果</span><br><span class="line">200: Ok</span><br><span class="line">Content-Type: application/json;charset=UTF-8</span><br><span class="line">&quot;result&quot;: [&#123;</span><br><span class="line">&quot;columns&quot;: [&quot;n&quot;],</span><br><span class="line">&quot;data&quot;: [&#123;</span><br><span class="line">&quot;row&quot;: [],</span><br><span class="line">&quot;meta&quot;: [],</span><br><span class="line">&quot;graph&quot;: []</span><br><span class="line">&#125;],</span><br><span class="line">&#125;],</span><br><span class="line">&quot;errors&quot;: []</span><br></pre></td></tr></table></figure><h4 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h4><p>针对事务端点的任何请求，其结果都将返回给客户端。因此当服务器发送 <code>HTTP</code> 状态代码时，服务器并不知道请求是否成功。因此对事务端点的所有请求都将返回 <code>200</code> 或 <code>201</code> 状态代码，而不管语句是否已经成功执行。在返回的响应内容的末尾，服务器将返回执行语句时发生的错误列表，如果列表为空则请求已成功完成。<br>在执行语句时如果发生任何错误，服务器将回滚事务。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">POST http://localhost:7474/db/data/transaction/12/commit</span><br><span class="line">ACCEPT: application/json;charset=UTF-8</span><br><span class="line">Content-Type: application/json</span><br><span class="line">&#123;</span><br><span class="line">&quot;statements&quot;: [&#123;</span><br><span class="line">&quot;statement&quot;: &quot;This is not a valid statement.&quot;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;</span><br><span class="line">// 返回结果</span><br><span class="line">200: Ok</span><br><span class="line">Content-Type: application/json;charset=UTF-8</span><br><span class="line">&#123;</span><br><span class="line">&quot;result&quot;: [],</span><br><span class="line">&quot;errors&quot;: [&#123;</span><br><span class="line">&quot;code&quot;: &quot;Neo.ClientError.Statement.SyntaxError&quot;,</span><br><span class="line">&quot;mesage&quot;: &quot;Invalid input&quot;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="在事务中处理错误"><a href="#在事务中处理错误" class="headerlink" title="在事务中处理错误"></a>在事务中处理错误</h4><p>当请求中出现错误时，服务器事务将会回滚。通过检查返回的响应中是否存在事务键，可以判断事务是否仍然打开。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">POST http://localhost:7474/db/data/transaction/12</span><br><span class="line">ACCEPT: application/json;charset=UTF-8</span><br><span class="line">Content-Type: application/json</span><br><span class="line">&#123;</span><br><span class="line">&quot;statements&quot;: [&#123;</span><br><span class="line">&quot;statement&quot;: &quot;This is not a valid statement.&quot;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;</span><br><span class="line">// 返回结果</span><br><span class="line">200: Ok</span><br><span class="line">Content-Type: application/json;charset=UTF-8</span><br><span class="line">&#123;</span><br><span class="line">&quot;commit&quot;: &quot;http://localhost:7474/db/data/transaction/12/commit&quot;</span><br><span class="line">&quot;result&quot;: [],</span><br><span class="line">&quot;errors&quot;: [&#123;</span><br><span class="line">&quot;code&quot;: &quot;Neo.ClientError.Statement.SyntaxError&quot;,</span><br><span class="line">&quot;mesage&quot;: &quot;Invalid input&quot;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h3 id="其他开发技术"><a href="#其他开发技术" class="headerlink" title="其他开发技术"></a>其他开发技术</h3><h4 id="Spring-Data-Neo4j"><a href="#Spring-Data-Neo4j" class="headerlink" title="Spring-Data-Neo4j"></a><code>Spring-Data-Neo4j</code></h4><p><code>Spring-Data-Neo4j</code> 集成了 <code>Neo4j-OGM</code> 库，提供快速全面的对象图映射，此外还提供对 <code>Spring</code> 转换、事务处理、 <code>Spring</code> 数据存储库、 <code>Spring</code> 数据 <code>REST</code> 和 <code>Spring-Boot</code> 的支持。</p><ol><li><p>添加依赖</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.data<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-data-neo4j<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>&#123;spring-data-neo4j-version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>配置代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@EnableNeo4jRepositories(&quot;org.neo4j.cineasts.repository&quot;)</span></span><br><span class="line"><span class="meta">@EnableTransactionManagement</span></span><br><span class="line"><span class="meta">@ComponentScane(&quot;org.neo4j.cineasts&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PersistenceContext</span> <span class="keyword">extends</span> <span class="title class_">Neo4jConfiguration</span> &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> SessionFactory <span class="title function_">getSessionFactory</span><span class="params">()</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">SessionFactory</span>(<span class="string">&quot;org.neo4j.cineasts.domain&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure></li><li><p>创建实体类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@NodeEntity</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Movie</span> &#123;</span><br><span class="line"><span class="meta">@GraphId</span></span><br><span class="line"><span class="type">long</span> id;</span><br><span class="line">String title;</span><br><span class="line">Person director;</span><br><span class="line"><span class="meta">@Relationship(type=&quot;ACTED_IN&quot;, direction=Relationship.INCOMING)</span></span><br><span class="line">Set&lt;Person&gt; actors = <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>声明 <code>repository</code> 接口</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> <span class="title class_">MovieRepository</span> <span class="keyword">extends</span> <span class="title class_">GraphRepository</span>&lt;Movie&gt; &#123;</span><br><span class="line"><span class="meta">@Query(&quot;MATCH (m:Movie)&lt;-[rating:RATED]-(user) WHERE id(m) = &#123;movieId&#125; RETURN rating&quot;)</span></span><br><span class="line">Iterable&lt;Rating&gt; <span class="title function_">getRatings</span><span class="params">(<span class="meta">@Param</span> Long movieId)</span>;</span><br><span class="line"></span><br><span class="line">List&lt;Movie&gt; <span class="title function_">findByTitle</span><span class="params">(String title)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>装配 <code>repository</code> 实例</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Autowired</span></span><br><span class="line">MovieRepository repo;</span><br><span class="line">List&lt;Movie&gt; movies = repo.findByTitle(<span class="string">&quot;The Matrix&quot;</span>);</span><br><span class="line">Iterable&lt;Rating&gt; ratings = repo.getRatings(movieId);</span><br></pre></td></tr></table></figure></li></ol><h4 id="使用-JDBC-连接-Neo4j"><a href="#使用-JDBC-连接-Neo4j" class="headerlink" title="使用 JDBC 连接 Neo4j"></a>使用 <code>JDBC</code> 连接 <code>Neo4j</code></h4><p>由于 <code>Cypher</code> 像 <code>SQL</code> 一样，是一种返回表结果的查询语言，因此可以支持 <code>JDBC API</code> 并提供 <code>Neo4j-JDBC</code> 驱动程序。驱动程序支持 <code>Neo4j 3.x</code> 的新二进制 <code>Bolt</code> 协议、事务 <code>HTTP</code> 端点和 <code>Neo4j</code> 嵌入式连接。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Connect</span></span><br><span class="line"><span class="type">Connection</span> <span class="variable">con</span> <span class="operator">=</span> DriverManager.getConnection(<span class="string">&quot;jdbc:neo4j:bolt://localhost&quot;</span>);</span><br><span class="line"><span class="comment">// Querying</span></span><br><span class="line"><span class="keyword">try</span> (<span class="type">Statement</span> <span class="variable">stmt</span> <span class="operator">=</span> con.createStatement()) &#123;</span><br><span class="line"><span class="type">ResultSet</span> <span class="variable">rs</span> <span class="operator">=</span> stmt.executeQuery(<span class="string">&quot;MATCH (n:User) RETURN n.name&quot;</span>);</span><br><span class="line"><span class="keyword">while</span> (rs.next()) &#123;</span><br><span class="line">System.out.println(rs.getString(<span class="string">&quot;n.name&quot;</span>));</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">con.close();</span><br></pre></td></tr></table></figure><h4 id="JCypher"><a href="#JCypher" class="headerlink" title="JCypher"></a><code>JCypher</code></h4><p><code>JCypher</code> 以不同的抽象级别为 <code>Neo4j</code> 提供了无缝集成的 <code>Java</code> 访问方式。在最顶层的的抽象层，<code>JCypher</code> 允许将复杂的业务域映射到图数据库。可以获得域对象或 <code>POJO</code> 的任意复杂图形，并将其直接存储到 <code>Neo4j</code> 中。不需要以任何方式修改域对象类，也不需要注解。<code>JCypher</code> 提供了一个开箱即用的默认映射。</p><hr><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><hr><h3 id="个人备注"><a href="#个人备注" class="headerlink" title="个人备注"></a>个人备注</h3><p><strong>此博客内容均为作者学习所做笔记，侵删！</strong><br><strong>若转作其他用途，请注明来源！</strong></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;HTTP-API&quot;&gt;&lt;a href=&quot;#HTTP-API&quot; class=&quot;headerlink&quot; title=&quot;HTTP API&quot;&gt;&lt;/a&gt;&lt;code&gt;HTTP API&lt;/code&gt;&lt;/h3&gt;&lt;p&gt;&lt;code&gt;Neo4j HTTP API&lt;/code&gt; 是专门针对跨平台操作开发出来的一套与开发平台、开发语言无关的 &lt;code&gt;API&lt;/code&gt;，因为可以使用任何编程语言来调用 &lt;code&gt;Neo4j HTTP API&lt;/code&gt;。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Neo4j" scheme="https://blog.vgbhfive.cn/tags/Neo4j/"/>
    
  </entry>
  
  <entry>
    <title>Neo4j系列博客-程序开发-驱动式</title>
    <link href="https://blog.vgbhfive.cn/Neo4j%E7%B3%BB%E5%88%97%E5%8D%9A%E5%AE%A2-%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91-%E9%A9%B1%E5%8A%A8%E5%BC%8F/"/>
    <id>https://blog.vgbhfive.cn/Neo4j%E7%B3%BB%E5%88%97%E5%8D%9A%E5%AE%A2-%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91-%E9%A9%B1%E5%8A%A8%E5%BC%8F/</id>
    <published>2022-03-17T14:15:52.000Z</published>
    <updated>2023-01-01T15:56:04.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="驱动包开发模式"><a href="#驱动包开发模式" class="headerlink" title="驱动包开发模式"></a>驱动包开发模式</h3><p><code>Neo4j</code> 驱动程序也为其他的语言开发了访问途径，编写使用驱动程序的应用程序实例就可以与数据库基于事务的会话。在会话中事务可以运行创建和查询数据的相关命令，也可以定义数据库模式以及监视和管理数据库。当 <code>Neo4j</code> 部署在因果集群中时，驱动程序可以处理读取和写入操作的路由。使用因果集群驱动程序还提供书签，用于保证因果一致性，也就是说应用程序可以在集群的不同成员上运行多个查询，同时保持数据的一致。 </p><p><code>Neo4j</code> 驱动程序使用 <code>Bolt</code> 协议进行通信，因果集群提供了使用驱动程序获取集群拓扑的功能，驱动程序必须具有集群感知能力才能提供路由和负载均衡。（<code>Bolt</code> 在多个版本中提供兼容）</p><span id="more"></span><h4 id="入门"><a href="#入门" class="headerlink" title="入门"></a>入门</h4><ol><li><p>使用依赖管理获得驱动</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.neo4j.driver<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>neo4j-java-driver<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>使用官方驱动包<br>每个 <code>Neo4j</code> 驱动程序都有一个用于创建驱动程序的数据库对象，步骤如下：</p><ul><li>向数据库对象请求一个新的驱动程序。</li><li>向驱动程序对象请求一个新的会话。</li><li>请求会话对象创建事务。</li><li>使用事务对象运行语句，他返回一个表示结果的对象。</li><li>处理结果。</li><li>关闭会话。</li></ul>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.neo4j.driver.v1.AuthTokens;</span><br><span class="line"><span class="keyword">import</span> org.neo4j.driver.v1.Driver;</span><br><span class="line"><span class="keyword">import</span> org.neo4j.driver.v1.GraphDatabase;</span><br><span class="line"><span class="keyword">import</span> org.neo4j.driver.v1.Record;</span><br><span class="line"><span class="keyword">import</span> org.neo4j.driver.v1.Session;</span><br><span class="line"><span class="keyword">import</span> org.neo4j.driver.v1.StatementResult;</span><br><span class="line"><span class="keyword">import</span> org.neo4j.driver.v1.Transaction;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.neo4j.driver.v1.Values.parameters;</span><br><span class="line"></span><br><span class="line"><span class="type">Driver</span> <span class="variable">driver</span> <span class="operator">=</span> GraphDatabase.driver(<span class="string">&quot;bolt://localhost:7687&quot;</span>, AuthTokens.basic(<span class="string">&quot;neo4j&quot;</span>, <span class="string">&quot;neo4j&quot;</span>));</span><br><span class="line"><span class="keyword">try</span> (<span class="type">Session</span> <span class="variable">session</span> <span class="operator">=</span> driver.session()) &#123;</span><br><span class="line"><span class="keyword">try</span> (<span class="type">Transaction</span> <span class="variable">tx</span> <span class="operator">=</span> session.beginTransaction()) &#123;</span><br><span class="line">tx.run(<span class="string">&quot;CREATE (a:Person &#123;name: &#123;name&#125;, title: &#123;title&#125;&#125;)&quot;</span>, parameters(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Arthur&quot;</span>, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;King&quot;</span>));</span><br><span class="line">tx.success();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">try</span> (<span class="type">Transaction</span> <span class="variable">tx</span> <span class="operator">=</span> session.beginTransaction()) &#123;</span><br><span class="line"><span class="type">StatementResult</span> <span class="variable">result</span> <span class="operator">=</span> tx.run(<span class="string">&quot;MATCH (a:Person) WHERE a.name = &#123;name&#125;&quot;</span> + <span class="string">&quot;RETURN a.name AS name, a.title as title&quot;</span>, parameters(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Arthur&quot;</span>));</span><br><span class="line">whiel (result.hasNext()) &#123;</span><br><span class="line"><span class="type">Record</span> <span class="variable">record</span> <span class="operator">=</span> result.next();</span><br><span class="line">System.out.println(String.format(<span class="string">&quot;%s %s&quot;</span>, record.gete(<span class="string">&quot;title&quot;</span>).asString(), record.get(<span class="string">&quot;name&quot;</span>).asString()));</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">driver.close();</span><br></pre></td></tr></table></figure></li></ol><h4 id="配置与连接"><a href="#配置与连接" class="headerlink" title="配置与连接"></a>配置与连接</h4><p>驱动程序对象实例可以在整个应用程序中跨多个线程进行全局共享，它包含一个到集群的各个成员的连接池，可以借由它执行任何操作。同时驱动程序提供 <code>Session</code> 封装了针对数据库的一个或多个工作事务的上下文。</p><h5 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h5><p>驱动程序包含一个图数据库对象，此对象提供驱动程序实例。当从数据库对象请求驱动程序实例时，需要提供 <code>URI</code> 声明 <code>Neo4j</code> 服务器的协议、主机和端口。<br>其中 <code>URI</code> 分为两种分为直接 <code>URI</code> 和路由 <code>URI</code>。其中直接 <code>URI</code> 用于连接单个实例，如果应用程序依赖路由和负载均衡，则需要单独提供。路由 <code>URI</code> 则是用于创建支持集群的驱动程序，路由驱动程序连接到集群并处理路由和负载均衡，可以根据连接获得集群拓扑信息。</p><p><code>Bolt URI</code> 格式遵循 <code>schema://host:port</code> 的标准 <code>URI</code> 模式。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Driver</span> <span class="variable">driver</span> <span class="operator">=</span> GraphDatabase.driver(<span class="string">&quot;bolt://localhost:7687&quot;</span>, AuthTokens.basic(<span class="string">&quot;neo4j&quot;</span>, <span class="string">&quot;neo4j&quot;</span>));</span><br></pre></td></tr></table></figure><p>创建驱动程序应用时需要传递一个 <code>URI</code> 当作初始化参数来连接服务器，如果没有服务器可用在该 <code>URI</code> 响应，则抛出 <code>ServiceUnavailableException</code>，因此可以在应用实例中组装一个 <code>List</code> 循环创建连接，这样会比较可靠。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Driver <span class="title function_">acquireDriver</span><span class="params">(List&lt;String&gt; uris, AuthToken authToken, Config config)</span> &#123;</span><br><span class="line"><span class="keyword">for</span> (String uri : uris) &#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="keyword">return</span> GraphDatabase.driver(uri, authToken, config);</span><br><span class="line">&#125; <span class="keyword">catch</span> (ServiceUnavailableException e) &#123;</span><br><span class="line"><span class="comment">// This URI failed, so loop around  again if we have another</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">ServiceUnavailableException</span>(<span class="string">&quot;No valid database URI found&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h5><ol><li><p>加密和授权<br>所有 <code>Neo4j</code> 驱动程序支持使用 <code>SSL/TLS</code> 对 <code>Neo4j</code> 驱动程序和 <code>Neo4j</code> 实例之间的连接进行加密。但是在使用本地地址 <code>localhost</code> 时不会启用加密。强烈建议使用加密功能以保护 <code>Neo4j</code> 中存储的身份验证凭据和数据。</p></li><li><p>加密<br>驱动程序可以通过配置来打开或关闭 <code>TLS</code> 加密。建议只应在可信的内部网络中关闭加密。虽然大部分驱动程序默认启用加密，但最好时明确配置为使用加密。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Driver</span> <span class="variable">driver</span> <span class="operator">=</span> GraphDatabase.driver(<span class="string">&quot;bolt://localhost:7687&quot;</span>, </span><br><span class="line">AuthTokens.basic(<span class="string">&quot;neo4j&quot;</span>, <span class="string">&quot;neo4j&quot;</span>),</span><br><span class="line">Config.build().withEncryptionLevel(Config.EncryptionLevel.REQUIRED).toConfig());</span><br></pre></td></tr></table></figure></li><li><p>解密<br>当建立加密连接时，需要验证远程对等端是期望连接到的对等端。没有验证这一点则容易受到<strong>中间人</strong>攻击，欺骗获取加密连接。<br><code>Neo4j</code> 共有两种信任策略：</p><ul><li>信任第一次使用策略。指的是驱动程序将信任对主机的第一个连接是安全和有效的，在后续的连接上，驱动程序将验证他与第一个连接上的主机通信。因此请确保在可信的网络环境中建立与服务器的第一个连接。  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Driver</span> <span class="variable">driver</span> <span class="operator">=</span> GraphDatabase.driver(<span class="string">&quot;bolt://localhost:7687&quot;</span>, </span><br><span class="line">AuthTokens.basic(<span class="string">&quot;neo4j&quot;</span>, <span class="string">&quot;neo4j&quot;</span>),</span><br><span class="line">Config.build().withEncryptionLevel(Config.EncryptionLevel.REQUIRED).withTrustStrategy(Config.TrustStrategy.trustOnFirstUse(<span class="keyword">new</span> <span class="title class_">File</span>(<span class="string">&quot;/path/to/neo4j_known_hosts&quot;</span>))).toConfig());</span><br></pre></td></tr></table></figure></li><li>信任签名的证书策略。指的是为驱动程序提供信任的证书。  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Driver</span> <span class="variable">driver</span> <span class="operator">=</span> GraphDatabase.driver(<span class="string">&quot;bolt://localhost:7687&quot;</span>, </span><br><span class="line">AuthTokens.basic(<span class="string">&quot;neo4j&quot;</span>, <span class="string">&quot;neo4j&quot;</span>),</span><br><span class="line">Config.build().withEncryptionLevel(Config.EncryptionLevel.REQUIRED).withTrustStrategy(Config.TrustStrategy.trustOnFirstUse(<span class="keyword">new</span> <span class="title class_">File</span>(<span class="string">&quot;/path/to/certificate.pem&quot;</span>))).toConfig());</span><br></pre></td></tr></table></figure></li></ul></li><li><p>客户端授权<br>服务器将要求驱动程序为用户提供身份验证凭证，以便连接到数据库，除非已禁用身份验证。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Driver</span> <span class="variable">driver</span> <span class="operator">=</span> GraphDatabase.driver(<span class="string">&quot;bolt://localhost:7687&quot;</span>, </span><br><span class="line"> AuthTokens.basic(<span class="string">&quot;neo4j&quot;</span>, <span class="string">&quot;neo4j&quot;</span>),</span><br><span class="line"> Config.build().withEncryptionLevel(Config.EncryptionLevel.REQUIRED).toConfig());</span><br></pre></td></tr></table></figure></li></ol><h4 id="执行-Cypher-语句"><a href="#执行-Cypher-语句" class="headerlink" title="执行 Cypher 语句"></a>执行 <code>Cypher</code> 语句</h4><p><code>Session</code> 会话用于事务处理的轻量级容器，与 <code>Neo4j</code> 数据库的所有交互都在 <code>session</code> 中进行，每个 <code>session</code> 会话是针对数据库的一个或多个事务，同时 <code>Session</code> 可以从驱动程序对象中获取。<br>使用路由驱动程序时，可以将 <code>session</code> 会话访问模式声明为 <code>READ</code> 或 <code>WRITE</code>。驱动程序将针对所选工作模式对指定的集群成员创建会话。在通常情况下，事务可以保证从用 <code>session</code> 创建运行的语句到对于每个语句的结果处理以及任何异常都能在可控的范围内，当事务全部执行完毕后，会话将被关闭。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> (<span class="type">Transaction</span> <span class="variable">tx</span> <span class="operator">=</span> session.beginTransaction()) &#123;</span><br><span class="line">tx.run(<span class="string">&quot;CREATE (:Person &#123;name: &#x27;Guinevere&#x27;&#125;&quot;</span>);</span><br><span class="line">tx.Success();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="Session"><a href="#Session" class="headerlink" title="Session"></a><code>Session</code></h5><p><code>Session</code> 会话如同 <code>Web</code> 开发中的 <code>Session</code>，可以区分开不同的操作实例。使用 <code>driver.session</code> 方法来创建一个新的 <code>Session</code>，<code>Session</code> 会话创建是一个低资源消耗的过程，其底层原理是连接将从构建的驱动程序连接池创建 <code>Session</code>，并在关闭时返还到连接池。</p><ol><li><p>访问模式<br>当驱动程序启用路由时，需要先制定访问模式 <code>READ</code> 或者 <code>WRITE</code>。如果省略则默认使用 <code>WRITE</code> 模式。路由驱动程序将分别针对适合写入或读取的实例创建会话，如果是针对因果集群进行部署意味者驱动程序可以有效地路由读取和写入。<br>如果创建会话的实例对于声明的访问模式不可用，则会抛出 <code>SessionExpiredException</code>。</p></li><li><p>连接池<br>驱动程序具有连接池，<code>Session</code> 会话将借用连接来执行工作，当会话关闭时，<code>Session</code> 将返回到连接池。最重要的时确保会话是正确关闭的，以便结果和错误完全由客户端接收，并且 <code>Session</code> 连接可以重新使用。另外当抛出异常时 <code>Session</code> 会话将被关闭，这样可以确保执行所有操作都是稳定可靠的。</p></li></ol><h5 id="回滚事务"><a href="#回滚事务" class="headerlink" title="回滚事务"></a>回滚事务</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> (<span class="type">Transaction</span> <span class="variable">tx</span> <span class="operator">=</span> session.beginTransaction()) &#123;</span><br><span class="line">tx.run(<span class="string">&quot;CREATE (:Person &#123;name: &#123;name&#125;&#125;&quot;</span>, Values.parameters(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Merlin&quot;</span>));</span><br><span class="line">tx.failure();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="自动提交事务"><a href="#自动提交事务" class="headerlink" title="自动提交事务"></a>自动提交事务</h5><p>通常情况下事务在程序中是被明确声明的，但有些情况下 <code>Session</code> 的 <code>run</code> 方法可以隐含地自动提交需要运行语句的事务，这只出现在只读查询的情况下，因为读操作不会改变数据库内容。并且自动提交事务不支持书签功能，在调试时难以诊断故障。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">StatementResult</span> <span class="variable">result</span> <span class="operator">=</span> transaction.run(<span class="string">&quot;CREATE (person:Person &#123;name: &#123;name&#125;&#125;)&quot;</span>, Values.parameters(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Arthur&quot;</span>));</span><br><span class="line">transaction.success();</span><br></pre></td></tr></table></figure><h5 id="查询语句中的参数"><a href="#查询语句中的参数" class="headerlink" title="查询语句中的参数"></a>查询语句中的参数</h5><p>建议在查询语句始终使用参数。使用参数具有显著的性能和安全优势：</p><ul><li>参数允许查询中重复使用，使查询更加高效。</li><li>保护数据库免受 <code>Cypher</code> 注入攻击。</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">StatementResult</span> <span class="variable">result</span> <span class="operator">=</span> transaction.run(<span class="string">&quot;CREATE (person:Person &#123;name: &quot;</span>Arthur<span class="string">&quot;&#125;)&quot;</span>);</span><br><span class="line">transaction.success();</span><br></pre></td></tr></table></figure><h5 id="书签"><a href="#书签" class="headerlink" title="书签"></a>书签</h5><p>可以在 <code>Session</code> 执行操作之后创建一个书签，书签是指向某些操作的指针。当为其他相关工作创建新会话时，可以使用已经创建的书签，同时书签确保之后的操作依赖于先前的操作。无论数据是否已复制到集群的每个实例，书签都保证下一个操作会被应用于先前设置了标签的实例。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Driver</span> <span class="variable">driver</span> <span class="operator">=</span> GraphDatabase.driver(<span class="string">&quot;bolt://localhost:7687&quot;</span>, AuthTokens.basic(<span class="string">&quot;neo4j&quot;</span>, <span class="string">&quot;neo4j&quot;</span>));</span><br><span class="line">String bookmark;</span><br><span class="line"><span class="keyword">try</span> (<span class="type">Session</span> <span class="variable">session</span> <span class="operator">=</span> driver.session(AccessMode.WRITE)) &#123;</span><br><span class="line"><span class="keyword">try</span> (<span class="type">Transaction</span> <span class="variable">tx</span> <span class="operator">=</span> session.beginTransaction()) &#123;</span><br><span class="line"> tx.run(<span class="string">&quot;CREATE (a:Person &#123;name: &#123;name&#125;, title: &#123;title&#125;&#125;)&quot;</span>, Values.parameters(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Arthur&quot;</span>, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;King&quot;</span>));</span><br><span class="line"> tx.success();</span><br><span class="line"> tx.close();</span><br><span class="line"> &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line"> bookmark = session.lastBookmark();</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> bookmark;</span><br></pre></td></tr></table></figure><p>创建书签之后，在集群随后的操作中就可以使用它。<code>Session</code> 会话将会为加过书签的实例提供服务。数据的视图对于应用程序是一致的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Driver</span> <span class="variable">driver</span> <span class="operator">=</span> GraphDatabase.driver(<span class="string">&quot;bolt://localhost:7687&quot;</span>, AuthTokens.basic(<span class="string">&quot;neo4j&quot;</span>, <span class="string">&quot;neo4j&quot;</span>));</span><br><span class="line"><span class="keyword">try</span> (<span class="type">Session</span> <span class="variable">session</span> <span class="operator">=</span> driver.session()) &#123;</span><br><span class="line">StatementResult result;</span><br><span class="line"><span class="keyword">try</span> (<span class="type">Transaction</span> <span class="variable">tx</span> <span class="operator">=</span> session.beginTransaction()) &#123;</span><br><span class="line">result = tx.run(<span class="string">&quot;MATCH (a:Person) WHERE a.name = &#123;name&#125;&quot;</span> + <span class="string">&quot;RETURN a.name AS name, a.title as title&quot;</span>, Values.parameters(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Arthur&quot;</span>));</span><br><span class="line">tx.success();</span><br><span class="line">tx.close();</span><br><span class="line">whiel (result.hasNext()) &#123;</span><br><span class="line"> <span class="type">Record</span> <span class="variable">record</span> <span class="operator">=</span> result.next();</span><br><span class="line"> System.out.println(String.format(<span class="string">&quot;%s %s&quot;</span>, record.get(<span class="string">&quot;title&quot;</span>).asString(), record.get(<span class="string">&quot;name&quot;</span>).asString()));</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="返回结果"><a href="#返回结果" class="headerlink" title="返回结果"></a>返回结果</h4><h5 id="结果游标"><a href="#结果游标" class="headerlink" title="结果游标"></a>结果游标</h5><p>结果游标提供了对结果记录流的访问。游标可以不断依次指向结果集合中的每个记录。在将游标移动到第一条记录之前，他会先指向记录的起始位置。一旦游标已经遍历到结果流的末尾，就可以使用摘要信息和元数据。<br>随着游标在结果集中前进，结果记录将被惰性加载。这意味着必须将游标移动到第一个结果，然后才能使用此结果。通常最好的做法就是明确使用结果和关闭会话，特别是在运行 <code>update</code> 语句时。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">String</span> <span class="variable">searchTerm</span> <span class="operator">=</span> <span class="string">&quot;Sword&quot;</span>;</span><br><span class="line"><span class="keyword">try</span> (<span class="type">Transaction</span> <span class="variable">tx</span> <span class="operator">=</span> session.beginTransaction()) &#123;</span><br><span class="line"> <span class="type">StatementResult</span> <span class="variable">result</span> <span class="operator">=</span> tx.run(<span class="string">&quot;MATCH (weapon:Weapon) WHERE weapon.name CONTAINS &#123;term&#125; RETURN weapon.name&quot;</span>, Values.parameters(<span class="string">&quot;name&quot;</span>, searchTerm));</span><br><span class="line"> <span class="keyword">while</span> (result.hasNext()) &#123;</span><br><span class="line"> <span class="type">Record</span> <span class="variable">record</span> <span class="operator">=</span> result.next();</span><br><span class="line"> System.out.println(record.get(<span class="string">&quot;weapon.name&quot;</span>).asString());</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果记录集合由记录组成。记录提供结果的一部分固定不变的内容，他是键和值的有序映射。这些键值对称为字段，由于字段都是有键和有序的，因此可以通过位置或键访问字段的值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">String</span> <span class="variable">searchTerm</span> <span class="operator">=</span> <span class="string">&quot;Sword&quot;</span>;</span><br><span class="line"><span class="keyword">try</span> (<span class="type">Transaction</span> <span class="variable">tx</span> <span class="operator">=</span> session.beginTransaction()) &#123;</span><br><span class="line"> <span class="type">StatementResult</span> <span class="variable">result</span> <span class="operator">=</span> tx.run(<span class="string">&quot;MATCH (weapon:Weapon) WHERE weapon.name CONTAINS &#123;term&#125; RETURN weapon.name, weapon.material, weapon.size&quot;</span>, Values.parameters(<span class="string">&quot;name&quot;</span>, searchTerm));</span><br><span class="line"> <span class="keyword">while</span> (result.hasNext()) &#123;</span><br><span class="line"> <span class="type">Record</span> <span class="variable">record</span> <span class="operator">=</span> result.next();</span><br><span class="line"> List&lt;String&gt; sword = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line"> <span class="keyword">for</span> (String key : record.keys()) &#123;</span><br><span class="line"> sword.add(key + <span class="string">&quot;: &quot;</span> + record.get(key));</span><br><span class="line"> &#125;</span><br><span class="line"> System.out.println(sword);</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="保留结果"><a href="#保留结果" class="headerlink" title="保留结果"></a>保留结果</h5><p>语句执行获得的结果直到在 <code>Session</code> 会话中运行另一个语句之前或直到当前事务关闭结果集都可用。如果需要保留特定的结果集，每个驱动程序提供了收集结果集合并将其转换为每种语言的标准数据结构的方法，另外保存的结果也可以直接用于其他待运行的新语句中。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Record&gt; records;</span><br><span class="line"><span class="keyword">try</span> (<span class="type">Session</span> <span class="variable">session</span> <span class="operator">=</span> driver.session()) &#123;</span><br><span class="line"><span class="keyword">try</span> (<span class="type">Transaction</span> <span class="variable">tx</span> <span class="operator">=</span> session.beginTransaction()) &#123;</span><br><span class="line"><span class="type">StatementResult</span> <span class="variable">result</span> <span class="operator">=</span> tx.run(<span class="string">&quot;MATCH (knight:Person:Knight) WHERE knight.castle = &#123;castle&#125; RETURN knight.name AS name&quot;</span>, Values.parameters(<span class="string">&quot;castle&quot;</span>, <span class="string">&quot;Camelot&quot;</span>));</span><br><span class="line">records = result.list();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (Record record : records) &#123;</span><br><span class="line">System.out.println(record.get(<span class="string">&quot;name&quot;</span>).asString() + <span class="string">&quot; is a knight of Camelot&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在查询中使用结果。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">StatementResult result;</span><br><span class="line"><span class="keyword">try</span> (<span class="type">Transaction</span> <span class="variable">tx</span> <span class="operator">=</span> session.beginTransaction()) &#123;</span><br><span class="line">result = tx.run(<span class="string">&quot;MATCH (knight:Person:Knight) WHERE knight.castle = &#123;castle&#125; RETURN id(knight) AS knight_id&quot;</span>, Values.parameters(<span class="string">&quot;castle&quot;</span>, <span class="string">&quot;Camelot&quot;</span>));</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (Record record : result.list()) &#123;</span><br><span class="line"><span class="keyword">try</span> (<span class="type">Transaction</span> <span class="variable">tx</span> <span class="operator">=</span> session.beginTransaction()) &#123;</span><br><span class="line">result = tx.run(<span class="string">&quot;MATCH (knight) WHERE id(knight) = &#123;id&#125; &quot;</span> + </span><br><span class="line"><span class="string">&quot;MATCH (king:Person) WHERE king.name = &#123;king&#125; &quot;</span> + </span><br><span class="line"><span class="string">&quot;CREATE (knight)-[:DEFENDS]-&gt;(king)&quot;</span>, Values.parameters(<span class="string">&quot;id&quot;</span>, record.get(<span class="string">&quot;knight_id&quot;</span>), <span class="string">&quot;king&quot;</span>, <span class="string">&quot;Arthur&quot;</span>));</span><br><span class="line">tx.success();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="结果摘要"><a href="#结果摘要" class="headerlink" title="结果摘要"></a>结果摘要</h5><p><code>Cypher</code> 语句的元数据可以与结果一起展现出来，方法是通过在 <code>Cypher</code> 语句前面添加 <code>PROFILE</code> 或 <code>EXPLAIN</code> 关键字来获得查询操作的运行计划。在 <code>Cypher</code> 指令前面添加 <code>PROFILE</code> 关键字会导致本次查询操作将生成一个运行计划，通过 <code>IresultSummary</code> 对象的 <code>Profile</code> 属性可以获得此运行计划。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> (<span class="type">Transaction</span> <span class="variable">tx</span> <span class="operator">=</span> session.beginTransaction()) &#123;</span><br><span class="line"><span class="type">StatementResult</span> <span class="variable">result</span> <span class="operator">=</span> tx.run(<span class="string">&quot;PROFILE MATCH (p:Person &#123;name: &#123;name&#125;&#125;) RETURN id(p)&quot;</span>, Values.parameters(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Camelot&quot;</span>));</span><br><span class="line"><span class="type">ResultSummary</span> <span class="variable">summary</span> <span class="operator">=</span> result.consume();</span><br><span class="line">System.out.println(summary.statementType());</span><br><span class="line">System.out.println(summary.profile());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>还可以为查询提供通知，同时也可以查询执行时间。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> (<span class="type">Transaction</span> <span class="variable">tx</span> <span class="operator">=</span> session.beginTransaction()) &#123;</span><br><span class="line"><span class="type">ResultSummary</span> <span class="variable">summary</span> <span class="operator">=</span> tx.run(<span class="string">&quot;EXPLAIN MATCH (king), (queen) RETURN king, queen&quot;</span>).consume();</span><br><span class="line"><span class="keyword">for</span> (Notification notification : summary.notifications()) &#123;</span><br><span class="line">System.out.println(notification);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h4><p><code>Neo4j</code> 具有用于处理和存储数据类型的系统，驱动程序可以将数据在应用程序语言类型和 <code>Neo4j</code> 类型系统之间进行转换，同时为了理解传递参数和过程结果的数据类型，需要知道 <code>Neo4j</code> 类型系统的基础知识和理解 <code>Neo4j</code> 类型在驱动程序中的映射关系。</p><p><code>Neo4j</code> 类型对参数和结果都是有效的：</p><ul><li><code>Boolean</code></li><li><code>Integer</code></li><li><code>Float</code></li><li><code>String</code></li><li><code>List</code></li><li><code>Map</code></li><li><code>Node</code></li><li><code>Relationship</code></li><li><code>Path</code></li></ul><p><code>Map</code> 和 <code>List</code> 可以由数据库处理并在语句中使用。<code>List</code> 的每个元素可以是 <code>Neo4j</code> 的基本类型，也可以存储节点和关系上的属性。节点或关系的属性不能使用 <code>Map</code> 和 <code>List</code> 相组合的类型。</p><table><thead><tr><th>Neo4j</th><th>Java</th></tr></thead><tbody><tr><td>Null</td><td>Null</td></tr><tr><td>Boolean</td><td>java.lang.Boolean</td></tr><tr><td>Integer</td><td>java.lang.Long</td></tr><tr><td>Float</td><td>java.lang.Double</td></tr><tr><td>String</td><td>java.lang.String</td></tr><tr><td>List</td><td>java.util.List<T></td></tr><tr><td>Map</td><td>java.util.Map&lt;K, V&gt;</td></tr><tr><td>Node</td><td>org.neo4j.driver.v1.types.Node(*)</td></tr><tr><td>Relationship</td><td>org.neo4j.driver.v1.types.Relationship(*)</td></tr><tr><td>Path</td><td>org.neo4j.driver.v1.Path(*)</td></tr></tbody></table><h4 id="异常"><a href="#异常" class="headerlink" title="异常"></a>异常</h4><p>异常列表如下：</p><ul><li><code>ClientException</code> 指示客户端执行的操作不正确，提供的错误代码可用于确定问题的详细原因。</li><li><code>ConnectionFailureException</code> 指示底层连接中存在问题，很可能已经被终止。</li><li><code>DatabaseException</code> 指示底层数据库中存在问题，提供的错误代码可用于确定问题的详细原因。</li><li><code>NoSuchRecordException</code> 每当客户端期望读取不可用的记录（不是服务器返回的）时抛出，通常表示客户端代码和数据库应用程序逻辑之间的期望不匹配。</li><li><code>ServiceUnavailableException</code> 表示驱动程序无法与提供的端点通信，在路由 <code>URI</code> 的情况下，可能需要重新创建驱动程序以解决此问题。</li><li><code>SessionExpiredException</code> 表示会话不再满足获取他的条件。（例如服务器不再接受写入请求）</li><li><code>TransientException</code> 用信号通知可能通过重试来解决的临时故障，提供的错误代码可用于确定问题的详细原因。</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="keyword">try</span> (<span class="type">Transaction</span> <span class="variable">tx</span> <span class="operator">=</span> session.beginTransaction()) &#123;</span><br><span class="line">tx.run(<span class="string">&quot;This will case a syntax error&quot;</span>).consume();</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">catch</span> (ClientException e) &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><hr><h3 id="个人备注"><a href="#个人备注" class="headerlink" title="个人备注"></a>个人备注</h3><p><strong>此博客内容均为作者学习所做笔记，侵删！</strong><br><strong>若转作其他用途，请注明来源！</strong></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;驱动包开发模式&quot;&gt;&lt;a href=&quot;#驱动包开发模式&quot; class=&quot;headerlink&quot; title=&quot;驱动包开发模式&quot;&gt;&lt;/a&gt;驱动包开发模式&lt;/h3&gt;&lt;p&gt;&lt;code&gt;Neo4j&lt;/code&gt; 驱动程序也为其他的语言开发了访问途径，编写使用驱动程序的应用程序实例就可以与数据库基于事务的会话。在会话中事务可以运行创建和查询数据的相关命令，也可以定义数据库模式以及监视和管理数据库。当 &lt;code&gt;Neo4j&lt;/code&gt; 部署在因果集群中时，驱动程序可以处理读取和写入操作的路由。使用因果集群驱动程序还提供书签，用于保证因果一致性，也就是说应用程序可以在集群的不同成员上运行多个查询，同时保持数据的一致。 &lt;/p&gt;
&lt;p&gt;&lt;code&gt;Neo4j&lt;/code&gt; 驱动程序使用 &lt;code&gt;Bolt&lt;/code&gt; 协议进行通信，因果集群提供了使用驱动程序获取集群拓扑的功能，驱动程序必须具有集群感知能力才能提供路由和负载均衡。（&lt;code&gt;Bolt&lt;/code&gt; 在多个版本中提供兼容）&lt;/p&gt;</summary>
    
    
    
    
    <category term="Neo4j" scheme="https://blog.vgbhfive.cn/tags/Neo4j/"/>
    
  </entry>
  
  <entry>
    <title>Neo4j系列博客-程序开发-嵌入式</title>
    <link href="https://blog.vgbhfive.cn/Neo4j%E7%B3%BB%E5%88%97%E5%8D%9A%E5%AE%A2-%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91-%E5%B5%8C%E5%85%A5%E5%BC%8F/"/>
    <id>https://blog.vgbhfive.cn/Neo4j%E7%B3%BB%E5%88%97%E5%8D%9A%E5%AE%A2-%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91-%E5%B5%8C%E5%85%A5%E5%BC%8F/</id>
    <published>2022-02-28T14:22:56.000Z</published>
    <updated>2023-01-01T15:58:04.728Z</updated>
    
    <content type="html"><![CDATA[<p><code>Neo4j</code> 正式支持 <code>.Net</code> 、 <code>Java</code> 、 <code>JavaScript</code> 、 <code>Ruby</code> 、 <code>PHP</code> 和 <code>Python</code> 的二进制 <code>Bolt</code> 协议驱动程序。这些开发平台通过引入相应的驱动程序包便可与 <code>Neo4j</code> 相互集成，然后就可以对 <code>Neo4j</code> 进行数据操作。</p><h3 id="入门"><a href="#入门" class="headerlink" title="入门"></a>入门</h3><p>目前 <code>Neo4j</code> 支持三种开发模式，分别为：</p><ul><li><code>Java</code> 嵌入式开发模式。<code>Neo4j</code> 是基于 <code>Java</code> 语言开发的，所以他能与 <code>Java</code> 开发天然结合，完全可以在代码中调用 <code>Neo4j</code> 的 <code>API</code>，并将对 <code>Neo4j</code> 数据库的操作嵌入在 <code>Java</code> 代码中。</li><li>驱动包开发模式。通过 <code>HTTP</code> 的 <code>HTTP API</code> 的驱动包让非基于 <code>JVM</code> 的开发平台、编程语言也能够操作 <code>Neo4j</code> 数据库。</li></ul><span id="more"></span><hr><h3 id="嵌入式开发模式"><a href="#嵌入式开发模式" class="headerlink" title="嵌入式开发模式"></a>嵌入式开发模式</h3><p><code>Java API</code> 嵌入式开发模式中，应用程序、<code>Java API</code>、<code>Neo4j</code> 数据的关系如下图所示：<br><img src="https://s2.loli.net/2022/03/11/1Jk8X26ZVwid54f.png" alt="neo4j-5-1.jpg"></p><p>当在同一个 <code>JVM</code> 中运行自己的代码和 <code>Neo4j</code> 时，需要注意以下几点：</p><ul><li>不要创建或保留过多不需要的对象。大型缓存会将不需要的对象推向垃圾回收区，会增加垃圾回收的负担。</li><li>尽量不要使用内部 <code>Neo4j API</code>。他们是供 <code>Neo4j</code> 内部使用，使用不当可能会破坏或更改 <code>Neo4j</code> 的固有特性。</li><li>在嵌入式模式下运行时，不要启用 <code>-XX:+TrustFinalNonStaticFields</code> 的 <code>JVM</code> 标志。</li></ul><h4 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h4><p>这一小节是为开发前的准备工作，包括 <code>JAR</code> 包的引入、不同 <code>IDE</code> 下的引入方式和程序主体代码的编写。</p><h5 id="引入-JAR-包"><a href="#引入-JAR-包" class="headerlink" title="引入 JAR 包"></a>引入 <code>JAR</code> 包</h5><p>首先根据应用程序使用的 <code>Java</code> 版本选择合适的 <code>Neo4j JAR</code> 包版本，然后在应用程序项目中引入此 <code>JAR</code> 包，这样 <code>Neo4j API</code> 就嵌入到了 <code>Java</code> 应用程序中。以下部分将介绍通过两个途径来引入 <code>Neo4j JAR</code> 包：</p><ul><li>将 <code>JAR</code> 文件直接添加到 <code>Java</code> 的执行路径 <code>ClassPath</code> 中。</li><li>使用依赖关系管理来添加 <code>Neo4j JAR</code> 包的依赖。</li></ul><h5 id="Intellij-IDEA"><a href="#Intellij-IDEA" class="headerlink" title="Intellij IDEA"></a><code>Intellij IDEA</code></h5><p>使用 <code>Libraries\Global Libraries</code> 和 <code>Configure Library</code> 对话框，可以引入 <code>JAR</code> 文件。</p><h5 id="Maven"><a href="#Maven" class="headerlink" title="Maven"></a><code>Maven</code></h5><p>添加到项目根目录下的 <code>pom.xml</code> 文件中。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependecy&gt;</span><br><span class="line">&lt;groupId&gt;org.neo4j&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;neo4j&lt;/artifactId&gt;</span><br><span class="line">&lt;version&gt;3.1&lt;/version&gt;</span><br><span class="line">&lt;/dependecy&gt;</span><br></pre></td></tr></table></figure><h5 id="启动和关闭-Neo4j"><a href="#启动和关闭-Neo4j" class="headerlink" title="启动和关闭 Neo4j"></a>启动和关闭 <code>Neo4j</code></h5><p>在完成上述步骤后，我们尝试使用 <code>Java API</code> 启动和关闭 <code>Neo4j</code>。要创建一个新的数据库或者打开一个已经存在的数据库，首先需要创建 <code>GraphDatabaseService</code> 实例。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">graphDb = <span class="keyword">new</span> <span class="title class_">GraphDatabaseFactory</span>().newEmbeddedDatabase(DB_PATH);</span><br><span class="line">registerShutdownHook(graphDb);</span><br></pre></td></tr></table></figure><p><small><code>GraphDatabaseService</code> 实例可以在多个线程之间共享，但不能创建指向同一个数据库的多个实例。</small><br>关闭一个已经打开的实例，需要调用 <code>shutdown()</code> 方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graphDb.shutdown();</span><br></pre></td></tr></table></figure><h5 id="按配置文件启动-Neo4j"><a href="#按配置文件启动-Neo4j" class="headerlink" title="按配置文件启动 Neo4j"></a>按配置文件启动 <code>Neo4j</code></h5><p><code>Neo4j</code> 数据库包含一个配置文件，如果想要让 <code>Neo4j</code> 按照配置启动，代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">GraphDatabaseService</span> <span class="variable">graphDb</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">GraphDatabaseService</span>()</span><br><span class="line">.newEmbeddedDatabaseBuilder(testDirectory.graphDbDir())</span><br><span class="line">.loadPropertiesFromFile(pathToConfig + <span class="string">&quot;neo4j.conf&quot;</span>)</span><br><span class="line">.newGraphDatabase();</span><br></pre></td></tr></table></figure><p>当然配置项也可以在代码中设置：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">GraphDatabaseService</span> <span class="variable">graphDb</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">GraphDatabaseService</span>()</span><br><span class="line">.newEmbeddedDatabaseBuilder(testDirectory.graphDbDir())</span><br><span class="line">.setConfig(GraphDatabaseSettings.pagecache_memory, <span class="string">&quot;512M&quot;</span>)</span><br><span class="line">.setConfig(GraphDatabaseSettings.string_block_size, <span class="string">&quot;60&quot;</span>)</span><br><span class="line">.setConfig(GraphDatabaseSettings.array_block_size, <span class="string">&quot;300&quot;</span>)</span><br><span class="line">.newGraphDatabase();</span><br></pre></td></tr></table></figure><h5 id="启动一个只读实例"><a href="#启动一个只读实例" class="headerlink" title="启动一个只读实例"></a>启动一个只读实例</h5><p>如果希望以只读的方式打开 <code>Neo4j</code> 数据库而不想进行任何写操作，代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">GraphDatabaseService</span> <span class="variable">graphDb</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">GraphDatabaseService</span>()</span><br><span class="line">.newEmbeddedDatabaseBuilder(testDirectory.graphDbDir())</span><br><span class="line">.setConfig(GraphDatabaseSettings.read_only, <span class="literal">true</span>)</span><br><span class="line">.newGraphDatabase();</span><br></pre></td></tr></table></figure><h4 id="创建图实例"><a href="#创建图实例" class="headerlink" title="创建图实例"></a>创建图实例</h4><p><code>Neo4j</code> 数据库中数据的基本结构：</p><ul><li>节点：表示一个实体，可以用关系连接起来。</li><li>关系：用来连接节点。</li><li>属性：依附在节点或关系上的属性及其属性值。</li></ul><p>任何关系都有一个指定的类型名。如果两个节点被 <code>KNOWS</code> 类型的关系相互连接起来，那么说明这两个人互相认识对方。因此图的很多含义就是被用这样的方式编码后存储在 <code>Neo4j</code> 数据库中，尽管关系是直接将两个节点连接起来，但不管关系指向哪个节点，他们在数据库中都可以快速地遍历、查询。</p><h5 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h5><p>关系的类型标签可以使用枚举类型 <code>enum</code> 创建。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">enum</span> <span class="title class_">RelType</span> <span class="keyword">implements</span> <span class="title class_">RelationshipType</span> &#123;</span><br><span class="line">ACTED_IN, DIRECTED, PRODUCED;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来就是启动数据库实例，需要注意的是，如果创建的数据库当前并不存在，那么就会系统会自动创建一个新的数据库。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">graphDb = <span class="keyword">new</span> <span class="title class_">GraphDatabaseFactory</span>().newEmbeddedDatabase(DB_PATH);</span><br><span class="line">registerShutdownHook(graphDb);</span><br></pre></td></tr></table></figure><p>这个实例是可以被被多个线程共享，但是在进行事务操作时多个进程之间是相互冲突的，因此在同一个时间只能有一个进程操作某实例。</p><h5 id="操作写入到事务中"><a href="#操作写入到事务中" class="headerlink" title="操作写入到事务中"></a>操作写入到事务中</h5><p>在 <code>Neo4j Java API</code> 中所有的操作都必须放入到一个事务中，正如这样以保证某些重要操作的可靠性。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> (<span class="type">Transaction</span> <span class="variable">tx</span> <span class="operator">=</span> graphDb.beginTx()) &#123;</span><br><span class="line"><span class="comment">// 所有的操作都放入到 try-catch 块中</span></span><br><span class="line">tx.success();</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">tx.failure();</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">tx.finish();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="创建一个节点"><a href="#创建一个节点" class="headerlink" title="创建一个节点"></a>创建一个节点</h5><p>除了上面的枚举类型定义，还需要定义变量，变量定义完成后还需要对变量进行赋值并创建节点。节点创建完成后并没有赋任何属性值，所以节点只包含默认的 <code>id</code> 值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">GraphDatabaseService graphDb;</span><br><span class="line">Node TheMatrix;</span><br><span class="line">Node Keanu;</span><br><span class="line">TheMatrix = graphDb.createNode();</span><br><span class="line">Keanu = graphDb.createNode();</span><br></pre></td></tr></table></figure><h5 id="为节点创建属性值"><a href="#为节点创建属性值" class="headerlink" title="为节点创建属性值"></a>为节点创建属性值</h5><p>在 <code>Neo4j</code> 中节点、关系都有属性，也就是说节点、关系所附带的值包含 <code>ID</code> 、<code>Label</code>（关系为 <code>Type</code>）、属性三种。任何节点或关系都可以包含多个属性。<br>属性包括属性名和属性值两部分。属性名可以按照 <code>Java</code> 命名规范取名，属性值可以是单个值也可以是数组。<br><small><code>NULL</code> 在 <code>Neo4j</code> 中不可以赋值，但可以通过 <code>NULL</code> 来判断属性是否存在。</small></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> (<span class="type">Transaction</span> <span class="variable">tx</span> <span class="operator">=</span> graphDb.beginTx()) &#123;</span><br><span class="line">TheMatrix = graphDb.createNode();</span><br><span class="line">TheMatrix.setProperty(<span class="string">&quot;title&quot;</span>, <span class="string">&quot;The matrix&quot;</span>);</span><br><span class="line">TheMatrix.setProperty(<span class="string">&quot;released&quot;</span>, <span class="number">1999</span>);</span><br><span class="line">TheMatrix.setProperty(<span class="string">&quot;tagline&quot;</span>, <span class="string">&quot;Welcome to the Real World&quot;</span>);</span><br><span class="line">Keanu = graphDb.createNode();</span><br><span class="line">Keanu.setProperty(<span class="string">&quot;title&quot;</span>, <span class="string">&quot;Keanu Reeves&quot;</span>);</span><br><span class="line">Keanu.setProperty(<span class="string">&quot;born&quot;</span>, <span class="number">1960</span>);</span><br><span class="line">tx.success();</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">tx.failure();</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">tx.finish();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="为节点添加标签"><a href="#为节点添加标签" class="headerlink" title="为节点添加标签"></a>为节点添加标签</h5><p>在 <code>Neo4j</code> 中有一种将节点归类的方法，那就是标签（<code>Label</code>）。通过给节点添加相同或不同的标签可以将节点进行归类。每个节点可以添加一个或多个标签，标签是一种文字描述，可以通过标签加载、查询所有节点。<br>创建一个标签，可以通过使用枚举类型继承 <code>Neo4j</code> 的 <code>Label</code> 接口来创建</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> <span class="title class_">MyLabels</span> <span class="keyword">implements</span> <span class="title class_">Label</span> &#123;</span><br><span class="line">Movie, Person;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>为节点添加标签</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> (<span class="type">Transaction</span> <span class="variable">tx</span> <span class="operator">=</span> graphDb.beginTx()) &#123;</span><br><span class="line">TheMatrix.addLabel(MyLabels.Movie);</span><br><span class="line">Keanu.addLabel(MyLabels.Person);</span><br><span class="line">tx.success();</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">tx.failure();</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">tx.finish();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>添加标签之后就可以通过标签来查询此类节点的集合。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> (<span class="type">Transaction</span> <span class="variable">tx</span> <span class="operator">=</span> graphDb.beginTx()) &#123;</span><br><span class="line">ResourceIterable&lt;Node&gt; movies = GlobalGraphOperations.at(graphDb)</span><br><span class="line">.getAllNodesWithLabel(MyLabels.Movie);</span><br><span class="line">tx.success();</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">tx.failure();</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">tx.finish();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在查找节点时，想通过节点属性和标签同时锁定节点集合，那么可以通过 <code>findNodesByLabelAndProperty()</code> 方法来实现。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ResourceIterable&lt;Node&gt; movies = GlobalGraphOperations.at(graphDb)</span><br><span class="line">.findNodesByLabelAndProperty(MyLabels.Movie, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;The matrix&quot;</span>);</span><br></pre></td></tr></table></figure><h5 id="创建关系"><a href="#创建关系" class="headerlink" title="创建关系"></a>创建关系</h5><p>创建两个节点之间的关系并为这个新创建的关系添加属性值。在创建时可以指定关系的类型，关系的类型类似节点的标签，唯一不同的是关系的类型只能指定一个。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">relationship = Keanu.createRelationshipTo(TheMatrix, RelType.ACTED_IN);</span><br><span class="line">relationship.setProperty(<span class="string">&quot;roles&quot;</span>, <span class="string">&quot;Neo&quot;</span>);</span><br></pre></td></tr></table></figure><h5 id="输出图结果"><a href="#输出图结果" class="headerlink" title="输出图结果"></a>输出图结果</h5><p>将创建的图数据打印在控制台上。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">System.out.println(Keanu.getProperty(<span class="string">&quot;name&quot;</span>));</span><br><span class="line">System.out.println(relationship.getProperty(<span class="string">&quot;roles&quot;</span>));</span><br><span class="line">System.out.println(secondNode.getProperty(<span class="string">&quot;title&quot;</span>));</span><br></pre></td></tr></table></figure><h5 id="删除数据"><a href="#删除数据" class="headerlink" title="删除数据"></a>删除数据</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Keanu.getSingleRelationship(RelType.ACTED_IN, Direction.OUTGOING).delete();</span><br><span class="line">Keanu.delete();</span><br><span class="line">TheMatrix.delete();</span><br></pre></td></tr></table></figure><p><small>如果尝试删除一个带有关系边的节点时必定会失败，因此必须首先删除关系并确保没有任何关系指向这个节点时，才能够删除它。这是为了任何关系都有起始节点和结束节点的指向，没有空指向的关系。</small></p><h5 id="关闭数据库"><a href="#关闭数据库" class="headerlink" title="关闭数据库"></a>关闭数据库</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graphDb.shutdown();</span><br></pre></td></tr></table></figure><h4 id="图数据遍历"><a href="#图数据遍历" class="headerlink" title="图数据遍历"></a>图数据遍历</h4><p>至此我们已经创建了一个由节点、关系和索引组成的图数据库，接下来就是查询图数据的强大功能：图遍历功能。图遍历是以一种特殊的方式在图中按照节点之间的关系依次访问各个节点的过程。<br><code>Neo4j</code> 遍历 <code>API</code> 采用的是一种基于回调的、惰性执行的机制，使用 <code>Neo4j</code> 的图遍历功能可以使用指定的方式对数据库进行遍历。另外还可以使用 <code>Cypher</code> 查询语句的声明式方法对图进行查询。</p><h5 id="入门概念"><a href="#入门概念" class="headerlink" title="入门概念"></a>入门概念</h5><p>使用以下几个概念来解释图遍历功能</p><ul><li>路径拓展（<code>PathExpander</code>）：定义将要对图数据库中的什么进行遍历，一般是指针对关系的指向和关系的类型进行遍历。</li><li>顺序（<code>Order</code>）：深度优先或广度优先。</li><li>唯一性（<code>Uniqueness</code>）：在遍历过程中，确保每个节点（关系、路径）只被遍历一次。</li><li>评估器（<code>Evaluator</code>）：用来决定返回什么结果，以及是否停止或继续遍历当前位置。</li><li>开始节点：启动遍历最先开始的节点。</li></ul><p> <code>Neo4j</code> 遍历框架的结构图如下：<br><img src="https://s2.loli.net/2022/03/13/S3jOcmHdY51MrRW.png" alt="neo4j-5-2.jpg"></p><h5 id="遍历框架的-Java-API"><a href="#遍历框架的-Java-API" class="headerlink" title="遍历框架的 Java API"></a>遍历框架的 <code>Java API</code></h5><p>遍历框架除了包括节点和关系之外还有几个主要接口：</p><ul><li>遍历描述接口（<code>Traversal Description Interface</code>）</li><li>评估器接口（<code>Evaluator Interface</code>）</li><li>遍历器接口（<code>Traverser Interface</code>）</li><li>唯一性接口（<code>Uniqueness Interface</code>）</li></ul><p> 遍历框架中的路径接口（<code>Path Interface</code>）在遍历中有特殊用途，因为他在评估该位置时用于表示图中的位置。此外路径拓展接口是遍历的核心，但是在使用 <code>API</code> 时很少需要实现它，因为但需要实现它时，还有一组更加高级的接口：<code>branchSelector</code> 、<code>BranchOrderingPolicy</code> 和 <code>TraversalBranch</code>。</p><h5 id="遍历描述接口"><a href="#遍历描述接口" class="headerlink" title="遍历描述接口"></a>遍历描述接口</h5><p>遍历描述接口（<code>Traversal Description</code>）是用于定义和初始化遍历的主接口。他不必由遍历框架的用户实现，而是由遍历框架的实现来作为用户描述遍历的方式。<code>Traversal Description</code> 实例是不可变的，并且其返回一个新的 <code>Traversal Description</code> 与使用该方法的参数来调用该方法的对象相比，该 <code>Traversal Description</code> 可以被修改。</p><h5 id="关系接口"><a href="#关系接口" class="headerlink" title="关系接口"></a>关系接口</h5><p>关系（<code>Relationships</code>）接口用于将关系类型添加到要遍历的关系类型列表中。默认情况下，该列表为空意味者他将遍历所有类型的关系。如果一个或者多个关系添加到此列表中，则只会遍历所添加的类型的瓜西。<br>共有两种遍历方法：</p><ul><li>包括方向参数，仅遍历指定方向的关系。</li><li>不包括方向参数，那么将遍历双向关系。</li></ul><h5 id="评估器接口"><a href="#评估器接口" class="headerlink" title="评估器接口"></a>评估器接口</h5><p>评估器用于在每个位置（路径中的位置）处来确定：如果遍历继续，当前节点是否应包括在结果中。<br>给定一个路径，遍某个分支的动作可以为以下动作之一：</p><ul><li><code>Evalution.INCLUDE_AND_CONTINUE</code>：在结果中包括此节点并继续遍历。</li><li><code>Evalution.INCLUDE_AND_PRUNE</code>：在结果中包括此节点，但不继续遍历。</li><li><code>Evalution.EXCLUDE_AND_CONTINUE</code>：在结果中排除此节点，但继续遍历。</li><li><code>Evalution.EXCLUDE_AND_PRUNE</code>：在结果中排除此节点，不继续遍历。</li></ul><p> 可以为遍历器添加多个评估器。但是要注意对于遍历器遇到的所有位置（包括起始节点）都将调用评估器。</p><h5 id="遍历器接口"><a href="#遍历器接口" class="headerlink" title="遍历器接口"></a>遍历器接口</h5><p>遍历器（<code>Traverser</code>）对象是调用 <code>Traversal Description</code> 对象的 <code>traverse()</code> 方法返回的结果，他表示在图中定位的遍历以及结果格式的规范。每次调用 <code>Traverser</code> 的 <code>next()</code> 方法时遍历操作都将被 <strong>惰性</strong> 地执行一次。</p><h5 id="唯一性接口"><a href="#唯一性接口" class="headerlink" title="唯一性接口"></a>唯一性接口</h5><p>唯一性是用来设置在遍历期间如何重新访问遍历过地位置的规则，如果未设置，则默认为 <code>NODE_GLOBAL</code>。<br>可以向遍历描述提供唯一性参数以指示在什么情况下遍历可以重新访问图中的相同位置，目前 <code>Neo4j</code> 可使用地唯一性级别为：</p><ul><li><code>NONE</code>：可以重新访问图中的任何位置。</li><li><code>NODE_GLOBAL</code>：整个图中的任何一个节点都不可能被访问多次。</li><li><code>RELATIONSHIP_GLOBAL</code>：整个图中的任何一个关系都不可能被访问多次。</li><li><code>NODE_PATH</code>：节点不会先前出现在达到他的路径中。</li><li><code>RELATIONSHIP_PATH</code>：先前在达到他的路径中不会存在关系边。</li><li><code>NODE_RECENT</code>：类似于 <code>NODE_GLOBAL</code> 唯一性，存在受访节点地全局集合，每个位置被检查。</li><li><code>RELATIONSHIP_RECENT</code>：类似于 <code>NODE_RECENT</code> 唯一性，但它指的是关系而不是节点。</li></ul><p> 深度优先&#x2F;广度优先就是用于设置深度优先&#x2F;广度优先 <code>BranchSelector</code> 排序策略地遍历方法。同样的结果可以通过从 <code>BranchOrderingPolicies</code> 中调用带有排序策略地 <code>order</code> 方法来实现，也可以编写自己的 <code>BranchSelector / BranchOrderingPolicy</code> 来实现排序。</p><h5 id="遍历顺序"><a href="#遍历顺序" class="headerlink" title="遍历顺序"></a>遍历顺序</h5><p>遍历顺序是指在遍历过程中按照什么顺序来遍历图的各个分支。</p><h5 id="分支选择器"><a href="#分支选择器" class="headerlink" title="分支选择器"></a>分支选择器</h5><p><code>BranchSelector / BranchOrderingPolicy</code> 用于选择下一次的遍历分支，这用于实现遍历排序。遍历框架提供了一些基本的排序实现：</p><ul><li><code>BranchOrderingPolicies.PREORDER_DEPTH_FIRST</code>：深度优先遍历，在访问其子节点之前访问每个节点。</li><li><code>BranchOrderingPolicies.POSTORDER_DEPTH_FIRST</code>：深度优先遍历，在访问其子节点后访问每个节点。</li><li><code>BranchOrderingPolicies.PREORDER_BREADTH_FIRST</code>：广度优先遍历，在访问其子节点之前访问每个节点。</li><li><code>BranchOrderingPolicies.POSTORDER_BREADTH_FIRST</code>：深度优先遍历，在访问其子节点后访问每个节点。</li></ul><p> <small>广度优先遍历比深度优先遍历需要更高的内存开销。</small></p><p><code>BranchSelectors</code> 具有状态属性，因此需要每次遍历唯一地实例化这个类。它通过 <code>BranchOrderingPolicy</code> 接口提供给 <code>Traversal Description</code>，<code>BranchOrderingPolicy</code> 接口是 <code>BranchSelectors</code> 实例的工厂。</p><h5 id="分支遍历策略"><a href="#分支遍历策略" class="headerlink" title="分支遍历策略"></a>分支遍历策略</h5><p>一个用于创建 <code>BranchSelectors</code> 的工厂，用于决定返回分支的顺序（其中分支的位置表示为从起始节点到当前节点的路径）。常见的策略是深度优先和广度优先，这也就是为什么有更方便的方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">description.order(BranchOrderingPolicies.PREORDER_DEPTH_FIRST);</span><br></pre></td></tr></table></figure><ol><li><p>分支选择器（<code>BranchSelector</code>）<br><code>BranchSelector</code> 用来从某个分支获取更多分支。本质上就是路径（<code>Path</code>）和关系拓展器（<code>RelationshipExpander</code>）的复合，可以用来从当前的一个分支获得新的 <code>TraversalBranches</code>。</p></li><li><p>遍历路径<br><code>Path</code> 是一个通用接口，在 <code>Neo4j API</code> 中使用 <code>Paths</code> 可以进行双向的的遍历。遍历器可以将图中被标记为返回的、被访问位置的、路径的形式返回其结果。<code>Path</code> 对象也用来评估图中的位置，用于确定遍历是否应当从某个点继续，以及是否应当将某个位置包括在结果集中。</p></li><li><p>路径扩展器<br>遍历框架使用路径拓展器（<code>PathExpander</code>，路径拓展器用来替换关系拓展器）来发现在遍历中从特定路径到进一步分支应遵循的关系。</p></li><li><p>拓展器<br>这个是比 <code>RelationshipExpander</code> 关系更加通用的存在，可以定义要为任何给定节点遍历的所有关系。</p></li></ol><h5 id="Java-中使用遍历框架"><a href="#Java-中使用遍历框架" class="headerlink" title="Java 中使用遍历框架"></a><code>Java</code> 中使用遍历框架</h5><p>使用遍历描述可以生成遍历器。<br><img src="https://s2.loli.net/2022/03/13/UGpFQwZ9vsnbmr3.png" alt="neo4j-5-3.jpg"></p><p>首先定义一个关系类型</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> <span class="title class_">Rels</span> <span class="keyword">implements</span> <span class="title class_">RelationshipType</span> &#123;</span><br><span class="line">LIKES, KNOWS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>遍历实例代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (Path position : db.traversalDescription()</span><br><span class="line">.depthFirst()</span><br><span class="line">.relationships(Rels.KNOW)</span><br><span class="line">.relationships(Rels.LIKES, Direction.INCOMING)</span><br><span class="line">.evaluator(Evaluators.toDepth(<span class="number">5</span>))</span><br><span class="line">.traverse(node)) &#123;</span><br><span class="line">output += position + <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于遍历的描述是不可变的，因此可以创建一个模板米哦啊书来保存由不同遍历共享的公共设置</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">firendsTraversal = db.traversalDescription()</span><br><span class="line">.depthFirst()</span><br><span class="line">.relationships(Rels.KNOWS)</span><br><span class="line">.uniqueness(Uniqueness.RELATIONSHIP_GLOBAL);</span><br></pre></td></tr></table></figure><p>现在创建一个新的遍历器，将遍历深度设置在 <code>2</code> 到 <code>4</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (Path path : firendsTraversal</span><br><span class="line">.evaluator(Evaluators.fromDepth(<span class="number">2</span>))</span><br><span class="line">.evaluator(Evaluators.toDepth(<span class="number">4</span>))</span><br><span class="line">.traverse(node)) &#123;</span><br><span class="line">output += path + <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>将遍历器转换为可迭代的节点</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (Node currentNode : firendsTraversal</span><br><span class="line">.traverse(node)</span><br><span class="line">.nodes()) &#123;</span><br><span class="line">output += currentNode.getProperty(<span class="string">&quot;name&quot;</span>) + <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用关系来遍历</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (Relationship relationship : firendsTraversal</span><br><span class="line">.traverse(node)</span><br><span class="line">.relationships()) &#123;</span><br><span class="line">output += relationship.getType().name() + <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="数据索引"><a href="#数据索引" class="headerlink" title="数据索引"></a>数据索引</h4><p>在关系型数据库中，索引提供了有序排列数据的方式，使用索引可以像字典一样快速地定位所要查找的记录。在 <code>Neo4j</code> 中索引也可以对指定的属性值进行快速定位查找，与关系数据库有所不同的是 <code>Neo4j</code> 中除了 <code>Cypher</code>，也可以通过 <code>Java</code> 应用程序通过代码来创建索引。</p><h5 id="自动索引"><a href="#自动索引" class="headerlink" title="自动索引"></a>自动索引</h5><p>参考之前 <code>Cypher</code> 中模式下的索引内容。</p><h5 id="手动索引"><a href="#手动索引" class="headerlink" title="手动索引"></a>手动索引</h5><p>手动索引操作是 <code>Neo4j</code> 索引 <code>API</code> 的一部分，每个索引都绑定到某个唯一的属性名称上，并且对节点或关系都可以创建索引。</p><h5 id="创建索引"><a href="#创建索引" class="headerlink" title="创建索引"></a>创建索引</h5><p>如果每个索引在请求时发现并不存在，则系统会自动创建此索引，如果没有给他定义配置参数，则索引将使用默认配置参数创建。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">IndexManager</span> <span class="variable">index</span> <span class="operator">=</span> graphDb.index();</span><br><span class="line">Index&lt;Node&gt; actors = index.forNodes(<span class="string">&quot;actors&quot;</span>);</span><br><span class="line">Index&lt;Node&gt; movies = index.forNodes(<span class="string">&quot;movies&quot;</span>);</span><br><span class="line"><span class="type">relationshipIndex</span> <span class="variable">roles</span> <span class="operator">=</span> index.forRelationships(<span class="string">&quot;roles&quot;</span>);</span><br></pre></td></tr></table></figure><p>如果想要知道某个索引是否已经存在</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">IndexManager</span> <span class="variable">index</span> <span class="operator">=</span> graphDb.index();</span><br><span class="line"><span class="type">boolean</span> <span class="variable">indexExists</span> <span class="operator">=</span> index.existsForNodes(<span class="string">&quot;actors&quot;</span>);</span><br></pre></td></tr></table></figure><h5 id="删除索引"><a href="#删除索引" class="headerlink" title="删除索引"></a>删除索引</h5><p>索引是可以删除的。删除时，将删除索引的全部内容及其关联配置。删除这个索引之后，可以使用相同的名称创建其索引，这样能保证索引的唯一性。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">IndexManager</span> <span class="variable">index</span> <span class="operator">=</span> graphDb.index();</span><br><span class="line">Index&lt;Node&gt; actors = index.forNodes(<span class="string">&quot;actors&quot;</span>);</span><br><span class="line">actors.delete();</span><br></pre></td></tr></table></figure><p><small>索引的删除实际上实在事务内提交的。如果这个事务被回滚了，那么多索引的删除就是无效的，索引还依然存在。</small></p><h5 id="添加索引"><a href="#添加索引" class="headerlink" title="添加索引"></a>添加索引</h5><p>索引支持将任意数量的键值对与任意数量的实体（节点或关系）相关联，也就是说一个创建好的索引可以被赋予在任何数量的节点或关系上。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Node</span> <span class="variable">reeves</span> <span class="operator">=</span> graphDb.createNode();</span><br><span class="line">reeves.setProperty(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Keanu Reeves&quot;</span>);</span><br><span class="line">actors.add(reeves, <span class="string">&quot;name&quot;</span>, reeves.getProperty(<span class="string">&quot;name&quot;</span>));</span><br><span class="line"><span class="type">Node</span> <span class="variable">bellucci</span> <span class="operator">=</span> graphDb.createNode();</span><br><span class="line">bellucci.setProperty(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Monica Bellucci&quot;</span>);</span><br><span class="line">actors.add(bellucci, <span class="string">&quot;name&quot;</span>, bellucci.getProperty(<span class="string">&quot;name&quot;</span>));</span><br><span class="line">actors.add(bellucci, <span class="string">&quot;name&quot;</span>, <span class="string">&quot;La Bellucci&quot;</span>);</span><br><span class="line"><span class="type">Node</span> <span class="variable">theMatrix</span> <span class="operator">=</span> graphDb.createNode();</span><br><span class="line">theMatrix.setProperty(<span class="string">&quot;title&quot;</span>, <span class="string">&quot;The matrix&quot;</span>);</span><br><span class="line">theMatrix.setProperty(<span class="string">&quot;year&quot;</span>, <span class="number">1999</span>);</span><br><span class="line">movies.add(theMatrix, <span class="string">&quot;title&quot;</span>, theMatrix.getProperty(<span class="string">&quot;title&quot;</span>));</span><br><span class="line">movies.add(theMatrix, <span class="string">&quot;year&quot;</span>, theMatrix.getProperty(<span class="string">&quot;year&quot;</span>));</span><br><span class="line"><span class="type">Node</span> <span class="variable">theMatrixReloaded</span> <span class="operator">=</span> graphDb.createNode();</span><br><span class="line">theMatrixReloaded.setProperty(<span class="string">&quot;title&quot;</span>, <span class="string">&quot;The Matrix Reloaded&quot;</span>);</span><br><span class="line">theMatrixReloaded.setProperty(<span class="string">&quot;year&quot;</span>, <span class="number">2003</span>);</span><br><span class="line">movies.add(theMatrixReloaded, <span class="string">&quot;title&quot;</span>, theMatrixReloaded.getProperty(<span class="string">&quot;title&quot;</span>));</span><br><span class="line">movies.add(theMatrixReloaded, <span class="string">&quot;year&quot;</span>, theMatrixReloaded.getProperty(<span class="string">&quot;year&quot;</span>));</span><br><span class="line"><span class="type">Node</span> <span class="variable">malena</span> <span class="operator">=</span> graphDb.createNode();</span><br><span class="line">malena.setProperty(<span class="string">&quot;title&quot;</span>, <span class="string">&quot;Malena&quot;</span>);</span><br><span class="line">malena.setProperty(<span class="string">&quot;year&quot;</span>, <span class="number">200</span>);</span><br><span class="line">movies.add(malena, <span class="string">&quot;title&quot;</span>, malena.getProperty(<span class="string">&quot;title&quot;</span>));</span><br><span class="line">movies.add(malena, <span class="string">&quot;year&quot;</span>, malena.getProperty(<span class="string">&quot;year&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="type">RelationshipType</span> <span class="variable">ACTS_IN</span> <span class="operator">=</span> RelationshipType.withName(<span class="string">&quot;ACTS_IN&quot;</span>);</span><br><span class="line"><span class="type">relationship</span> <span class="variable">role1</span> <span class="operator">=</span> reeves.createRelationshipTo(theMatrix, ACTS_IN);</span><br><span class="line">role1.setProperty(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Neo&quot;</span>);</span><br><span class="line">roles.add(role1, <span class="string">&quot;name&quot;</span>, role1.getProperty(<span class="string">&quot;name&quot;</span>));</span><br><span class="line"><span class="type">relationship</span> <span class="variable">role2</span> <span class="operator">=</span> reeves.createRelationshipTo(theMatrixReloaded, ACTS_IN);</span><br><span class="line">role2.setProperty(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Neo&quot;</span>);</span><br><span class="line">roles.add(role2, <span class="string">&quot;name&quot;</span>, role2.getProperty(<span class="string">&quot;name&quot;</span>));</span><br><span class="line"><span class="type">relationship</span> <span class="variable">role3</span> <span class="operator">=</span> bellucci.createRelationshipTo(theMatrixReloaded, ACTS_IN);</span><br><span class="line">role3.setProperty(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Persephone&quot;</span>);</span><br><span class="line">roles.add(role3, <span class="string">&quot;name&quot;</span>, role3.getProperty(<span class="string">&quot;name&quot;</span>));</span><br><span class="line"><span class="type">relationship</span> <span class="variable">role4</span> <span class="operator">=</span> bellucci.createRelationshipTo(malena, ACTS_IN);</span><br><span class="line">role4.setProperty(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Malena SScordia&quot;</span>);</span><br><span class="line">roles.add(role4, <span class="string">&quot;name&quot;</span>, role4.getProperty(<span class="string">&quot;name&quot;</span>));</span><br></pre></td></tr></table></figure><p>创建索引后，数据库中的图结构如下<br><img src="https://s2.loli.net/2022/03/14/ZLcOBGEsu4NgCyn.png" alt="neo4j-5-4.jpg"></p><h5 id="将索引移除"><a href="#将索引移除" class="headerlink" title="将索引移除"></a>将索引移除</h5><p>将索引从节点或关系上移除与上面的添加操作类似，移除索引需要制定索引的参数，可以通过提供以下参数组合来完成：</p><ul><li>实体（节点、索引）</li><li>实体、索引键名</li><li>实体、索引键名、索引键值<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">actors.remove(bellucci);</span><br><span class="line">actors.remove(bellucci, <span class="string">&quot;name&quot;</span>);</span><br><span class="line">actors.remove(bellucci, <span class="string">&quot;name&quot;</span>, <span class="string">&quot;La Bellucci&quot;</span>);</span><br></pre></td></tr></table></figure></li></ul><h5 id="更新索引"><a href="#更新索引" class="headerlink" title="更新索引"></a>更新索引</h5><p>要更新索引必须删除旧的索引条目，然后再添加新的索引条目。<br>节点或关系可以与索引中任意数量的键值对关联，这意味着可以使用具有相同键的许多键值对对节点或关系建立索引。当属性值改变想更新索引时，仅仅对新值创建索引是不够的，还必须删除旧值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建节点</span></span><br><span class="line"><span class="type">Node</span> <span class="variable">fishburn</span> <span class="operator">=</span> graphDb.createNode();</span><br><span class="line">fishburn.setProperty(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Fishburn&quot;</span>);</span><br><span class="line"><span class="comment">// 对 name 创建索引</span></span><br><span class="line">actors.add(fishburn, <span class="string">&quot;name&quot;</span>, fishburn.getProperty(<span class="string">&quot;name&quot;</span>));</span><br><span class="line"><span class="comment">// 属性值更改，我们需要重新更新这个索引</span></span><br><span class="line">actors.remove(fishburn, <span class="string">&quot;name&quot;</span>, fishburn.getProperty(<span class="string">&quot;name&quot;</span>));</span><br><span class="line">fishburn.setProperty(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Laurence Fishburn&quot;</span>);</span><br><span class="line">actors.add(fishburn, <span class="string">&quot;name&quot;</span>, fishburn.getProperty(<span class="string">&quot;name&quot;</span>));</span><br></pre></td></tr></table></figure><h5 id="节点索引下的查询"><a href="#节点索引下的查询" class="headerlink" title="节点索引下的查询"></a>节点索引下的查询</h5><p>节点在创建好索引的情况下，可以通过两种方式查询：<code>get</code> 和 <code>query</code>。<code>get</code> 方法将返回与给定键值对完全匹配的结果。<code>query</code> 方法可以直接使用索引查询更底层功能。</p><ol><li><p><code>get</code> 方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 返回与查询的键值对完全匹配的结果</span></span><br><span class="line">IndexHits&lt;Node&gt; hits = actors.get(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Keanu Reeves&quot;</span>);</span><br><span class="line"><span class="type">Node</span> <span class="variable">reeves</span> <span class="operator">=</span> hits.getSingle();</span><br></pre></td></tr></table></figure><p><code>IndexHits</code> 是一个 <code>Iterator</code> 类的继承，它提供了一些特别有用的方法。</p></li><li><p><code>query</code> 方法<br><code>query</code> 方法有两种使用方式，一种使用方式就是提供单一的键值对来匹配查询索引所关联的属性；另一种方式就是提供多个键值对来匹配（可以使用模糊匹配运算符 <code>*</code>）。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 单一键值对</span></span><br><span class="line"><span class="keyword">for</span> (Node actor : actors.query(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;*e*&quot;</span>)) &#123;</span><br><span class="line"><span class="comment">// *e* 为模糊匹配，返回结果为 Reeves 和 Bellucci</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 多个键值对</span></span><br><span class="line"><span class="keyword">for</span> (Node movie : movies.query(<span class="string">&quot;title:*Matrix* AND year:1999&quot;</span>)) &#123;</span><br><span class="line"><span class="comment">// 返回结果为 1999 年的 The Matrix</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h5 id="关系索引下的索引"><a href="#关系索引下的索引" class="headerlink" title="关系索引下的索引"></a>关系索引下的索引</h5><p>关系索引下的查询与节点索引类似，但在查询中需要指定所要查询的关系的开始节点或结束节点。这些额外的方法在 <code>RelationshipIndex</code> 接口中，该接口扩展了 <code>Index&lt;Relationship&gt;</code> 接口。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 以 reeves 作为开始节点的关系，使用单一键值对查询</span></span><br><span class="line">IndexHits&lt;Relationship&gt; reevesAsNeoHits = roles.get(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Neo&quot;</span>, reeves, <span class="literal">null</span>);</span><br><span class="line"><span class="type">Relationship</span> <span class="variable">reevesAsNeo</span> <span class="operator">=</span> reevesAsNeoHits.Iterabor().next();</span><br><span class="line">reevesAsNeoHits.close();</span><br><span class="line"><span class="comment">// 使用 query 方法</span></span><br><span class="line">IndexHits&lt;Relationship&gt; matrixAsNeoHits = roles.query(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;*eo&quot;</span>, <span class="literal">null</span>, theMatrix);</span><br><span class="line"><span class="type">Relationship</span> <span class="variable">matrixNeo</span> <span class="operator">=</span> matrixAsNeoHits.Iterator().next();</span><br><span class="line">matrixAsNeoHits.close();</span><br></pre></td></tr></table></figure><p>查询特定关系</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">roles.add(reevesAsNeo, <span class="string">&quot;type&quot;</span>, reevesAsNeo.getType().name());</span><br><span class="line"><span class="keyword">try</span> (Transaction tx : graphDb.beginTx()) &#123;</span><br><span class="line">IndexHits&lt;Relationship&gt; typeHits = roles.query(<span class="string">&quot;type:ACTS_IN AND name:Neo&quot;</span>, <span class="literal">null</span>, theMatrix);</span><br><span class="line"><span class="type">Relationship</span> <span class="variable">typeNeo</span> <span class="operator">=</span> typeHits.iterator().next();</span><br><span class="line">typeHits.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="结果评分"><a href="#结果评分" class="headerlink" title="结果评分"></a>结果评分</h5><p>在查询中特别是模糊匹配查询中，我们需要得到结果集中每个结果的匹配相似度，这就需要评分实现。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">IndexHits&lt;Node&gt; hits = movies.query(<span class="string">&quot;title&quot;</span>, <span class="string">&quot;The*&quot;</span>);</span><br><span class="line"><span class="keyword">for</span> (Node movie : hits) &#123;</span><br><span class="line">System.out.println(movie.getProperty(<span class="string">&quot;title&quot;</span>) + <span class="string">&quot; &quot;</span> + hits.currentScore());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="索引配置和全文索引"><a href="#索引配置和全文索引" class="headerlink" title="索引配置和全文索引"></a>索引配置和全文索引</h5><p>在创建索引时，可以配置索引的一些属性来控制索引的行为。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建 Lucene 全文索引</span></span><br><span class="line"><span class="type">IndexManager</span> <span class="variable">index</span> <span class="operator">=</span> graphDb.index();</span><br><span class="line">Index&lt;Node&gt; fulltextMovies = index.forNodes(<span class="string">&quot;movie-fulltext&quot;</span>, MapUtil.stringMap(IndexManager.PROVIDER, <span class="string">&quot;lucene&quot;</span>, <span class="string">&quot;type&quot;</span>, <span class="string">&quot;fulltext&quot;</span>));</span><br><span class="line">fulltextMovies.add(theMatrix, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;The Matrix&quot;</span>);</span><br><span class="line">fulltextMovies.add(theMatrixReloaded, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;The Matrix Reloaded&quot;</span>);</span><br><span class="line"><span class="type">Node</span> <span class="variable">found</span> <span class="operator">=</span> fulltextMovies.query(<span class="string">&quot;title&quot;</span>, <span class="string">&quot;roleAdEd&quot;</span>).getSingle();</span><br><span class="line"><span class="comment">// 不区分大小写的全文索引</span></span><br><span class="line"><span class="type">IndexManager</span> <span class="variable">index</span> <span class="operator">=</span> graphDb.index().forNodes(<span class="string">&quot;exact-case-insensitive&quot;</span>, MapUtil.stringMap(<span class="string">&quot;type&quot;</span>, <span class="string">&quot;exact&quot;</span>, <span class="string">&quot;to_lower_case&quot;</span>, <span class="string">&quot;true&quot;</span>));</span><br><span class="line"><span class="type">Node</span> <span class="variable">node</span> <span class="operator">=</span> graphDb.createNode();</span><br><span class="line">index.add(node, <span class="string">&quot;name&quot;</span>, <span class="string">&quot;Thomas Anderson&quot;</span>);</span><br><span class="line">assertContains(index.query(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Thomas Anderson&quot;</span>), node);</span><br><span class="line">assertContains(index.query(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;thomas Anderson&quot;</span>), node);</span><br></pre></td></tr></table></figure><h5 id="Lucene-索引的其他特性"><a href="#Lucene-索引的其他特性" class="headerlink" title="Lucene 索引的其他特性"></a><code>Lucene</code> 索引的其他特性</h5><ol><li><p>数值范围<br>当对数值型数据创建索引时，<code>Lucene</code> 支持针对数值的智能索引。首先需要使用 <code>ValueContext</code> 方法标记一个值，使其被当作一个数值来创建索引，然后可以按照范围进行查询。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">movies.add(theMatrix, <span class="string">&quot;year-numeric&quot;</span>, <span class="keyword">new</span> <span class="title class_">ValueContext</span>(<span class="number">1999</span>).indexNumeric());</span><br><span class="line">movies.add(theMatrixReloaded, <span class="string">&quot;year-numeric&quot;</span>, <span class="keyword">new</span> <span class="title class_">ValueContext</span>(<span class="number">2003</span>).indexNumeric());</span><br><span class="line">movies.add(malena, <span class="string">&quot;year-numeric&quot;</span>, <span class="keyword">new</span> <span class="title class_">ValueContext</span>(<span class="number">2000</span>).indexNumeric());</span><br><span class="line">hits = movies.query(QueryContext.numericRange(<span class="string">&quot;year-numeric&quot;</span>, <span class="number">1997</span>, <span class="number">1999</span>));</span><br></pre></td></tr></table></figure></li><li><p><code>Lucene</code> 排序<br><code>Lucene</code> 索引具有优秀的排序功能，通过 <code>QueryContext</code> 类就可以实现。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">hits = movies.query(<span class="string">&quot;title&quot;</span>, <span class="keyword">new</span> <span class="title class_">QueryContext</span>(<span class="string">&quot;*&quot;</span>).sort(<span class="string">&quot;title&quot;</span>));</span><br><span class="line"><span class="keyword">for</span> (Node hit : hits) &#123;</span><br><span class="line"><span class="comment">// 按照 title 排序</span></span><br><span class="line">&#125;</span><br><span class="line">hits = movies.query(<span class="string">&quot;title&quot;</span>, <span class="keyword">new</span> <span class="title class_">QueryContext</span>(<span class="string">&quot;title:*&quot;</span>).sort(<span class="string">&quot;year&quot;</span>, <span class="string">&quot;title&quot;</span>));</span><br><span class="line"><span class="keyword">for</span> (Node hit : hits) &#123;</span><br><span class="line"><span class="comment">// 按照 year 排序然后再按照 title 排序</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 也可以按照匹配的相似度（分数）对结果进行排序</span></span><br><span class="line">hits = movies.query(<span class="string">&quot;title&quot;</span>, <span class="keyword">new</span> <span class="title class_">QueryContext</span>(<span class="string">&quot;The*&quot;</span>).sortByScore());</span><br><span class="line"><span class="keyword">for</span> (Node hit : hits) &#123;</span><br><span class="line"><span class="comment">// 按照相似度排序</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>使用 <code>Lucene</code> 查询对象进行查询<br>可以通过编程方式实例化这些查询并作为参数传入，而不是传递 <code>Lucene</code> 查询语法查询。(<code>TermQuery</code> 基本上与在索引上使用 <code>get</code> 方法是一样的)</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Node</span> <span class="variable">actor</span> <span class="operator">=</span> actors.query(<span class="keyword">new</span> <span class="title class_">TermQuery</span>(<span class="keyword">new</span> <span class="title class_">Term</span>(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Keanu Revves&quot;</span>))).getSingle();</span><br><span class="line"><span class="comment">// 使用 Lucene 查询对象执行通配符搜索</span></span><br><span class="line">hits = movies.query(<span class="keyword">new</span> <span class="title class_">WildcardQuery</span>(<span class="keyword">new</span> <span class="title class_">Term</span>(<span class="string">&quot;title&quot;</span>, <span class="string">&quot;The Matrix*&quot;</span>)));</span><br><span class="line"><span class="keyword">for</span> (Node movie : hits) &#123;</span><br><span class="line">System.out.println(movie.getProperty(<span class="string">&quot;title&quot;</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>复合查询<br><code>Lucene</code> 支持在同一查询中查询多个术语。但是复合查询无法对已经创建索引条目和尚未创建索引条目的属性同时进行搜索。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hits = movies.query(<span class="string">&quot;title:*Matirx* AND year:1999&quot;</span>);</span><br></pre></td></tr></table></figure></li><li><p>操作符<br>查询中的默认关系运算符（<code>AND</code> 或 <code>OR</code>）也可以通过 <code>QueryContext</code> 类来更改行为：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">QueryContext</span> <span class="variable">query</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">QueryContext</span>(<span class="string">&quot;title:*Matrix* AND year:1999&quot;</span>).defaultOperator(Operator.AND);</span><br><span class="line">hits = movies.query(query);</span><br></pre></td></tr></table></figure></li></ol><h4 id="事务管理"><a href="#事务管理" class="headerlink" title="事务管理"></a>事务管理</h4><p>为了完全保持数据完整性并确保良好的事务行为，<code>Neo4j</code> 支持 <code>ACID</code> 即原子性（<code>Atomicity</code>）、一致性（<code>Consistency</code>）、隔离性（<code>Isolation</code>）、持久性（<code>Durability</code>）四个要素。<br>特别需要注意以下几点：</p><ul><li>访问图、索引或者模式的所有数据库操作都必须在事务中执行。</li><li>默认访问级别为 <code>READ_COMMITTED</code>。</li><li>通过遍历检索的数据不受其他事务的修改保护。</li><li>可以只有写锁被获取并保持，直到事务结束。</li><li>可以手动获取节点和关系上的写锁，以实现更高级别的隔离（<code>SERIALIZABLE</code>）。</li><li>在节点和关系级别都可以获取锁定权限。</li><li>死锁检测被构建在核心事务管理中。</li></ul><h5 id="交互周期"><a href="#交互周期" class="headerlink" title="交互周期"></a>交互周期</h5><p>处理事务的交互周期如下：</p><ul><li>开始一个事务。</li><li>执行数据库操作。</li><li>将事务标记为成功或不成功。</li><li>完成事务。</li></ul><p>事务是被限制在线程内的，可以嵌套为 <strong>平行嵌套事务</strong>。平行嵌套事务指的是所有嵌套事务都被添加到顶层事务的作用域中。嵌套事务可以标记顶层事务以进行回滚，这意味着整个事务都将被回滚，仅回滚在嵌套事务中的操作是不可能的。<br>完成每个事务然后提交是很重要的，程序中惯用的方法就是使用 <code>try-finally</code> 块处理事务。首先在 <code>try</code> 块中的最后一个操作应该是标记事务成功即执行 <code>success()</code> 方法，而 <code>finally</code> 块写完成事务的相关操作。完成事务将根据成功状态执行提交或回滚。</p><p><small>在事务中执行的所有修改都会被暂时保存在内存中，所以在遇到大型事务时应将其拆分为小的事务，以避免内存溢出。</small></p><h5 id="隔离级别"><a href="#隔离级别" class="headerlink" title="隔离级别"></a>隔离级别</h5><p><code>Neo4j</code> 中的事务使用读提交隔离级别，也就是一旦事务被提交就可以看到修改，而不会出现在其他事务中看到未提交的数据。另外 <code>Neo4j API</code> 还支持显式锁定节点和关系，通过获取和释放锁可以获得更高级别的隔离。</p><ol><li><p>默认自动加锁的情况</p><ul><li>在添加、更改或删除节点或关系上的属性时，将对操作的节点或关系执行写锁定。</li><li>在创建或删除节点时，将为操作的节点执行写锁定。</li><li>在创建或删除关系时，将对操作的关系及其两个节点执行写锁定。<br> 锁将添加到事务中，并在事务完成时释放。</li></ul></li><li><p><code>Cypher</code> 中的更新丢失<br><code>Cypher</code> 中在某些情况下可以获取写锁来模拟改进的隔离。例如多个并发 <code>Cypher</code> 查询增加属性值的情况，由于读提交隔离级别的限制，增加操作的结果可能是无法确定，如果存在直接依赖，则 <code>Cypher</code> 将在读取前自动获取写锁定。直接依赖关系是指 <code>SET</code> 的右侧在表达式中读取依赖属性或者在 <code>map</code> 字面值的键值对的值中。<br>然而在某些情况下判断读写依赖太过于复杂，可以在某些情况下 <code>Cypher</code> 不会自动加上写锁定。</p><ul><li>在读取请求的值之前，通过写入虚拟属性来获取节点的写锁定。  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MATCH (n) WITH n.prop as p SET n.prop = k + 1</span><br></pre></td></tr></table></figure></li><li>在同一查询中读取和写入的属性之间的循环依赖性。  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MATCH (n) SET n += &#123;propA: n.propB + 1, propB: n.propA + 1&#125;</span><br></pre></td></tr></table></figure></li></ul><p>  为了在复杂情况下确保行为的确定性，有比远哦在所操作的节点上显式获取写锁定。虽然在 <code>Cypher</code> 中没有明确的支持，但是可以通过写入一个临时属性来解决这个限制就可以了。</p></li></ol><h5 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h5><p>在任何系统中只要使用了锁，那么就会遇到死锁，然而在 <code>Neo4j</code> 中有在死锁发生异常之前会检查任何死锁的机制，在抛出异常之前，事务被标记为回滚。由事务获取的所有锁仍然被保留着，并在事务完成时释放（<code>finally</code> 块中）。因死锁而导致未能执行的事务之后就由用户在需要时进行重试。</p><ol><li><p>死锁处理程序<br>在代码中处理死锁首先需要明确以下问题：</p><ul><li>需要进行有限的重试次数，如果达到阈值则失败。</li><li>在每次尝试之间暂停一下，以允许其他事务完成，然后再次尝试。</li><li>重试循环不仅可以用于死锁，也可以用于其它类型的瞬态错误。</li></ul><p> 使用 <code>TransactionTemplate</code> 处理死锁，他将帮助我们实现所需要的处理。<br> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义基本模板</span></span><br><span class="line"><span class="type">TransactionTemplate</span> <span class="variable">template</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TransactionTemplate</span>().retries(<span class="number">5</span>).backoff(<span class="number">3</span>, TimeUnit.SECONDS);</span><br><span class="line"><span class="comment">// 指定要使用的数据库和要执行的函数</span></span><br><span class="line"><span class="type">Object</span> <span class="variable">result</span> <span class="operator">=</span> template.with(GraphDatabaseService).execute(Transaction -&gt; &#123;</span><br><span class="line"><span class="type">Object</span> <span class="variable">result1</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"><span class="keyword">return</span> result1;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p></li><li><p>使用循环处理死锁</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Throwable</span> <span class="variable">txEx</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"><span class="type">int</span> <span class="variable">RETRIES</span> <span class="operator">=</span> <span class="number">5</span>;</span><br><span class="line"><span class="type">int</span> <span class="variable">BACKOFF</span> <span class="operator">=</span> <span class="number">3000</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; RETRIES; i++) &#123;</span><br><span class="line"><span class="keyword">try</span> (<span class="type">Transaction</span> <span class="variable">tx</span> <span class="operator">=</span> GraphDatabaseService.beginTx()) &#123;</span><br><span class="line"><span class="type">Object</span> <span class="variable">result</span> <span class="operator">=</span> doStuff(tx);</span><br><span class="line">tx.success();</span><br><span class="line"><span class="keyword">return</span> result;</span><br><span class="line">&#125; <span class="keyword">catch</span> (Throwable ex) &#123;</span><br><span class="line">txEx = ex;</span><br><span class="line"><span class="keyword">if</span> (!(ex <span class="keyword">instanceof</span> DeadlockDetectedException)) &#123;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (i &lt; RETRIES - <span class="number">1</span>) &#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">Thread.sleep(BACKOFF);</span><br><span class="line">&#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">TransactionFailureException</span>(<span class="string">&quot;Interrupted&quot;</span>, e);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (txEx <span class="keyword">instanceof</span> TransactionFailureException) &#123;</span><br><span class="line"><span class="keyword">throw</span> ((TransactionFailureException) txEx);</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (txEx <span class="keyword">instanceof</span> Error) &#123;</span><br><span class="line"><span class="keyword">throw</span> ((Error) txEx);</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (txEx <span class="keyword">instanceof</span> RuntimePermission) &#123;</span><br><span class="line"><span class="keyword">throw</span> ((RuntimeException) txEx);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">TransactionFailureException</span>(<span class="string">&quot;Failed&quot;</span>, txEx);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h5 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h5><p><code>Neo4j</code> 提供了三个主要的策略来确保唯一性，即单线程策略、获取或创建策略、消极锁策略。这三种策略可以运行在高可用性集群环境和单实例环境。</p><ol><li><p>单线程策略<br>单线程策略指的是系统中不会存在多个线程去创建同一个实体（节点、关系）。同样，在高可用性集群环境下，外部的单线程也可以在高可用性集群环境和单实例环境。</p></li><li><p>获取或创建策略<br>获取或创建唯一节点的首选方法就是使用唯一性约束和 <code>Cypher</code>。通过使用 <code>put-if-absent</code> 功能，可以使用手动索引来保证实体唯一性。此时手动索引将是一个锁，并且这个锁仅仅锁定用来保证线程和事务唯一性的最小资源。</p></li><li><p>消极锁策略<br>虽然消极锁策略也是一个保证唯一性的策略，但 <code>Neo4j</code> 更推荐使用以上两个策略，如果都不可性再考虑使用消极锁策略。</p></li></ol><h4 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h4><p>过程（<code>Procedure</code>）是以 <code>Java</code> 编写然后部署到数据库中的扩展插件，过程可以在 <code>Cypher</code> 中执行。其中用户自定义过程与数据库的存储过程又有本质的区别，用户自定义过程并不是使用 <code>Cypher</code> 创建的数据操作的集合，而是使用 <code>Java API</code> 创建的数据库功能插件。<br>过程是一种允许 <code>Neo4j</code> 通过编写自定义代码来扩展出更多功能的机制，然后直接通过 <code>Cypher</code> 调用，过程可以接收参数对数据库执行操作并返回相应结果。<br>通过将打包后的 <code>JAR</code> 文件放到每个独立或者集群服务器的 <code>neo4j-home/plugins</code> 目录下来部署到数据库中，每一个部署完成后的数据库都必须重新启动以使新的过程生效。<br>过程是扩展 <code>Neo4j</code> 的首选手段，过程提供的功能如下：</p><ul><li>提供对 <code>Cypher</code> 中不可用的功能的访问，例如手动索引。</li><li>提供对第三方系统的访问。</li><li>执行全局操作，例如对连接的组件计数或查找密集节点。</li><li>实现难以用 <code>Cypher</code> 明确表达的操作。</li></ul><h5 id="调用过程"><a href="#调用过程" class="headerlink" title="调用过程"></a>调用过程</h5><p>调用过程需要使用 <code>Cypher</code> <code>CALL</code> 子句。此外过程名必须是唯一指定的。<code>CALL</code> 语句可以是 <code>Cypher</code> 语句中的唯一子句或者可以与其他子句结合，可以在查询中直接提供参数或从关联的参数集中提取参数。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CALL org.neo4j.example.findMaxNodes(1000);</span><br></pre></td></tr></table></figure><h5 id="用户自定义过程"><a href="#用户自定义过程" class="headerlink" title="用户自定义过程"></a>用户自定义过程</h5><p>自定义过程通过包含代码本以及任何依赖包的 <code>JAR</code> 包文件（不包括 <code>Neo4j</code> 依赖）进行部署。这些文件应放置在每个独立数据库或集群成员的 <code>plugin</code> 目录中，并在下次重启后生效。</p><ol><li><p>创建新项目<br>使用 <code>Maven</code> 创建一个项目，依赖部分中的 <code>neo4j</code> 范围设置为 <code>provided</code>，因为一旦这个过程部署到 <code>Neo4j</code> 实例中，此依赖将由 <code>Neo4j</code> 提供。此外还有测试所需要的依赖库 <code>Neo4j Harness</code>，一个允许启动轻量级 <code>Neo4j</code> 实例的应用程序。<code>Neo4j</code> 驱动程序，用于发送调用过程的 <code>Cypher</code> 语句。<code>JUnit</code> 一个通用的 <code>Java</code> 测试框架。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;org.neo4j&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;neo4j&lt;/artifactId&gt;</span><br><span class="line">&lt;version&gt;$&#123;neo4j.version&#125;&lt;/version&gt;</span><br><span class="line">&lt;scope&gt;provided&lt;/scope&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;org.neo4j.test&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;neo4j-harness&lt;/artifactId&gt;</span><br><span class="line">&lt;version&gt;$&#123;neo4j.version&#125;&lt;/version&gt;</span><br><span class="line">&lt;scope&gt;test&lt;/scope&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;org.neo4j.driver&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;neo4j-java-driver&lt;/artifactId&gt;</span><br><span class="line">&lt;version&gt;<span class="number">1.0</span>-SNAPSHOT&lt;/version&gt;</span><br><span class="line">&lt;scope&gt;test&lt;/scope&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;junit&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;junit&lt;/artifactId&gt;</span><br><span class="line">&lt;version&gt;<span class="number">4.12</span>&lt;/version&gt;</span><br><span class="line">&lt;scope&gt;test&lt;/scope&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure></li><li><p>编写集成测试<br>具体步骤就是首先决定程序要做什么，然后写一个测试用例证明他是正确的，最后写一个能够通过测试的过程。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ManualFullTextIndexTest</span> &#123;</span><br><span class="line"><span class="meta">@Rule</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">Neo4jRule</span> <span class="variable">neo4j</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Neo4jRule</span>().withProcedure(FullTextIndex.class);</span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">shouldAllowIndexingAndFindingANode</span><span class="params">()</span> <span class="keyword">throws</span> Throwable &#123;</span><br><span class="line"><span class="keyword">try</span> (<span class="type">Driver</span> <span class="variable">driver</span> <span class="operator">=</span> GraphDatabase.driver(neo4j.boltURI(), Config.build().withEncryptionLevel(Config.EncryptionLevel.NONE).toConfig())) &#123;</span><br><span class="line"><span class="type">Session</span> <span class="variable">session</span> <span class="operator">=</span> driver.session();</span><br><span class="line"><span class="type">long</span> <span class="variable">nodeId</span> <span class="operator">=</span> session.run(<span class="string">&quot;CREATE (p:User &#123;name: &#x27;Brookreson&#x27;&#125;) RETURN id(p)&quot;</span>).single().get(<span class="number">0</span>).asLong();</span><br><span class="line">session.run(<span class="string">&quot;CALL example.index(&#123;id&#125;, [&#x27;name&#x27;])&quot;</span>, parameters(<span class="string">&quot;id&quot;</span>, nodeId));</span><br><span class="line"><span class="type">StatementResult</span> <span class="variable">result</span> <span class="operator">=</span> session.run(<span class="string">&quot;CALL example.search(&#x27;User&#x27;, &#x27;name:Brook*&#x27;)&quot;</span>);</span><br><span class="line">assertThat(result.single().get(<span class="string">&quot;nodedId&quot;</span>).asLong, equalTo(nodeId));</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>自定义过程<br>完整的示例可以从 <code>Github</code> 上<a href="https://github.com/neo4j-examples/neo4j-procedure-template">找到</a>。下面说一下需要注意的地方：</p><ul><li>所有过程都需要使用 <code>@Procedure</code> 注解。有写入数据库操作的过程，需要另外添加 <code>@PerformsWrites</code>。</li><li>过程的上下文对象要与过程使用的每个资源对象相同，都需要添加 <code>@Context</code> 注解。</li><li>需要了解过程有关输入和输出的详细信息。</li></ul></li></ol><h4 id="在线备份"><a href="#在线备份" class="headerlink" title="在线备份"></a>在线备份</h4><p>以编程方式备份完整或后续增量的数据。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">OnlineBackup</span> <span class="variable">backup</span> <span class="operator">=</span> OnlineBackup.from(<span class="string">&quot;127.0.0.1&quot;</span>);</span><br><span class="line">backup.full(backupPath.getPath());</span><br><span class="line">assertTrue(<span class="string">&quot;Should be consistent&quot;</span>, backup.isConsistent());</span><br><span class="line">backup.incermental(backupPath.getPath());</span><br></pre></td></tr></table></figure><h4 id="JMX-监控"><a href="#JMX-监控" class="headerlink" title="JMX 监控"></a><code>JMX</code> 监控</h4><p>为了连续了解 <code>Neo4j</code> 数据库的运行状况，我们可以使用基于 <code>JMX (Java Management Extensions)</code> 报告运行指标，<code>JMX</code> 作为一个为应用程序、设备、系统等植入管理系统的框架，<code>JMX</code> 可以跨越一系列异构操作平台、系统体系结构和网络传输协议，灵活开发无缝集成系统、网络和服务来管理应用。</p><p>那么如何使用 <code>JMX</code> 接入 <code>Neo4j</code> 呢？要启用此功能，必须在配置文件中将 <code>com.sun.management.jmxremote</code> 选项取消注释。然后重启 <code>Neo4j</code> 和 <code>JConsole</code> 接着就可以在 <code>JConsole</code> 的面板中找到 <code>neo4j</code> 的进程了。</p><hr><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><hr><h3 id="个人备注"><a href="#个人备注" class="headerlink" title="个人备注"></a>个人备注</h3><p><strong>此博客内容均为作者学习所做笔记，侵删！</strong><br><strong>若转作其他用途，请注明来源！</strong></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;Neo4j&lt;/code&gt; 正式支持 &lt;code&gt;.Net&lt;/code&gt; 、 &lt;code&gt;Java&lt;/code&gt; 、 &lt;code&gt;JavaScript&lt;/code&gt; 、 &lt;code&gt;Ruby&lt;/code&gt; 、 &lt;code&gt;PHP&lt;/code&gt; 和 &lt;code&gt;Python&lt;/code&gt; 的二进制 &lt;code&gt;Bolt&lt;/code&gt; 协议驱动程序。这些开发平台通过引入相应的驱动程序包便可与 &lt;code&gt;Neo4j&lt;/code&gt; 相互集成，然后就可以对 &lt;code&gt;Neo4j&lt;/code&gt; 进行数据操作。&lt;/p&gt;
&lt;h3 id=&quot;入门&quot;&gt;&lt;a href=&quot;#入门&quot; class=&quot;headerlink&quot; title=&quot;入门&quot;&gt;&lt;/a&gt;入门&lt;/h3&gt;&lt;p&gt;目前 &lt;code&gt;Neo4j&lt;/code&gt; 支持三种开发模式，分别为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Java&lt;/code&gt; 嵌入式开发模式。&lt;code&gt;Neo4j&lt;/code&gt; 是基于 &lt;code&gt;Java&lt;/code&gt; 语言开发的，所以他能与 &lt;code&gt;Java&lt;/code&gt; 开发天然结合，完全可以在代码中调用 &lt;code&gt;Neo4j&lt;/code&gt; 的 &lt;code&gt;API&lt;/code&gt;，并将对 &lt;code&gt;Neo4j&lt;/code&gt; 数据库的操作嵌入在 &lt;code&gt;Java&lt;/code&gt; 代码中。&lt;/li&gt;
&lt;li&gt;驱动包开发模式。通过 &lt;code&gt;HTTP&lt;/code&gt; 的 &lt;code&gt;HTTP API&lt;/code&gt; 的驱动包让非基于 &lt;code&gt;JVM&lt;/code&gt; 的开发平台、编程语言也能够操作 &lt;code&gt;Neo4j&lt;/code&gt; 数据库。&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    
    <category term="Neo4j" scheme="https://blog.vgbhfive.cn/tags/Neo4j/"/>
    
  </entry>
  
  <entry>
    <title>Neo4j系列博客-数据库管理</title>
    <link href="https://blog.vgbhfive.cn/Neo4j%E7%B3%BB%E5%88%97%E5%8D%9A%E5%AE%A2-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86/"/>
    <id>https://blog.vgbhfive.cn/Neo4j%E7%B3%BB%E5%88%97%E5%8D%9A%E5%AE%A2-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86/</id>
    <published>2022-02-26T02:54:48.000Z</published>
    <updated>2023-01-01T15:59:15.809Z</updated>
    
    <content type="html"><![CDATA[<h3 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h3><p>部署主要包括：容量规划、单实例或集群安装及安装后的相关处理。</p><h4 id="系统需求"><a href="#系统需求" class="headerlink" title="系统需求"></a>系统需求</h4><p>运行一个 <code>Neo4j</code> 数据库实例所需的系统需求清单：</p><ul><li><code>CPU</code>：通常性能受限于内存容量和磁盘 <code>I/O</code> 容量。推荐配置：<code>Intel Core i7, IBM POWER8</code></li><li>内存：图越大则所需内存越多。推荐配置：<code>16~32GB</code> 或更多。</li><li>磁盘：磁盘性能是最重要的指标。推荐配置：<code>SSD w/ SATA</code>。</li><li>文件系统：由于普通 <code>Linux / UNIX</code> 系统中存在的缓冲区高速缓存或页面高速缓存，大多数磁盘都是经过缓存进行的。因此当系统发生故障时，这种延迟可能会造成文件更新内容的丢失。推荐配置：<code>ext4 / ZFS</code>。</li><li>软件：<code>Neo4j</code> 需要一个 <code>Java</code> 虚拟机，因此 <code>Neo4j</code> 中都会提前预装 <code>JVM</code>。</li></ul><span id="more"></span><h4 id="文件位置"><a href="#文件位置" class="headerlink" title="文件位置"></a>文件位置</h4><p>默认情况下 <code>Neo4j</code> 安装后的重要文件及目录如下：（此处为 <code>Linux / UNIX</code> 发行版本的文件目录）</p><ul><li><code>Configuration</code>： <code>&lt;neo4j-home&gt;/conf/neo4j.conf</code></li><li><code>Data</code>： <code>&lt;neo4j-home&gt;/data</code></li><li><code>Logs</code>： <code>&lt;neo4j-home&gt;/logs</code></li><li><code>Metrics</code>： <code>&lt;neo4j-home&gt;/metrics</code></li><li><code>Import</code>： <code>&lt;neo4j-home&gt;/import</code></li><li><code>Bin</code>： <code>&lt;neo4j-home&gt;/bin</code></li><li><code>Lib</code>： <code>&lt;neo4j-home&gt;/lib</code></li><li><code>Plugins</code>： <code>&lt;neo4j-home&gt;/plugins</code></li></ul><p><code>Log</code> 文件位置：</p><ul><li><code>neo4j.log</code>： 标准日志。</li><li><code>debug.log</code>： 调试 <code>Neo4j</code> 的日志。</li><li><code>http.log</code>： <code>HTTP API</code> 的请求日志。</li><li><code>gc.log</code>： <code>JVM</code> 提供的垃圾收集日志。</li><li><code>query.log</code>： 记录超过设定查询时间阈值的查询日志（仅限企业版）。</li><li><code>security.log</code>： 数据库安全事件日志（仅限企业版）。</li><li><code>service-error.log</code>： 安装或运行 <code>Windows</code> 服务时遇到的错误日志（仅限 <code>Windows</code>）。</li></ul><p>可以使用 <code>dbms.directions.*</code> 配置对数据库部分路径进行修改，<code>&lt;neo4j-home&gt;, bin, conf, certificates</code> 的位置可以使用环境变量进行配置。</p><p><code>Neo4j</code> 数据库运行的用户必须对相应的文件夹和文件具有以下权限：</p><ul><li>只读权限： <code>conf, import, bin, lib, plugins</code>。</li><li>读写权限： <code>data, logs, metrcis</code>。</li><li>执行权限： <code>bin</code> 目录中的所有文件。</li></ul><h4 id="端口"><a href="#端口" class="headerlink" title="端口"></a>端口</h4><p><code>Neo4j</code> 使用到的主要端口：</p><ul><li>6362： 备份端口。默认情况下禁用备份功能。</li><li>7474： <code>HTTP</code> 服务端口。建议生产环境下不打开此端口，因为未加密。</li><li>7473： 由 <code>REST API</code> 使用。</li><li>7687： 由 <code>Cypher-Shell</code> 和 <code>Neo4j</code> 浏览器使用。</li><li>5000, 6000, 7000： 因果集群端口。列出的端口是配置文件中的默认端口，端口在实际使用中可能不同，须做相应的修改。</li><li>5001, 6001： 高性能集群端口。列出的端口是配置文件中的默认端口，端口在实际使用中可能不同，须做相应的修改。</li><li>2003： <code>Graphite</code> 监控端口。<code>Neo4j</code> 数据库与 <code>Graphite</code> 服务器通信的端口。</li><li>3637： <code>JMX</code> 监控端口。不推荐采用这种检查数据库的方式，默认情况下不启用。</li><li>1337： <code>Neo4j-shell</code> 工具使用的端口，现已被弃用。</li></ul><h4 id="初始密码"><a href="#初始密码" class="headerlink" title="初始密码"></a>初始密码</h4><p>使用 <code>neo4j-admin</code> 的 <code>set-inital-password</code> 命令设定当前用户的 <code>neo4j</code> 数据库密码，此操作必须在首次启动数据库之前执行。<br>语法为：<code>neo4j-admin set-inital-password &lt;password&gt;</code>。<br>如果未使用此方法显式设置密码，<code>Neo4j</code> 数据库将其设置为默认密码 <code>neo4j</code>，该密码可在首次登录时依据提示来更改此默认密码。</p><h4 id="数据收集器"><a href="#数据收集器" class="headerlink" title="数据收集器"></a>数据收集器</h4><p><code>Neo4j</code> 使用数据收集器（<code>UDC</code>）收集使用数据的信息，并提供给官方的 <code>UDC</code> 服务器（网址为： <code>udc.neo4j.com</code>），该数据收集器可以禁用，并且不收集任何机密信息。<br><code>Neo4j</code> 数据库默认开启 <code>UDC</code> 程序，并伴随数据库启动而自动运行，<code>UDC</code> 将在数据库正常运行的 10 分钟后才发送第一个 <code>ping</code> 命令，这样做有两个考虑：首先不希望启动 <code>UDC</code> 而使数据库变慢，其次希望将自动 <code>ping</code> 测试保持最少。</p><h4 id="配置-Neo4j-连接器"><a href="#配置-Neo4j-连接器" class="headerlink" title="配置 Neo4j 连接器"></a>配置 <code>Neo4j</code> 连接器</h4><p>应用程序与 <code>Neo4j</code> 数据库之间通信需要有相应的机制作为保障，从而 <code>Neo4j</code> 连接器应用而生，支持 <code>Bolt</code> 二进制协议或者 <code>HTTP/HTTPS</code> 方式，极大的方便了应用程序的开发。<br>默认情况下可配置三种不同的 <code>Neo4j</code> 连接器：<code>Bolt</code> 连接器、<code>HTTP</code> 连接器和 <code>HTTPS</code> 连接器。</p><p>每种 <code>Neo4j</code> 连接器均有三个参数：</p><ul><li><code>enabled</code>： 启用或禁用连接器。</li><li><code>listen_address</code>： 设定指定 <code>Neo4j</code> 如何监听传入链接，它由两部分组成：网络 <code>IP</code> 地址和端口号，并以格式 “网络 <code>IP</code> 地址 <code>:</code> 端口号” 表示。</li><li><code>advertised_address</code>： 设定指定客户端使用该连接器的地址。</li><li><code>dbms.connectors.default_listen_address</code>： 所有连接器的 <code>listen_address</code> 的默认网络接口地址。</li><li><code>dbms.connectors.default_advertised_address</code>： 所有连接器的 <code>advertised_address</code> 的默认网络接口地址。</li></ul><h4 id="证书"><a href="#证书" class="headerlink" title="证书"></a>证书</h4><p>默认情况下，<code>Neo4j</code> 数据库在与官方驱动配套程序使用时，将采用 <code>TLS</code> 协议加密苏哦有客户服务器通信，包括 <code>Bolt</code> 和 <code>HTTP</code> 协议，这能确保应用程序与数据库之间的安全可靠通信。<br>如果需要使用自己的 <code>SSL</code> 证书，则需要这两个文件分别命名为 <code>neo4j.key</code> 和 <code>neo4j.cert</code>。其中密钥文件 <code>neo4j.key</code> 是不加密的，需要正确设置该文件的权限，以便只有 <code>Neo4j</code> 用户能够读取它。先将此文件放入指定的目录中，默认在 <code>&lt;neo4j-home&gt;/certificates</code> 目录下，也可通过在 <code>neo4j.conf</code> 中设置 <code>dbms.connectories.certificates</code> 来指定证书文件的存放路径，默认为 <code>certificates</code>（相对路径）。</p><hr><h3 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h3><p><code>Neo4j</code> 数据库提供了一个简单直观的 <code>Web</code> 监控界面，通过浏览器方式访问 <code>Neo4j</code> 数据库。主要包含：磁盘利用情况、缓存活跃情况和集群情况。<br>集群情况中包含了众多的界面参数：</p><ul><li><code>Store Sizes</code>： 存储容量。</li><li><code>ID Allocation</code>： <code>ID</code> 分配。</li><li><code>Page Cache</code>： 页面缓存。</li><li><code>Transactions</code>： 事务。</li></ul><h4 id="指标"><a href="#指标" class="headerlink" title="指标"></a>指标</h4><p><small>指标的功能仅企业版支持。</small><br><code>Neo4j</code> 可以配置为以下两种不同的方式来呈现指标：</p><ul><li>将指标导出为 <code>CSV</code> 文件。</li><li>向 <code>Graphite</code> 或基于 <code>Graphite</code> 协议的任何监控工具发送指标。</li></ul><ol><li><p>启用指标记录</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">metrics.neo4j.enabled=true</span><br><span class="line">metrics.neo4j.tx.enabled=true</span><br><span class="line">metrics.neo4j.pagecache.enabled=true</span><br><span class="line">metrics.neo4j.counts.enabled=true</span><br><span class="line">metrics.neo4j.network.enabled=true</span><br></pre></td></tr></table></figure></li><li><p><code>Graphite</code><br>将以下设置添加到 <code>neo4j.conf</code> 配置文件中，以开启与 <code>Graphite</code> 的集成，从而启动 <code>Neo4j</code> 连接到 <code>Graphite</code> 来监控 <code>Neo4j</code> 的各项指标。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">metrics.graphite.enabled=true</span><br><span class="line">metrics.graphite.server=localhost:2003</span><br><span class="line">metrics.graphite.interval=3m</span><br><span class="line">metrics.prefix=Neo4j_1</span><br></pre></td></tr></table></figure></li><li><p><code>CSV</code> 文件<br>将以下设置添加到 <code>neo4j.conf</code> 配置文件中，以便将各项指标导出到本地 <code>CSV</code> 文件中。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">metrics.csv.enabled=true</span><br><span class="line"># default is a metrics directory under neo4j-home</span><br><span class="line"># metrics.csv.path=&#x27;/local/fiel/system/path&#x27;</span><br><span class="line">metrics.csv.interval=3m</span><br></pre></td></tr></table></figure></li><li><p>可用通用指标<br>建议查书或者官方网站。</p></li></ol><h4 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h4><p><code>Neo4j</code> 日志分为安全日志和查询日志两种，用于记录数据库的查询和发生的安全事件。</p><h5 id="查询日志"><a href="#查询日志" class="headerlink" title="查询日志"></a>查询日志</h5><ul><li><code>dbms.logs.query.enabled=fasle</code>： 是否记录数据库所执行的查询。</li><li><code>dbms.logs.query.paramter_logging_enabled=true</code>： 是否设定查询耗时超过配置阈值。</li><li><code>dbms.logs.query.threshold=0</code>： 用于设定记录查询的阈值，即如果查询执行所花费的时间大于此阈值，则记录此查询（前提是启用查询日志记录）。</li><li><code>query.log</code>： 设置查询日志的文件名，存储在 <code>Logs</code> 目录中，当然也可以在 <code>neo4j.conf</code> 配置文件中配置查询日志的轮换。</li><li><code>dbms.logs.query.ratation.keep_number=7</code>： 设置保存历是查询日志文件的数量。</li><li><code>dbms.logs.query.ratation.size=20MB</code>： 查询日志自动轮换的文件大小。</li></ul><h5 id="安全事件日志"><a href="#安全事件日志" class="headerlink" title="安全事件日志"></a>安全事件日志</h5><p><code>Neo4j</code> 数据库安全事件日志功能用于记录所有的安全事件，对于本机用户管理，将记录以下操作：</p><ul><li>登陆尝试，每个默认值都记录成功和不成功的登录。</li><li>更改用户的密码、管理员和用户。</li><li>创建和删除用户，包括失败的尝试。</li><li>创建和删除自定义角色，包括失败的尝试。</li><li>为用户分配和删除角色，包括失败的尝试。</li><li>暂停和激活用户。</li><li>非管理员用户尝试列出用户和角色的失败尝试。</li></ul><p><small>如果使用 <code>LDAP</code> 作为身份验证方法，还会记录一些 <code>LDAP</code> 配置错误的情况，以及 <code>LDAP</code> 服务器通信事件和故障。</small></p><p>安全事件日志文件名为 <code>security.log</code>，存放在 <code>Logs</code> 目录中，可以在 <code>neo4j.conf</code> 配置文件中配置安全事件日志的轮换。</p><ul><li><code>dbms.logs.security.rotation.size=20MB</code>： 安全事件日志自动轮换的文件大小。</li><li><code>dbms.logs.security.rotation.delay=300s</code>： 设置在最后一次日志轮换发生后，日志可能再次轮换之前的最小时间间隔。</li><li><code>dbms.logs.security.rotation.keep_number=7</code>： 设置保存安全事件日志的文件数量。</li></ul><h4 id="查询管理"><a href="#查询管理" class="headerlink" title="查询管理"></a>查询管理</h4><p><code>Neo4j</code> 提供了相应的手段可从安全性或性能角度对查询语句进行检查。查询日志可用于数据库的连续监控和故障排除，事务超时功能可以为查询设定最大的运行时间，查询管理则可查看数据库中运行的查询，必要时可以终止某个查询。</p><h5 id="事务超时"><a href="#事务超时" class="headerlink" title="事务超时"></a>事务超时</h5><p>执行保护功能可以终止某执行时间超过配置超时时间的事务。<br><code>dbms.transaction.timeout=10s</code> 表示设定事务超时时间为 <code>10s</code>，而当设定值为 <code>0s</code> 时，则为禁用执行保护。</p><p><small>此功能对使用自定义超时（通过 <code>Java API</code>）指定的事务不产生影响。</small></p><h5 id="查询管理-1"><a href="#查询管理-1" class="headerlink" title="查询管理"></a>查询管理</h5><p><small>此功能仅在企业版中支持。</small></p><ol><li><p>列出所有的查询<br>管理员可以查询到当前运行中的所有查询，而当前用户仅可以查看到自己当前运行的所有查询。<br>语法为： <code>CALL dbms.listQueries();</code></p></li><li><p>终止多个查询<br>管理员可以终止给定查询 <code>ID</code> 列表的事务，而当前用户仅可以终止自己创建的事务。<br>语法为： <code>CALL dbms.killQueries(ids);</code>，其中 <code>ids</code> 为 <code>List&lt;String&gt;</code> 类型，是需要终止的事务 <code>ID</code> 的列表。</p></li><li><p>终止一个查询<br>管理员可以终止给定查询 <code>ID</code> 列表的任意一个事务，而当前用户仅可以终止自己创建的一个事务。<br>语法为： <code>CALL dbms,killQuery(id);</code>，类型为 <code>String</code> 类型，是需要终止的事务 <code>ID</code>。</p></li></ol><h4 id="因果集群监控"><a href="#因果集群监控" class="headerlink" title="因果集群监控"></a>因果集群监控</h4><ol><li><p>查询因果集群核心服务器<br>可以在因果集群的每个实例上调用过程 <code>dbms.cluster.role()</code> 以返回该实例的角色。<br>语法为： <code>CALL dbms.cluster.role()</code>，返回值为 <code>LEADER, FOLLOWER, READ_REPLICA</code> 三个中的一个，类型为 <code>String</code> 类型。</p></li><li><p>获取因果集群的整体概况<br>函数 <code>dbms.cluster.overview()</code> 返回集群中所有实例的详细信息，以便获取集群的拓扑概述。<br>语法为： <code>CALL dbms.cluster.overview()</code>。</p></li><li><p>获取路由推荐<br>应用程序需要知道哪个实例可以提供所需的服务。<br>语法为： <code>CALL dbms.cluster.routing.getServers()</code>，该过程返回特定服务与提供此服务的实例的地址之间的映射，还返回生存时间（<code>TTL</code>）信息。</p></li></ol><hr><h3 id="安全管理"><a href="#安全管理" class="headerlink" title="安全管理"></a>安全管理</h3><p>对于 <code>Neo4j</code> 数据库而言，首要的就是数据安全，可通过遵循有关服务器和网络安全性的行业做法确保物理数据安全，再通过适当的身份验证和授权规则来确保 <code>Neo4j</code> 的信息安全。</p><h4 id="社区版用户管理"><a href="#社区版用户管理" class="headerlink" title="社区版用户管理"></a>社区版用户管理</h4><p><code>Neo4j</code> 社区版在安全管理方面相比企业版而言，功能较弱，仅提供用户和密码管理，没有涉及角色、权限控制等企业必需的安全管理功能。本地用户和角色管理通过使用内置的 <code>Cypher</code> 过程进行管理。</p><ol><li><p><code>dbms.security.listUsers</code><br>当前用户查看系统中所有用户的详细信息。<br>语法为：<code>CALL dbms.security.listUsers();</code>，返回值为：<code>username</code> 和 <code>flags</code>。</p></li><li><p><code>dbms.security.changePassword</code><br>当前用户更改自己的密码。<br>语法为：<code>CALL dbms.security.changePassword(password);</code>，其中参数为当前用户的新密码。</p></li><li><p><code>dbms.security.showCurrentUser</code><br>显示当前用户详情，并显示是否需要更改密码。<br>语法为：<code>CALL dbms.security.showCurrentUser();</code>，返回值为 <code>username</code> 和 <code>falgs</code>。</p></li><li><p><code>dbms.security.createUser</code><br>将用户添加到 <code>Neo4j</code> 社区版系统。<br>语法为：<code>CALL dbms.scurity.createUser(usernaem, password, requirePasswordChange);</code>，其中 <code>username</code> 和 <code>password</code> 为新添加用户的用户名和密码，<code>requirePasswordChange</code> 表示是否需要修改密码。</p></li><li><p><code>dbms.security.deleteUser</code><br>从系统中永久删除用户。<br>语法为：<code>CALL dbms,security.deleteUser();</code>，其中 <code>username</code> 为待删除的用户名。</p></li></ol><h4 id="LDAP-集成"><a href="#LDAP-集成" class="headerlink" title="LDAP 集成"></a><code>LDAP</code> 集成</h4><p><code>LDAP</code> 协议以 <code>X.500</code> 标准为基础，但与 <code>X.500</code> 相比 <code>LDAP</code> 更简单，它可根据需要定制，并支持 <code>TCP/IP</code> 协议，因此使用非常广泛。<br><code>Neo4j</code> 本身支持 <code>LDAP</code> 协议，包括：<code>Active Directory</code>、<code>OpenLDAP</code> 或者其他的 <code>LDAP</code> 兼容的身份验证服务。所有设置都需要在服务器启动时在默认配置文件 <code>neo4j.conf</code> 中进行设定。</p><ol><li><p>配置<code>Neo4j</code> 使用 <code>LDAP</code> 作为身份验证和授权提供方。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dbms.security.auth_enabled=true</span><br><span class="line">dbms.security.auth_provider=ldap</span><br></pre></td></tr></table></figure></li><li><p>配置活动目录。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">dbms.security.ldap.host=ldap://myactivedirectiory.example.com</span><br><span class="line">dbms.security.ldap.authentication.user_dn_template=cn=[0],cn=Users,dc=example,dc=com</span><br><span class="line">dbms.security.ldap.authentication.user_search_base=cn=Users,dc=example,dc=com</span><br><span class="line">dbms.security.ldap.authentication.user_search_filter=cn=(&amp;(objextClass=*)(cn=&#123;0&#125;))</span><br><span class="line">dbms.security.ldap.authentication.group_membership_attributes=memberOf</span><br><span class="line">dbms.security.ldap.authentication.group_to_role_mapping=\</span><br><span class="line">&quot;cn=Neo4j Read Only,cn=Users,dc=neo4j,dc=com&quot; = reader ;\</span><br><span class="line">&quot;cn=Neo4j Read-Write,cn=Users,dc=neo4j,dc=com&quot; = publisher ;\</span><br><span class="line">&quot;cn=Neo4j Schema Manager,ch=Users,dc=neo4j,dc=com&quot; = architect ;\</span><br><span class="line">&quot;cn=Neo4j Administrator,cn=Users,dc=neo4j,dc=com&quot; = admin ;\</span><br><span class="line">&quot;cn=Neo4j Procedures,cn=Users,dc=neo4j,dc=com&quot; = allowed_role ;\</span><br></pre></td></tr></table></figure></li></ol><h5 id="ldapsearch-工具"><a href="#ldapsearch-工具" class="headerlink" title="ldapsearch 工具"></a><code>ldapsearch</code> 工具</h5><p>可以使用 <code>LDAP</code> 命令行工具 <code>ldapsearch</code> 来验证配置是否正确、<code>LDAP</code> 服务器是否正在响应，可以通过发送包含 <code>LDAP</code> 配置设置值的搜索命令来执行此项操作。</p><ol><li><p>参数 <code>dbms.security.ldap.authorization.use_system_account=true</code> 的验证为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># ldapsearch -v -H ldap://&lt;dbms.security.ldap.host&gt; -x -D &lt;dbms.security.ldap.authentication.system_username&gt; -w &lt;dbms.security.ldap.authentication.system_password&gt; -b &lt;dbms.security.ldap.authentication.user_search_base&gt; &quot;&lt;dbms.security.ldap.authentication.user_search_filter&gt;&quot; &lt;dbms.security.ldap.authentication.group_membership_attributes&gt;</span><br><span class="line"># ldapsearch -v -H ldap://myactivedirectiory.example.com:389 -x -D cn=search-account,cn=Users,dc=example,dc=com -w secret -b cn=Users,dc=example,dc=com &quot;cn=(&amp;(objextClass=*)(cn=john))&quot; memberOf</span><br></pre></td></tr></table></figure></li><li><p>参数 <code>dbms.security.ldap.authorization.use_system_account=false</code> 的验证为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># ldapsearch -v -H ldap://&lt;dbms.security.ldap.host&gt; -x -D &lt;dbms.security.ldap.authentication.user_dn_template : replace &#123;0&#125;&gt; -W -b &lt;dbms.security.ldap.authentication.user_search_base&gt; &quot;&lt;dbms.security.ldap.authentication.user_search_filter : replace &#123;0&#125;&gt;&quot; &lt;dbms.security.ldap.authentication.group_membership_attributes&gt;</span><br><span class="line"># ldapsearch -v -H ldap://myactivedirectiory.example.com:389 -x -D cn=search-account,cn=Users,dc=example,dc=com -W -b cn=Users,dc=example,dc=com &quot;cn=(&amp;(objextClass=*)(cn=john))&quot; memberOf</span><br></pre></td></tr></table></figure></li></ol><h5 id="认证缓存"><a href="#认证缓存" class="headerlink" title="认证缓存"></a>认证缓存</h5><p>认证缓存（<code>Auth Cache</code>）是 <code>Neo4j</code> 通过 <code>LDAP</code> 服务器缓存认证结果以提升性能的机制，它采用 <code>dbms.security.ldap.autnentication.cache_enabled</code> 和 <code>dbms.security.auth_cache_ttl</code> 参数进行配置。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dbms.security.ldap.authentication.cache_enabled=true</span><br><span class="line">dbms.security.auth_cache_ttl=10m</span><br></pre></td></tr></table></figure><p>管理员可以手动清除身份验证缓存，以强制重新查询来自联合身份验证提供的系统身份验证和授权信息，可以在 <code>Neo4j</code> 浏览器或 <code>Neo4j Cypher Shell</code> 中执行语句：<code>CALL dbms.security.clearAuthCache();</code> 即可。</p><p>可以采用 <code>StartTLD</code> 来配置对活动目录的加密。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dbms.security.ldap.use_startls=true</span><br><span class="line">dbms.security.ldap.host=ldap://myactivedirectory.example.com</span><br><span class="line"># 也可以使用 LDAPS 来配置活动目录</span><br><span class="line">dbms.security.ldap.host=ldaps://myactivedirectory.example.com:636</span><br></pre></td></tr></table></figure><p>在实际生产环境中，建议使用由证书颁发机构颁发的 <code>SSL</code> 证书来确保对 <code>LDAP</code> 服务器的安全访问。可以在 <code>neo4j.conf</code> 中使用参数 <code>dbms.jvm.addtional</code> 来指定证书的详细信息，以告知 <code>Neo4j</code> 本地证书的位置。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dbms.jvm.addtional=-Djavax.net.ssl.keyStore=MyCert.key</span><br><span class="line">dbms.jvm.addtional=-Djavax.net.ssl.keyStorePassword=secret</span><br><span class="line">dbms.jvm.addtional=-Djavax.net.ssl.trustStore=MyCert.jks</span><br><span class="line">dbms.jvm.addtional=-Djavax.net.ssl.trustStorePassword=secret</span><br></pre></td></tr></table></figure><h4 id="子图访问控制"><a href="#子图访问控制" class="headerlink" title="子图访问控制"></a>子图访问控制</h4><p>通过使用用户定义的过程和自定义角色，管理员可以将用户的访问和动作限制到图中的指定部分，即：可以在子图的级别配置访问控制。<br>自定义角色是由 <code>Neo4j</code> 数据库管理员创建和删除，仅用于控制执行某些自定义开发的过程，与数据库自带的角色相比，自定义角色的权限需要在 <code>neo4j.conf</code> 中显式准许。</p><h5 id="管理自定义角色"><a href="#管理自定义角色" class="headerlink" title="管理自定义角色"></a>管理自定义角色</h5><ol><li><p>本机用户场景<br>创建自定义角色，然后将此角色分配给相关用户。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 创建 accounting 角色并将其分配给预先存在的 billsmith 用户</span><br><span class="line">CALL dbms.security.createRole(&#x27;accounting&#x27;)</span><br><span class="line">CALL dbms.security.addRoleToUser(&#x27;accounting&#x27;, &#x27;billsmith&#x27;)</span><br></pre></td></tr></table></figure></li><li><p>联合用户场景（<code>LDAP</code>）<br>在 <code>LDAP</code> 方案中，<code>LDAP</code> 用户组必须映射到 <code>Neo4j</code> 中的自定义角色。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 将组号 101 的 LDAP 组映射到自定义 accounting 角色</span><br><span class="line">dbms.security.realms.ldap.authorization.group_to_role_mapping=101=accounting</span><br></pre></td></tr></table></figure></li></ol><h5 id="配置过程的权限"><a href="#配置过程的权限" class="headerlink" title="配置过程的权限"></a>配置过程的权限</h5><p>需要自行创建读或写数据的过程（<code>Procedure</code>），自然内置或第三方库自带的过程除外，此过程与普通 <code>Cypher</code> 语句执行的安全规则相同。<br>可以使用配置选项 <code>dbms.security.procedures.default_allowed</code> 和 <code>dbms.security.procedures.roles</code> 来准许特定角色执行相应的访问过程。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 具有 Convert 角色的用户都可执行 apoc.convert 命名空间中的所有过程</span><br><span class="line">dbms.security.procedures.roles = apoc.convert.*:Convert;apoc.load.json.*:Convert,DataSource;apoc.trigger.add:TriggerHappy</span><br></pre></td></tr></table></figure><h4 id="安全清单"><a href="#安全清单" class="headerlink" title="安全清单"></a>安全清单</h4><p>安全清单为 <code>Neo4j</code> 数据库安全性建议的总结。</p><ul><li>在安全网络及安全服务器上部署 <code>Neo4j</code>，使用子网和防火墙，只打开必要的端口。</li><li>保护静态数据，使用卷加密，管理对数据库转换和备份的访问。</li><li>保护传输中的数据，对远程访问 <code>Neo4j</code> 数据库，只打开加密的 <code>Bolt</code> 或 <code>HTTPS</code> 访问链接，使用受信任证书颁发机构颁发的 <code>SSL</code> 证书。</li><li>验证部署的任何自定义代码（过程和非托管扩展）。</li><li>确保 <code>Neo4j</code> 文件正确的文件权限。</li><li>如果启用了 <code>LOAD CSV</code> 函数操作，确保未授权用户不可导入数据。</li><li>检查 <code>neo4j.conf</code> 文件，了解已弃用函数和远程 <code>JMX</code> 相关的端口。</li><li>使用 <code>Neo4j</code> 最新的补丁版本。</li></ul><hr><h3 id="运维与优化"><a href="#运维与优化" class="headerlink" title="运维与优化"></a>运维与优化</h3><p>本节介绍影响操作性能的因素，以及如何调整 <code>Neo4j</code> 以获得最佳吞吐量。</p><h4 id="内存调优"><a href="#内存调优" class="headerlink" title="内存调优"></a>内存调优</h4><p><code>Neo4j</code> 在启动时将自动配置内存相关参数的默认值，并默认可使用机器上的所有内存。<br>有三种类型的内存需要考虑：</p><ul><li>操作系统内存。</li><li>页面缓存。</li><li>堆空间。</li></ul><p><small>需要注意的是，操作系统内存不能显式配置，而实指定页面缓存和堆空间之后所剩余的内存。</small></p><ol><li><p>操作系统内存大小<br>必须为服务器上与 <code>Neo4j</code> 数据库不相关的其他程序预留一些内存。<br><code>1 GB</code> 内存是 <code>Neo4j</code> 服务器的最低配置。基本的计算方法如下： <code>系统内存 = 1GB + (graph.db / index) + (graph.db / schema)</code>。</p></li><li><p>页面缓存大小<br>页面缓存用于缓存存储在磁盘上的 <code>Neo4j</code> 数据，确保将来自磁盘的所有或至少大部分图数据缓存到内存中。<br>可通过简单的方法确定页面缓存的大小：汇总含 <code>&lt;neo4j-home&gt;/data/database/graph.db/*store.db*</code> 的所有文件大小，再增加 <code>20%</code> 的预留。<br>指定页面缓存的参数是 <code>dbms.memory.pagecache.size</code> 该参数设定允许 <code>Neo4j</code> 使用多少内存用于高速缓存。如果在启动时没有明确指定，<code>Neo4j</code> 将给予默认配置： <code>(机器可用内存 - JVM 最大堆分配) * 50%</code>。</p></li><li><p>堆大小<br>可用堆大小是影响 <code>Neo4j</code> 性能的一个重要因素。大多数 <code>Neo4j</code> 应用，堆大小设置为 <code>8~16GB</code> 之间即可稳定运行。在文件 <code>&lt;neo4j-home&gt;/conf/neo4j-wrapper.conf</code> 中设置 <code>dbms.memory.heap.initial_size</code> 和 <code>dbms.memory.heap_max_size</code> 参数即可，以兆字节为单位。（建议将这两个参数设置为相同的值，以避免不必要的垃圾收集）</p></li><li><p>调整垃圾收集器<br>建议使用并发垃圾收集器。</p></li><li><p>因此内存调优可按照如下步骤进行：</p><ul><li>计划操作系统内存大小。</li><li>计划页面缓存大小调整。</li><li>计划堆空间大小。</li><li>做合理的检查，实际操作系统内存分配 &#x3D; 可用内存 - （页面缓存 + 堆空间大小）。</li></ul></li></ol><h4 id="压缩存储"><a href="#压缩存储" class="headerlink" title="压缩存储"></a>压缩存储</h4><p>在很多情况下，<code>Neo4j</code> 可以压缩和内联存储属性值，其目的在于节省磁盘空间和提高 <code>I/O</code> 操作性能。</p><p>短数组的压缩存储采用<strong>位剃削</strong>算法，以减少存储数组中成员的位数。步骤如下：</p><ul><li>对于数组的每个成员，确定最左边设置位的位置。</li><li>确定数组中所有成员中最大的位置。</li><li>他将所有成员减少到该位数。</li><li>存储这些值，前缀为一个小标题。</li></ul><p><small>当在数组中包括单个负值时，将使用原始字节大小来存储。</small></p><h4 id="Linux-文件系统调优"><a href="#Linux-文件系统调优" class="headerlink" title="Linux 文件系统调优"></a><code>Linux</code> 文件系统调优</h4><p><code>Neo4j</code> 数据库在查询数据时通常会产生许多少量、随机的读操作，而在提交更改时经常会产生少量的顺序写操作。<br>因此修改 <code>Linux</code> 使用的完全公平排队（<code>Completely Fair Queuing, CFQ</code>）算法来调度 <code>IO</code> 请求，将其修改为期限调度器（<code>Deadline Scheduler</code>）更适合数据库的特定 <code>IO</code> 工作负载情形。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$echo &#x27;deadline&#x27; &gt; /sys/block/sda/queue/scheduler</span><br><span class="line">$cat /sys/block/sda/queue/scheduler</span><br><span class="line">noop [deadline] cfq</span><br></pre></td></tr></table></figure><h4 id="磁盘、内存及相关提示"><a href="#磁盘、内存及相关提示" class="headerlink" title="磁盘、内存及相关提示"></a>磁盘、内存及相关提示</h4><p>与其他的持久化方案一致，性能取决于使用的持久化介质，这就意味着更好的磁盘等于更好的性能。<br>存储文件保存在低寻道时间的磁盘上将大大提高读取操作的性能。同时为了减少磁盘访问可以加大内存容量。<br>同时也可以使用 <code>dstat</code> 或 <code>vmstat</code> 等工具来收集应用程序的运行信息。</p><hr><h3 id="备份与恢复"><a href="#备份与恢复" class="headerlink" title="备份与恢复"></a>备份与恢复</h3><p>此功能仅适用于企业版。<br>将 <code>Neo4j</code> 数据库备份到远程或离线存储是一项基本操作，<code>Neo4j</code> 支持全量备份和增量备份，对于三种配置方式（单实例、高可用集群和因果集群）的 <code>Neo4j</code> 数据库，其备份过程是相同的。备份使用 <code>neo4j-bakcup</code> 工具在网络上运行，即可从 <code>Neo4j</code> 服务器备份到本地副本。</p><p>必须配置两个参数才能执行备份：</p><ul><li><code>dbms.backup.enabled=true</code>，启用备份，这是默认值。</li><li><code>dbms.backup.address=&lt;IP&gt;:6362</code>，配置备份服务监听的接口和端口。</li></ul><p><small>这里备份的数据与生产系统没有任何的依赖关系，需要分开存储，如果可以需要遵循<a href="https://guozeyu.com/2018/08/backup/"><strong>321</strong>原则</a>。</small></p><h4 id="执行备份"><a href="#执行备份" class="headerlink" title="执行备份"></a>执行备份</h4><p>备份命令 <code>neo4j-admin</code> 工具位于 <code>bin</code> 目录下，使用 <code>backup</code> 参数运行它，以便对正在运行的数据库执行联机备份。<br>语法为：<code>neo4j-admin backup --backup-dir=&lt;backup-path&gt; --name=&lt;graph.db-backup&gt; [--from=&lt;address&gt;] [--fallback-to-full[=&lt;true|fasle&gt;]] [--check-consistency[=&lt;true|false&gt;]] [--cc-report-dir=&lt;directory&gt;] [--additional-config=&lt;config-file-path&gt;] [--timeout=&lt;timeout&gt;]</code>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">neo4j-admin backup --from=192.168.1.34 --backup-dir=/mnt/backup/neo4j-backup --name=graph.db-backup</span><br></pre></td></tr></table></figure><p>增量备份需指定现有备份目录并且有上次被封以来的事务日志。备份工具将上次备份之后的任何操作进行备份，其结果将是与当前服务器状态一致的更新备份。<br>另外增量备份可能会失败，主要原因在于事务日志被删除且 <code>--fallback-to-full</code> 参数被设置为 <code>false</code>，建议将参数设置为 <code>true</code>，避免在增量备份时失败可以转换为全量备份。同时事务日志的自动轮询时间也是很重要的，配置 <code>dbms.tx_log.rotation.retention_policy</code> 以便事务日志保存在增量备份之间。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">neo4j-admin backup --from=192.168.1.34 --backup-dir=/mnt/backup/neo4j-backup --name=graph.db-backup --fallback-to-full=true --check-consistency=true</span><br></pre></td></tr></table></figure><p>备份因果集群时，核心服务器和只读副本都支持备份协议，都可用于集群备份，但是在生产中更倾向于使用只读副本作为备份，因为只读副本的数量在因果集群部署中远远多于核心服务器。</p><h4 id="恢复备份"><a href="#恢复备份" class="headerlink" title="恢复备份"></a>恢复备份</h4><p><code>Neo4j</code> 备份是全功能的数据库备份。恢复备份，必须关闭数据库，使用 <code>neo4j-admin</code> 工具的 <code>restore</code> 参数恢复备份。<br>语法为：<code>neo4j-admin restore --from=&lt;backup-path&gt; --database=graph.db --force</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">neo4j-admin restore --from=/mnt/backup/neo4j-backup --database=graph.db --force</span><br></pre></td></tr></table></figure><p>从高可用集群环境中的备份进行恢复，请按照以下步骤进行：</p><ul><li>关闭集群中的所有数据库实例。</li><li>恢复每个实例上的备份。</li><li>启动数据库实例。</li></ul><p>恢复 <code>Neo4j</code> 因果集群的步骤与创建因果集群的步骤类似，即首先创建一个新的因果集群，但是不要启动组成集群的实例，而首先进行数据库的恢复。</p><hr><h3 id="相关工具"><a href="#相关工具" class="headerlink" title="相关工具"></a>相关工具</h3><h4 id="Cypher-Shell"><a href="#Cypher-Shell" class="headerlink" title="Cypher Shell"></a><code>Cypher Shell</code></h4><p><code>Cypher Shell</code> 是 <code>Neo4j</code> 数据库的一个命令行工具，可以用于数据库连接、调用 <code>Cypher</code> 语句进行数据查询或定义相关模式和执行管理任务。<br><code>Cypher Shell</code> 采用显式事务方式，允许将多个操作分组一并执行或回滚，通信方式采用加密的二进制 <code>Bolt</code> 协议。<br>语法为：<code>cypher-shell [-h] [-a ADDRESS] [-u USEWRNAME] [-p PASSWORD] [--encryption &#123;true, fasle&#125;] [--format &#123;verbose, plain&#125;] [--debug] [--fail-fast | --fail-at-end] [cypher]</code>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$cypher-shell -u johnode -p secret</span><br><span class="line">neo4j&gt;MATCH (n) RETURn n</span><br></pre></td></tr></table></figure><h4 id="转储和加载"><a href="#转储和加载" class="headerlink" title="转储和加载"></a>转储和加载</h4><p><code>Neo4j</code> 数据转储和加载需要用到 <code>neo4j-admin</code> 命令，该命令可将数据库从一个环境移动到另一个环境，也可用于数据库的脱机备份。<br>命令格式为：<code>neo4j-admin dump --database=&lt;datttabase&gt; --to=&lt;destination-path&gt;</code> 和 <code>neo4j-admin load --from=&lt;archive-path&gt; --database=&lt;database&gt; [--force]</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">neo4j-admin dump --database=graph.db --to=/backups/graph.db/2022-02-27.dump</span><br><span class="line">neo4j-admin load --from=/backups/graph.db/2022-02-27.dump --database=graph.db --force</span><br></pre></td></tr></table></figure><p><small>对于 <code>Neo4j</code> 在版本上的变更导致数据库目录结构的变更，建议 <code>neo4j-admin dump</code> 和 <code>neo4j-admin load</code> 这种更安全的全库导出、导入方式。</small></p><h4 id="一致性检查"><a href="#一致性检查" class="headerlink" title="一致性检查"></a>一致性检查</h4><p>一致性检查可以使用 <code>neo4j-admin</code> 工具的 <code>check-consistency</code> 参数来检查数据库的一致性。<br>该 <code>neo4j-admin</code> 工具位于 <code>bin</code> 目录中，语法调用为：<code>neo4j-admin check-conversistency --database=&lt;database&gt; [--report-dir=&lt;directory&gt;] [--additional-config=&lt;file&gt;] [--verbose]</code>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">neo4j-admin check-conversistency --database=graph.db</span><br></pre></td></tr></table></figure><p>如果一致性检查工具未发现错误，则程序自动运行结束并不生成相应的报告；但如果发生错误，程序将会退出，退出代码为 <code>1</code>，并将错误信息写入到 <code>inconsistencies-YYYY-MM-DD.HH24.MI.SS.report</code> 的报告文件中，此文件位置在当前目录下或者由参数 <code>report-dir</code> 指定。<br>一致性检查工具可以调用由参数 <code>--additional-config</code> 指定的配置文件中的其他配置选项，配置文件的格式与 <code>neo4j.conf</code> 格式相同。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># conversistency-check.properties</span><br><span class="line">tools.conversistency_checker.check_graph=false</span><br><span class="line">tools.conversistency_checker.check_indexes=true</span><br><span class="line">tools.conversistency_checker.check_label_scan_store=true</span><br><span class="line">tools.conversistency_checker.check_property_owners=false</span><br></pre></td></tr></table></figure><p><small>一致性检查工具不能与当前正在使用的数据库一起使用，如果与正在运行的数据库一起使用，这自动停止并输出错误信息。</small></p><hr><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><p><a href="https://guozeyu.com/2018/08/backup/">321原则</a></p><hr><h3 id="个人备注"><a href="#个人备注" class="headerlink" title="个人备注"></a>个人备注</h3><p><strong>此博客内容均为作者学习所做笔记，侵删！</strong><br><strong>若转作其他用途，请注明来源！</strong></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;部署&quot;&gt;&lt;a href=&quot;#部署&quot; class=&quot;headerlink&quot; title=&quot;部署&quot;&gt;&lt;/a&gt;部署&lt;/h3&gt;&lt;p&gt;部署主要包括：容量规划、单实例或集群安装及安装后的相关处理。&lt;/p&gt;
&lt;h4 id=&quot;系统需求&quot;&gt;&lt;a href=&quot;#系统需求&quot; class=&quot;headerlink&quot; title=&quot;系统需求&quot;&gt;&lt;/a&gt;系统需求&lt;/h4&gt;&lt;p&gt;运行一个 &lt;code&gt;Neo4j&lt;/code&gt; 数据库实例所需的系统需求清单：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;CPU&lt;/code&gt;：通常性能受限于内存容量和磁盘 &lt;code&gt;I/O&lt;/code&gt; 容量。推荐配置：&lt;code&gt;Intel Core i7, IBM POWER8&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;内存：图越大则所需内存越多。推荐配置：&lt;code&gt;16~32GB&lt;/code&gt; 或更多。&lt;/li&gt;
&lt;li&gt;磁盘：磁盘性能是最重要的指标。推荐配置：&lt;code&gt;SSD w/ SATA&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;文件系统：由于普通 &lt;code&gt;Linux / UNIX&lt;/code&gt; 系统中存在的缓冲区高速缓存或页面高速缓存，大多数磁盘都是经过缓存进行的。因此当系统发生故障时，这种延迟可能会造成文件更新内容的丢失。推荐配置：&lt;code&gt;ext4 / ZFS&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;软件：&lt;code&gt;Neo4j&lt;/code&gt; 需要一个 &lt;code&gt;Java&lt;/code&gt; 虚拟机，因此 &lt;code&gt;Neo4j&lt;/code&gt; 中都会提前预装 &lt;code&gt;JVM&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    
    <category term="Neo4j" scheme="https://blog.vgbhfive.cn/tags/Neo4j/"/>
    
  </entry>
  
  <entry>
    <title>Neo4j系列博客-Cypher-3</title>
    <link href="https://blog.vgbhfive.cn/Neo4j%E7%B3%BB%E5%88%97%E5%8D%9A%E5%AE%A2-Cypher-3/"/>
    <id>https://blog.vgbhfive.cn/Neo4j%E7%B3%BB%E5%88%97%E5%8D%9A%E5%AE%A2-Cypher-3/</id>
    <published>2022-02-20T08:18:37.000Z</published>
    <updated>2022-11-25T14:00:18.913Z</updated>
    
    <content type="html"><![CDATA[<h3 id="查询调优"><a href="#查询调优" class="headerlink" title="查询调优"></a>查询调优</h3><span id="more"></span><hr><h3 id="执行计划"><a href="#执行计划" class="headerlink" title="执行计划"></a>执行计划</h3><hr><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><hr><h3 id="个人备注"><a href="#个人备注" class="headerlink" title="个人备注"></a>个人备注</h3><p><strong>此博客内容均为作者学习所做笔记，侵删！</strong><br><strong>若转作其他用途，请注明来源！</strong></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;查询调优&quot;&gt;&lt;a href=&quot;#查询调优&quot; class=&quot;headerlink&quot; title=&quot;查询调优&quot;&gt;&lt;/a&gt;查询调优&lt;/h3&gt;</summary>
    
    
    
    
    <category term="TODO" scheme="https://blog.vgbhfive.cn/tags/TODO/"/>
    
    <category term="Neo4j" scheme="https://blog.vgbhfive.cn/tags/Neo4j/"/>
    
  </entry>
  
  <entry>
    <title>MySQL-select查询为空但数据库有数据</title>
    <link href="https://blog.vgbhfive.cn/MySQL-select%E6%9F%A5%E8%AF%A2%E4%B8%BA%E7%A9%BA%E4%BD%86%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9C%89%E6%95%B0%E6%8D%AE/"/>
    <id>https://blog.vgbhfive.cn/MySQL-select%E6%9F%A5%E8%AF%A2%E4%B8%BA%E7%A9%BA%E4%BD%86%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9C%89%E6%95%B0%E6%8D%AE/</id>
    <published>2022-02-20T05:40:01.000Z</published>
    <updated>2023-01-01T15:59:53.960Z</updated>
    
    <content type="html"><![CDATA[<h3 id="问题复现"><a href="#问题复现" class="headerlink" title="问题复现"></a>问题复现</h3><p>年后又是一波需求狂潮，在经历了上一周的痛苦上班时间之后，这周一又开始了新的需求，新的 Code 生活也伴随而来重新开始。</p><p>首先我先简略描述一下本次的需求，我这边负责的后台向服务端的接口推送一条信息，然后服务端会把接收到的信息处理后，同步推送到我们的另一个接口。<br>而在上一步的推送信息之后，我们这边会启动一个异步的任务会在特定的时间段内处理服务端返回的信息。<br>那么问题就来了，在这个异步任务中实时去查询 <code>SQL</code>，但是查询回来的<strong>结果是空的</strong>。</p><span id="more"></span><hr><h3 id="问题处理步骤"><a href="#问题处理步骤" class="headerlink" title="问题处理步骤"></a>问题处理步骤</h3><ol><li><p>开启 <code>debug</code> 查看 <code>SQL</code> 语句的执行记录，并检查参数格式是否正确。</p></li><li><p>检查 <code>SQL</code> 执行无误后，本地模拟线上处理流程，本地无法复现线上生产问题。</p></li><li><p>设置 <code>SQL</code> 禁用 <code>MyBatis</code> 一级缓存。同时发现该类上存在 <code>@Transactional</code> 注解。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">useCache=&quot;false&quot; flushCache=&quot;true&quot;</span><br></pre></td></tr></table></figure></li><li><p>将 <code>insert</code> 部分代码与 <code>select</code> 部分代码拆分，不在同一个事务中提交。</p></li></ol><hr><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>回顾本次的业务流程，相当于是多线程对同一个资源进行操作，而由于 <code>MyBatis</code> 自带的一级缓存和 <code>SqlConnectionPool</code> 连接池，导致异步任务的 <code>sql</code> 去查询时，每次都会使用同一个 <code>connection</code>，然后查询语句就会匹配上缓存，且因为在同一个事务中 <code>select</code> 语句和 <code>insert</code> 语句执行之间会导致事务提交存在空挡。导致在服务端推送结果之后，<code>sql</code> 依旧查询不到结果。</p><hr><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><hr><h3 id="个人备注"><a href="#个人备注" class="headerlink" title="个人备注"></a>个人备注</h3><p><strong>此博客内容均为作者学习所做笔记，侵删！</strong><br><strong>若转作其他用途，请注明来源！</strong></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;问题复现&quot;&gt;&lt;a href=&quot;#问题复现&quot; class=&quot;headerlink&quot; title=&quot;问题复现&quot;&gt;&lt;/a&gt;问题复现&lt;/h3&gt;&lt;p&gt;年后又是一波需求狂潮，在经历了上一周的痛苦上班时间之后，这周一又开始了新的需求，新的 Code 生活也伴随而来重新开始。&lt;/p&gt;
&lt;p&gt;首先我先简略描述一下本次的需求，我这边负责的后台向服务端的接口推送一条信息，然后服务端会把接收到的信息处理后，同步推送到我们的另一个接口。&lt;br&gt;而在上一步的推送信息之后，我们这边会启动一个异步的任务会在特定的时间段内处理服务端返回的信息。&lt;br&gt;那么问题就来了，在这个异步任务中实时去查询 &lt;code&gt;SQL&lt;/code&gt;，但是查询回来的&lt;strong&gt;结果是空的&lt;/strong&gt;。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Java" scheme="https://blog.vgbhfive.cn/tags/Java/"/>
    
    <category term="MySQL" scheme="https://blog.vgbhfive.cn/tags/MySQL/"/>
    
    <category term="Day" scheme="https://blog.vgbhfive.cn/tags/Day/"/>
    
  </entry>
  
</feed>
